18/06/25 10:22:02 INFO SparkContext: Running Spark version 2.1.0
18/06/25 10:22:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/06/25 10:22:04 INFO SecurityManager: Changing view acls to: JBRickert
18/06/25 10:22:04 INFO SecurityManager: Changing modify acls to: JBRickert
18/06/25 10:22:04 INFO SecurityManager: Changing view acls groups to: 
18/06/25 10:22:04 INFO SecurityManager: Changing modify acls groups to: 
18/06/25 10:22:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JBRickert); groups with view permissions: Set(); users  with modify permissions: Set(JBRickert); groups with modify permissions: Set()
18/06/25 10:22:05 INFO Utils: Successfully started service 'sparkDriver' on port 52521.
18/06/25 10:22:05 INFO SparkEnv: Registering MapOutputTracker
18/06/25 10:22:05 INFO SparkEnv: Registering BlockManagerMaster
18/06/25 10:22:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/06/25 10:22:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/06/25 10:22:05 INFO DiskBlockManager: Created local directory at /private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/blockmgr-630eb3a9-e518-41d7-8389-4f3e09f152d7
18/06/25 10:22:05 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/06/25 10:22:05 INFO SparkEnv: Registering OutputCommitCoordinator
18/06/25 10:22:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/06/25 10:22:06 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/06/25 10:22:06 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:52521/jars/sparklyr-2.1-2.11.jar with timestamp 1529947326744
18/06/25 10:22:07 INFO Executor: Starting executor ID driver on host localhost
18/06/25 10:22:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52522.
18/06/25 10:22:07 INFO NettyBlockTransferService: Server created on 127.0.0.1:52522
18/06/25 10:22:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/06/25 10:22:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52522, None)
18/06/25 10:22:07 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52522 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 52522, None)
18/06/25 10:22:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52522, None)
18/06/25 10:22:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52522, None)
18/06/25 10:22:08 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/06/25 10:22:08 INFO SharedState: Warehouse path is 'file:/Users/JBRickert/Documents/RStudio_Projects/useR_2018/spark-warehouse'.
18/06/25 10:22:08 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/06/25 10:22:10 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/06/25 10:22:10 INFO ObjectStore: ObjectStore, initialize called
18/06/25 10:22:10 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/06/25 10:22:10 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/06/25 10:22:14 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/06/25 10:22:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 10:22:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 10:22:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 10:22:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 10:22:16 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/06/25 10:22:16 INFO ObjectStore: Initialized ObjectStore
18/06/25 10:22:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/06/25 10:22:17 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/06/25 10:22:18 INFO HiveMetaStore: Added admin role in metastore
18/06/25 10:22:18 INFO HiveMetaStore: Added public role in metastore
18/06/25 10:22:18 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/06/25 10:22:18 INFO HiveMetaStore: 0: get_all_databases
18/06/25 10:22:18 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_all_databases	
18/06/25 10:22:18 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/06/25 10:22:18 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/06/25 10:22:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 10:22:19 INFO SessionState: Created HDFS directory: /tmp/hive/JBRickert
18/06/25 10:22:19 INFO SessionState: Created local directory: /var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/JBRickert
18/06/25 10:22:19 INFO SessionState: Created local directory: /var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/e9ab437f-8ea8-44f4-9f60-e0b5f7abaead_resources
18/06/25 10:22:19 INFO SessionState: Created HDFS directory: /tmp/hive/JBRickert/e9ab437f-8ea8-44f4-9f60-e0b5f7abaead
18/06/25 10:22:19 INFO SessionState: Created local directory: /var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/JBRickert/e9ab437f-8ea8-44f4-9f60-e0b5f7abaead
18/06/25 10:22:19 INFO SessionState: Created HDFS directory: /tmp/hive/JBRickert/e9ab437f-8ea8-44f4-9f60-e0b5f7abaead/_tmp_space.db
18/06/25 10:22:19 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/JBRickert/Documents/RStudio_Projects/useR_2018/spark-warehouse
18/06/25 10:22:19 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:22:19 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:22:19 INFO HiveMetaStore: 0: get_database: global_temp
18/06/25 10:22:19 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/06/25 10:22:19 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/06/25 10:22:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:22:26 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:22:26 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:22:26 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:22:26 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:22:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:22:26 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:22:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:22:27 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:22:27 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:22:27 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:22:27 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:22:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:22:27 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:24:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:24:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:24:55 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:24:55 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:24:56 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:24:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:24:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:24:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:24:57 INFO CodeGenerator: Code generated in 741.247119 ms
18/06/25 10:24:57 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 10:24:57 INFO DAGScheduler: Got job 0 (collect at utils.scala:43) with 1 output partitions
18/06/25 10:24:57 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:43)
18/06/25 10:24:57 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:24:57 INFO DAGScheduler: Missing parents: List()
18/06/25 10:24:57 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:40), which has no missing parents
18/06/25 10:24:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
18/06/25 10:24:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
18/06/25 10:24:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52522 (size: 4.6 KB, free: 366.3 MB)
18/06/25 10:24:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
18/06/25 10:24:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:40)
18/06/25 10:24:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/06/25 10:24:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
18/06/25 10:24:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/06/25 10:24:58 INFO Executor: Fetching spark://127.0.0.1:52521/jars/sparklyr-2.1-2.11.jar with timestamp 1529947326744
18/06/25 10:24:58 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52521 after 25 ms (0 ms spent in bootstraps)
18/06/25 10:24:58 INFO Utils: Fetching spark://127.0.0.1:52521/jars/sparklyr-2.1-2.11.jar to /private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/spark-ce1c91b7-c54e-4245-b8fb-847fb524ad52/userFiles-7aac3681-aee3-4674-8393-4db67418e2a7/fetchFileTemp7365369161249779964.tmp
18/06/25 10:24:58 INFO Executor: Adding file:/private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/spark-ce1c91b7-c54e-4245-b8fb-847fb524ad52/userFiles-7aac3681-aee3-4674-8393-4db67418e2a7/sparklyr-2.1-2.11.jar to class loader
18/06/25 10:24:58 INFO CodeGenerator: Code generated in 15.577509 ms
18/06/25 10:24:58 INFO CodeGenerator: Code generated in 18.430996 ms
18/06/25 10:24:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
18/06/25 10:24:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 511 ms on localhost (executor driver) (1/1)
18/06/25 10:24:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/06/25 10:24:58 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:43) finished in 0.584 s
18/06/25 10:24:58 INFO DAGScheduler: Job 0 finished: collect at utils.scala:43, took 1.268755 s
18/06/25 10:24:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:24:59 INFO SparkSqlParser: Parsing command: iris
18/06/25 10:24:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:24:59 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
18/06/25 10:24:59 INFO SparkSqlParser: Parsing command: `iris`
18/06/25 10:24:59 INFO CodeGenerator: Code generated in 19.557566 ms
18/06/25 10:24:59 INFO CodeGenerator: Code generated in 12.92802 ms
18/06/25 10:24:59 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 10:24:59 INFO DAGScheduler: Registering RDD 16 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:24:59 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 10:24:59 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:24:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/06/25 10:24:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/06/25 10:24:59 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 10:24:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 366.3 MB)
18/06/25 10:24:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 366.3 MB)
18/06/25 10:24:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52522 (size: 8.5 KB, free: 366.3 MB)
18/06/25 10:24:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
18/06/25 10:24:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:24:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/06/25 10:24:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 10001 bytes)
18/06/25 10:24:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/06/25 10:24:59 INFO CodeGenerator: Code generated in 12.56969 ms
18/06/25 10:25:00 INFO CodeGenerator: Code generated in 50.028135 ms
18/06/25 10:25:00 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 5.6 KB, free 366.3 MB)
18/06/25 10:25:00 INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:52522 (size: 5.6 KB, free: 366.3 MB)
18/06/25 10:25:00 INFO CodeGenerator: Code generated in 5.685422 ms
18/06/25 10:25:00 INFO CodeGenerator: Code generated in 25.19898 ms
18/06/25 10:25:00 INFO ContextCleaner: Cleaned accumulator 0
18/06/25 10:25:00 INFO ContextCleaner: Cleaned accumulator 1
18/06/25 10:25:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2820 bytes result sent to driver
18/06/25 10:25:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 546 ms on localhost (executor driver) (1/1)
18/06/25 10:25:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/06/25 10:25:00 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.549 s
18/06/25 10:25:00 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:25:00 INFO DAGScheduler: running: Set()
18/06/25 10:25:00 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/06/25 10:25:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:52522 in memory (size: 4.6 KB, free: 366.3 MB)
18/06/25 10:25:00 INFO DAGScheduler: failed: Set()
18/06/25 10:25:00 INFO ContextCleaner: Cleaned accumulator 52
18/06/25 10:25:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[19] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 10:25:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
18/06/25 10:25:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
18/06/25 10:25:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 366.3 MB)
18/06/25 10:25:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[19] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/06/25 10:25:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
18/06/25 10:25:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/06/25 10:25:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:25:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
18/06/25 10:25:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2129 bytes result sent to driver
18/06/25 10:25:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 74 ms on localhost (executor driver) (1/1)
18/06/25 10:25:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/06/25 10:25:00 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.076 s
18/06/25 10:25:00 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.705682 s
18/06/25 10:25:00 INFO CodeGenerator: Code generated in 9.506517 ms
18/06/25 10:25:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:00 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
18/06/25 10:25:00 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:25:00 INFO DAGScheduler: Registering RDD 23 (collect at utils.scala:196)
18/06/25 10:25:00 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:25:00 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
18/06/25 10:25:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/06/25 10:25:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/06/25 10:25:00 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[23] at collect at utils.scala:196), which has no missing parents
18/06/25 10:25:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 366.2 MB)
18/06/25 10:25:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.4 KB, free 366.2 MB)
18/06/25 10:25:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52522 (size: 8.4 KB, free: 366.3 MB)
18/06/25 10:25:00 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[23] at collect at utils.scala:196)
18/06/25 10:25:00 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/06/25 10:25:00 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 9993 bytes)
18/06/25 10:25:00 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/06/25 10:25:00 INFO BlockManager: Found block rdd_13_0 locally
18/06/25 10:25:00 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2098 bytes result sent to driver
18/06/25 10:25:00 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 16 ms on localhost (executor driver) (1/1)
18/06/25 10:25:00 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/06/25 10:25:00 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.017 s
18/06/25 10:25:00 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:25:00 INFO DAGScheduler: running: Set()
18/06/25 10:25:00 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/06/25 10:25:00 INFO DAGScheduler: failed: Set()
18/06/25 10:25:00 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[26] at collect at utils.scala:196), which has no missing parents
18/06/25 10:25:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/06/25 10:25:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/06/25 10:25:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 366.3 MB)
18/06/25 10:25:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[26] at collect at utils.scala:196)
18/06/25 10:25:00 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/06/25 10:25:00 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
18/06/25 10:25:00 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/06/25 10:25:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:25:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 10:25:00 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
18/06/25 10:25:00 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 12 ms on localhost (executor driver) (1/1)
18/06/25 10:25:00 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/06/25 10:25:00 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.013 s
18/06/25 10:25:00 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.052925 s
18/06/25 10:25:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
18/06/25 10:25:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:25:00 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:00 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:25:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:25:00 INFO CodeGenerator: Code generated in 13.394485 ms
18/06/25 10:25:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:25:01 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:01 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:01 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:01 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:25:01 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:25:01 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 10:25:01 INFO DAGScheduler: Got job 3 (collect at utils.scala:43) with 1 output partitions
18/06/25 10:25:01 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:43)
18/06/25 10:25:01 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:25:01 INFO DAGScheduler: Missing parents: List()
18/06/25 10:25:01 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[33] at map at utils.scala:40), which has no missing parents
18/06/25 10:25:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 366.2 MB)
18/06/25 10:25:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.2 MB)
18/06/25 10:25:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52522 (size: 4.6 KB, free: 366.3 MB)
18/06/25 10:25:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[33] at map at utils.scala:40)
18/06/25 10:25:01 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/06/25 10:25:01 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
18/06/25 10:25:01 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/06/25 10:25:01 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1238 bytes result sent to driver
18/06/25 10:25:01 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 24 ms on localhost (executor driver) (1/1)
18/06/25 10:25:01 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/06/25 10:25:01 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:43) finished in 0.025 s
18/06/25 10:25:01 INFO DAGScheduler: Job 3 finished: collect at utils.scala:43, took 0.039896 s
18/06/25 10:25:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:07 INFO SparkSqlParser: Parsing command: flights
18/06/25 10:25:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:07 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
18/06/25 10:25:07 INFO SparkSqlParser: Parsing command: `flights`
18/06/25 10:25:07 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 10:25:07 INFO DAGScheduler: Registering RDD 42 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:07 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 10:25:07 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
18/06/25 10:25:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
18/06/25 10:25:07 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[42] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 10:25:07 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 30.7 KB, free 366.2 MB)
18/06/25 10:25:07 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.7 KB, free 366.2 MB)
18/06/25 10:25:07 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52522 (size: 11.7 KB, free: 366.3 MB)
18/06/25 10:25:07 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[42] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:07 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 322
18/06/25 10:25:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 366.3 MB)
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 270
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 271
18/06/25 10:25:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:52522 in memory (size: 4.6 KB, free: 366.3 MB)
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 53
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 54
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 55
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 56
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 57
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 58
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 59
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 60
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 61
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 62
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 63
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 64
18/06/25 10:25:08 INFO ContextCleaner: Cleaned shuffle 0
18/06/25 10:25:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:52522 in memory (size: 8.5 KB, free: 366.3 MB)
18/06/25 10:25:08 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 366.3 MB)
18/06/25 10:25:08 INFO ContextCleaner: Cleaned accumulator 161
18/06/25 10:25:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:52522 in memory (size: 8.4 KB, free: 366.3 MB)
18/06/25 10:25:08 WARN TaskSetManager: Stage 6 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:25:08 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365330 bytes)
18/06/25 10:25:08 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/06/25 10:25:09 INFO CodeGenerator: Code generated in 20.85538 ms
18/06/25 10:25:09 INFO CodeGenerator: Code generated in 127.28753 ms
18/06/25 10:25:12 INFO MemoryStore: Block rdd_39_0 stored as values in memory (estimated size 22.5 MB, free 343.8 MB)
18/06/25 10:25:12 INFO BlockManagerInfo: Added rdd_39_0 in memory on 127.0.0.1:52522 (size: 22.5 MB, free: 343.8 MB)
18/06/25 10:25:12 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2733 bytes result sent to driver
18/06/25 10:25:12 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5123 ms on localhost (executor driver) (1/1)
18/06/25 10:25:12 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/06/25 10:25:12 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 5.124 s
18/06/25 10:25:12 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:25:12 INFO DAGScheduler: running: Set()
18/06/25 10:25:12 INFO DAGScheduler: waiting: Set(ResultStage 7)
18/06/25 10:25:12 INFO DAGScheduler: failed: Set()
18/06/25 10:25:12 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[45] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 10:25:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 343.8 MB)
18/06/25 10:25:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 343.7 MB)
18/06/25 10:25:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 343.8 MB)
18/06/25 10:25:12 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[45] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:12 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/06/25 10:25:12 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, ANY, 5953 bytes)
18/06/25 10:25:12 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
18/06/25 10:25:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:25:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 10:25:12 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2042 bytes result sent to driver
18/06/25 10:25:12 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
18/06/25 10:25:12 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/06/25 10:25:12 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
18/06/25 10:25:12 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 5.155783 s
18/06/25 10:25:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:12 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
18/06/25 10:25:12 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:25:12 INFO DAGScheduler: Registering RDD 49 (collect at utils.scala:196)
18/06/25 10:25:12 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:25:12 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
18/06/25 10:25:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
18/06/25 10:25:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
18/06/25 10:25:12 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[49] at collect at utils.scala:196), which has no missing parents
18/06/25 10:25:12 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 30.7 KB, free 343.7 MB)
18/06/25 10:25:12 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.8 KB, free 343.7 MB)
18/06/25 10:25:12 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:52522 (size: 11.8 KB, free: 343.8 MB)
18/06/25 10:25:12 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[49] at collect at utils.scala:196)
18/06/25 10:25:12 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/06/25 10:25:12 WARN TaskSetManager: Stage 8 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:25:12 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365323 bytes)
18/06/25 10:25:12 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
18/06/25 10:25:12 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 343.8 MB)
18/06/25 10:25:12 INFO ContextCleaner: Cleaned accumulator 431
18/06/25 10:25:12 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:25:12 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2171 bytes result sent to driver
18/06/25 10:25:13 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 355 ms on localhost (executor driver) (1/1)
18/06/25 10:25:13 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/06/25 10:25:13 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.357 s
18/06/25 10:25:13 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:25:13 INFO DAGScheduler: running: Set()
18/06/25 10:25:13 INFO DAGScheduler: waiting: Set(ResultStage 9)
18/06/25 10:25:13 INFO DAGScheduler: failed: Set()
18/06/25 10:25:13 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[52] at collect at utils.scala:196), which has no missing parents
18/06/25 10:25:13 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 343.7 MB)
18/06/25 10:25:13 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 343.7 MB)
18/06/25 10:25:13 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 343.8 MB)
18/06/25 10:25:13 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[52] at collect at utils.scala:196)
18/06/25 10:25:13 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/06/25 10:25:13 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 5946 bytes)
18/06/25 10:25:13 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
18/06/25 10:25:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:25:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 10:25:13 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2042 bytes result sent to driver
18/06/25 10:25:13 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 9 ms on localhost (executor driver) (1/1)
18/06/25 10:25:13 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/06/25 10:25:13 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.009 s
18/06/25 10:25:13 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.384815 s
18/06/25 10:25:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
18/06/25 10:25:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:25:13 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:13 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:13 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:13 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:25:13 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:25:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:25:13 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:13 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:13 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:13 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:25:13 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:25:13 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 10:25:13 INFO DAGScheduler: Got job 6 (collect at utils.scala:43) with 1 output partitions
18/06/25 10:25:13 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:43)
18/06/25 10:25:13 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:25:13 INFO DAGScheduler: Missing parents: List()
18/06/25 10:25:13 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[59] at map at utils.scala:40), which has no missing parents
18/06/25 10:25:13 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.7 KB, free 343.7 MB)
18/06/25 10:25:13 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KB, free 343.7 MB)
18/06/25 10:25:13 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:52522 (size: 4.6 KB, free: 343.8 MB)
18/06/25 10:25:13 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[59] at map at utils.scala:40)
18/06/25 10:25:13 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/06/25 10:25:13 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
18/06/25 10:25:13 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
18/06/25 10:25:13 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1248 bytes result sent to driver
18/06/25 10:25:13 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 11 ms on localhost (executor driver) (1/1)
18/06/25 10:25:13 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/06/25 10:25:13 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:43) finished in 0.013 s
18/06/25 10:25:13 INFO DAGScheduler: Job 6 finished: collect at utils.scala:43, took 0.020374 s
18/06/25 10:25:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:14 INFO SparkSqlParser: Parsing command: batting
18/06/25 10:25:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:14 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
18/06/25 10:25:14 INFO SparkSqlParser: Parsing command: `batting`
18/06/25 10:25:14 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 10:25:14 INFO DAGScheduler: Registering RDD 68 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:14 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 10:25:14 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/06/25 10:25:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/06/25 10:25:14 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[68] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 10:25:14 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 31.9 KB, free 343.7 MB)
18/06/25 10:25:14 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.7 KB, free 343.6 MB)
18/06/25 10:25:14 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:52522 (size: 11.7 KB, free: 343.8 MB)
18/06/25 10:25:14 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[68] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:14 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
18/06/25 10:25:14 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:52522 in memory (size: 11.8 KB, free: 343.8 MB)
18/06/25 10:25:14 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 343.8 MB)
18/06/25 10:25:14 INFO ContextCleaner: Cleaned accumulator 540
18/06/25 10:25:14 INFO ContextCleaner: Cleaned accumulator 541
18/06/25 10:25:14 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:52522 in memory (size: 4.6 KB, free: 343.8 MB)
18/06/25 10:25:14 INFO ContextCleaner: Cleaned accumulator 592
18/06/25 10:25:14 WARN TaskSetManager: Stage 11 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 10:25:14 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814099 bytes)
18/06/25 10:25:14 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
18/06/25 10:25:14 INFO CodeGenerator: Code generated in 16.153246 ms
18/06/25 10:25:14 INFO CodeGenerator: Code generated in 107.615915 ms
18/06/25 10:25:16 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:52522 in memory (size: 11.7 KB, free: 343.8 MB)
18/06/25 10:25:16 INFO ContextCleaner: Cleaned shuffle 2
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 334
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 333
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 332
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 331
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 330
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 329
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 328
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 327
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 326
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 325
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 324
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 323
18/06/25 10:25:16 INFO MemoryStore: Block rdd_65_0 stored as values in memory (estimated size 3.3 MB, free 340.4 MB)
18/06/25 10:25:16 INFO BlockManagerInfo: Added rdd_65_0 in memory on 127.0.0.1:52522 (size: 3.3 MB, free: 340.5 MB)
18/06/25 10:25:16 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2733 bytes result sent to driver
18/06/25 10:25:16 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 2121 ms on localhost (executor driver) (1/1)
18/06/25 10:25:16 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/06/25 10:25:16 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 2.123 s
18/06/25 10:25:16 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:25:16 INFO DAGScheduler: running: Set()
18/06/25 10:25:16 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/06/25 10:25:16 INFO DAGScheduler: failed: Set()
18/06/25 10:25:16 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[71] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 10:25:16 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
18/06/25 10:25:16 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
18/06/25 10:25:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 340.5 MB)
18/06/25 10:25:16 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[71] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 10:25:16 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/06/25 10:25:16 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, ANY, 5954 bytes)
18/06/25 10:25:16 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
18/06/25 10:25:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:25:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:25:16 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2042 bytes result sent to driver
18/06/25 10:25:16 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 8 ms on localhost (executor driver) (1/1)
18/06/25 10:25:16 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/06/25 10:25:16 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.009 s
18/06/25 10:25:16 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 2.151818 s
18/06/25 10:25:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:16 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
18/06/25 10:25:16 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:25:16 INFO DAGScheduler: Registering RDD 75 (collect at utils.scala:196)
18/06/25 10:25:16 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:25:16 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
18/06/25 10:25:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/06/25 10:25:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/06/25 10:25:16 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[75] at collect at utils.scala:196), which has no missing parents
18/06/25 10:25:16 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.9 KB, free 340.4 MB)
18/06/25 10:25:16 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 11.7 KB, free 340.4 MB)
18/06/25 10:25:16 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:52522 (size: 11.7 KB, free: 340.4 MB)
18/06/25 10:25:16 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[75] at collect at utils.scala:196)
18/06/25 10:25:16 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/06/25 10:25:16 WARN TaskSetManager: Stage 13 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 10:25:16 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814091 bytes)
18/06/25 10:25:16 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
18/06/25 10:25:16 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 340.5 MB)
18/06/25 10:25:16 INFO ContextCleaner: Cleaned accumulator 701
18/06/25 10:25:16 INFO BlockManager: Found block rdd_65_0 locally
18/06/25 10:25:16 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2171 bytes result sent to driver
18/06/25 10:25:16 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 95 ms on localhost (executor driver) (1/1)
18/06/25 10:25:16 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/06/25 10:25:16 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.095 s
18/06/25 10:25:16 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:25:16 INFO DAGScheduler: running: Set()
18/06/25 10:25:16 INFO DAGScheduler: waiting: Set(ResultStage 14)
18/06/25 10:25:16 INFO DAGScheduler: failed: Set()
18/06/25 10:25:16 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[78] at collect at utils.scala:196), which has no missing parents
18/06/25 10:25:16 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
18/06/25 10:25:16 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
18/06/25 10:25:16 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 340.4 MB)
18/06/25 10:25:16 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[78] at collect at utils.scala:196)
18/06/25 10:25:16 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
18/06/25 10:25:16 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 5946 bytes)
18/06/25 10:25:16 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
18/06/25 10:25:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:25:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:25:16 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2042 bytes result sent to driver
18/06/25 10:25:16 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
18/06/25 10:25:16 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/06/25 10:25:16 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.006 s
18/06/25 10:25:16 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.121261 s
18/06/25 10:25:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
18/06/25 10:25:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:25:16 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:16 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:25:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:25:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:25:34 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:34 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:34 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:25:34 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:25:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:25:34 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:25:34 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 10:25:34 INFO DAGScheduler: Got job 9 (collect at utils.scala:43) with 1 output partitions
18/06/25 10:25:34 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:43)
18/06/25 10:25:34 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:25:34 INFO DAGScheduler: Missing parents: List()
18/06/25 10:25:34 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[85] at map at utils.scala:40), which has no missing parents
18/06/25 10:25:34 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 8.7 KB, free 340.4 MB)
18/06/25 10:25:34 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.6 KB, free 340.4 MB)
18/06/25 10:25:34 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:52522 (size: 4.6 KB, free: 340.4 MB)
18/06/25 10:25:34 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[85] at map at utils.scala:40)
18/06/25 10:25:34 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/06/25 10:25:34 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6462 bytes)
18/06/25 10:25:34 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
18/06/25 10:25:34 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1258 bytes result sent to driver
18/06/25 10:25:34 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (executor driver) (1/1)
18/06/25 10:25:34 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:43) finished in 0.008 s
18/06/25 10:25:34 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/06/25 10:25:34 INFO DAGScheduler: Job 9 finished: collect at utils.scala:43, took 0.016503 s
18/06/25 10:25:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 10:25:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 10:25:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 10:25:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 10:25:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 10:25:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:25:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 1000
18/06/25 10:25:55 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#208) generates partition filter: ((dep_delay.count#1338 - dep_delay.nullCount#1337) > 0)
18/06/25 10:25:55 INFO InMemoryTableScanExec: Predicate (dep_delay#208 = 2.0) generates partition filter: ((dep_delay.lowerBound#1336 <= 2.0) && (2.0 <= dep_delay.upperBound#1335))
18/06/25 10:25:55 INFO CodeGenerator: Code generated in 15.61211 ms
18/06/25 10:25:55 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:25:55 INFO DAGScheduler: Got job 10 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:25:55 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
18/06/25 10:25:55 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:25:55 INFO DAGScheduler: Missing parents: List()
18/06/25 10:25:55 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[88] at collect at utils.scala:196), which has no missing parents
18/06/25 10:25:55 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 34.7 KB, free 340.3 MB)
18/06/25 10:25:55 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 12.6 KB, free 340.3 MB)
18/06/25 10:25:55 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:52522 (size: 12.6 KB, free: 340.4 MB)
18/06/25 10:25:55 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
18/06/25 10:25:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[88] at collect at utils.scala:196)
18/06/25 10:25:55 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/06/25 10:25:55 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:52522 in memory (size: 11.7 KB, free: 340.4 MB)
18/06/25 10:25:55 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 10:25:55 INFO ContextCleaner: Cleaned accumulator 810
18/06/25 10:25:55 INFO ContextCleaner: Cleaned accumulator 811
18/06/25 10:25:55 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:52522 in memory (size: 4.6 KB, free: 340.5 MB)
18/06/25 10:25:55 WARN TaskSetManager: Stage 16 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:25:55 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 10:25:55 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
18/06/25 10:25:55 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:25:55 INFO CodeGenerator: Code generated in 9.5063 ms
18/06/25 10:25:55 INFO CodeGenerator: Code generated in 23.085023 ms
18/06/25 10:25:56 WARN Executor: 1 block locks were not released by TID = 16:
[rdd_39_0]
18/06/25 10:25:56 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 67686 bytes result sent to driver
18/06/25 10:25:56 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 775 ms on localhost (executor driver) (1/1)
18/06/25 10:25:56 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/06/25 10:25:56 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 0.775 s
18/06/25 10:25:56 INFO DAGScheduler: Job 10 finished: collect at utils.scala:196, took 0.791643 s
18/06/25 10:25:56 INFO CodeGenerator: Code generated in 15.143839 ms
18/06/25 10:26:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:26:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `zmhsbhbwht`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
18/06/25 10:26:38 INFO CodeGenerator: Code generated in 45.712279 ms
18/06/25 10:26:38 INFO CodeGenerator: Code generated in 56.938549 ms
18/06/25 10:26:38 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:26:38 INFO DAGScheduler: Registering RDD 91 (collect at utils.scala:196)
18/06/25 10:26:38 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 4 output partitions
18/06/25 10:26:38 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
18/06/25 10:26:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
18/06/25 10:26:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
18/06/25 10:26:38 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[91] at collect at utils.scala:196), which has no missing parents
18/06/25 10:26:38 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 50.3 KB, free 340.3 MB)
18/06/25 10:26:38 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 19.9 KB, free 340.3 MB)
18/06/25 10:26:38 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:52522 (size: 19.9 KB, free: 340.4 MB)
18/06/25 10:26:38 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
18/06/25 10:26:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[91] at collect at utils.scala:196)
18/06/25 10:26:38 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/06/25 10:26:38 INFO ContextCleaner: Cleaned accumulator 911
18/06/25 10:26:38 WARN TaskSetManager: Stage 17 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:26:38 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 10:26:38 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 597
18/06/25 10:26:39 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:52522 in memory (size: 12.6 KB, free: 340.4 MB)
18/06/25 10:26:39 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:52522 in memory (size: 11.7 KB, free: 340.5 MB)
18/06/25 10:26:39 INFO ContextCleaner: Cleaned shuffle 4
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 604
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 603
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 602
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 601
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 600
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 599
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 598
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 596
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 595
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 594
18/06/25 10:26:39 INFO ContextCleaner: Cleaned accumulator 593
18/06/25 10:26:39 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:26:39 INFO CodeGenerator: Code generated in 16.653968 ms
18/06/25 10:26:39 INFO CodeGenerator: Code generated in 8.95653 ms
18/06/25 10:26:39 INFO CodeGenerator: Code generated in 7.239597 ms
18/06/25 10:26:39 INFO CodeGenerator: Code generated in 5.792335 ms
18/06/25 10:26:39 INFO CodeGenerator: Code generated in 11.853596 ms
18/06/25 10:26:39 INFO CodeGenerator: Code generated in 6.402285 ms
18/06/25 10:26:39 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2442 bytes result sent to driver
18/06/25 10:26:39 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 1240 ms on localhost (executor driver) (1/1)
18/06/25 10:26:39 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/06/25 10:26:39 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:196) finished in 1.241 s
18/06/25 10:26:39 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:26:39 INFO DAGScheduler: running: Set()
18/06/25 10:26:39 INFO DAGScheduler: waiting: Set(ResultStage 18)
18/06/25 10:26:39 INFO DAGScheduler: failed: Set()
18/06/25 10:26:39 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[94] at collect at utils.scala:196), which has no missing parents
18/06/25 10:26:39 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 27.3 KB, free 340.4 MB)
18/06/25 10:26:39 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.7 KB, free 340.4 MB)
18/06/25 10:26:39 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:52522 (size: 11.7 KB, free: 340.4 MB)
18/06/25 10:26:39 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
18/06/25 10:26:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[94] at collect at utils.scala:196)
18/06/25 10:26:39 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
18/06/25 10:26:39 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 10:26:39 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 19, localhost, executor driver, partition 1, ANY, 5947 bytes)
18/06/25 10:26:39 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 20, localhost, executor driver, partition 2, ANY, 5947 bytes)
18/06/25 10:26:39 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 21, localhost, executor driver, partition 3, ANY, 5947 bytes)
18/06/25 10:26:39 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
18/06/25 10:26:39 INFO Executor: Running task 1.0 in stage 18.0 (TID 19)
18/06/25 10:26:39 INFO Executor: Running task 3.0 in stage 18.0 (TID 21)
18/06/25 10:26:39 INFO Executor: Running task 2.0 in stage 18.0 (TID 20)
18/06/25 10:26:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:26:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:26:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 10:26:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:26:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/06/25 10:26:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/06/25 10:26:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:26:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/06/25 10:26:39 INFO Executor: Finished task 2.0 in stage 18.0 (TID 20). 23246 bytes result sent to driver
18/06/25 10:26:39 INFO Executor: Finished task 1.0 in stage 18.0 (TID 19). 22319 bytes result sent to driver
18/06/25 10:26:39 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 20) in 42 ms on localhost (executor driver) (1/4)
18/06/25 10:26:39 INFO Executor: Finished task 3.0 in stage 18.0 (TID 21). 21386 bytes result sent to driver
18/06/25 10:26:39 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 22143 bytes result sent to driver
18/06/25 10:26:39 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 19) in 43 ms on localhost (executor driver) (2/4)
18/06/25 10:26:39 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 21) in 43 ms on localhost (executor driver) (3/4)
18/06/25 10:26:39 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 45 ms on localhost (executor driver) (4/4)
18/06/25 10:26:39 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.046 s
18/06/25 10:26:39 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/06/25 10:26:39 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 1.300569 s
18/06/25 10:26:39 INFO CodeGenerator: Code generated in 7.395802 ms
18/06/25 10:27:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting`
18/06/25 10:27:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting`
18/06/25 10:27:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting`
18/06/25 10:27:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting`
18/06/25 10:27:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting`
18/06/25 10:27:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting`
LIMIT 1000
18/06/25 10:27:08 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:27:08 INFO DAGScheduler: Got job 12 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:27:08 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:196)
18/06/25 10:27:08 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:27:08 INFO DAGScheduler: Missing parents: List()
18/06/25 10:27:08 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[96] at collect at utils.scala:196), which has no missing parents
18/06/25 10:27:08 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 27.6 KB, free 340.3 MB)
18/06/25 10:27:08 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 9.7 KB, free 340.3 MB)
18/06/25 10:27:08 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:52522 (size: 9.7 KB, free: 340.4 MB)
18/06/25 10:27:08 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
18/06/25 10:27:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[96] at collect at utils.scala:196)
18/06/25 10:27:08 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
18/06/25 10:27:08 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:52522 in memory (size: 11.7 KB, free: 340.4 MB)
18/06/25 10:27:08 WARN TaskSetManager: Stage 19 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 10:27:08 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814017 bytes)
18/06/25 10:27:08 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
18/06/25 10:27:08 INFO BlockManager: Found block rdd_65_0 locally
18/06/25 10:27:08 INFO CodeGenerator: Code generated in 17.778201 ms
18/06/25 10:27:08 WARN Executor: 1 block locks were not released by TID = 22:
[rdd_65_0]
18/06/25 10:27:08 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 48185 bytes result sent to driver
18/06/25 10:27:08 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 149 ms on localhost (executor driver) (1/1)
18/06/25 10:27:08 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/06/25 10:27:08 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:196) finished in 0.150 s
18/06/25 10:27:08 INFO DAGScheduler: Job 12 finished: collect at utils.scala:196, took 0.158914 s
18/06/25 10:27:08 INFO CodeGenerator: Code generated in 12.144908 ms
18/06/25 10:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:19 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`, rank() OVER (PARTITION BY `playerID` ORDER BY `H` DESC) AS `zzz4`
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `fhicxhhvzy`
ORDER BY `playerID`, `yearID`, `teamID`) `fepyagkefg`) `ddhinplyxs`
WHERE (`zzz4` <= 2.0 AND `H` > 0.0)
18/06/25 10:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:19 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`, rank() OVER (PARTITION BY `playerID` ORDER BY `H` DESC) AS `zzz5`
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `ablltovvgs`
ORDER BY `playerID`, `yearID`, `teamID`) `uiknmpqghm`) `xkpdctonpq`
WHERE (`zzz5` <= 2.0 AND `H` > 0.0)
18/06/25 10:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:19 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`, rank() OVER (PARTITION BY `playerID` ORDER BY `H` DESC) AS `zzz6`
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `asisqoqref`
ORDER BY `playerID`, `yearID`, `teamID`) `oaqdmeiald`) `ftyvhydhfo`
WHERE (`zzz6` <= 2.0 AND `H` > 0.0)
18/06/25 10:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:19 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`, rank() OVER (PARTITION BY `playerID` ORDER BY `H` DESC) AS `zzz7`
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `cxggkvxuln`
ORDER BY `playerID`, `yearID`, `teamID`) `gfstnbtfil`) `bpupkjylvb`
WHERE (`zzz7` <= 2.0 AND `H` > 0.0)
18/06/25 10:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:19 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`, rank() OVER (PARTITION BY `playerID` ORDER BY `H` DESC) AS `zzz8`
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `uusmjqsulf`
ORDER BY `playerID`, `yearID`, `teamID`) `kzzgsucxjb`) `iugzghcsrn`
WHERE (`zzz8` <= 2.0 AND `H` > 0.0)
18/06/25 10:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:19 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`, rank() OVER (PARTITION BY `playerID` ORDER BY `H` DESC) AS `zzz9`
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `vbfxooyhxz`
ORDER BY `playerID`, `yearID`, `teamID`) `zczaygcolk`) `mqbrmciuur`
WHERE (`zzz9` <= 2.0 AND `H` > 0.0)
LIMIT 1000
18/06/25 10:27:19 INFO CodeGenerator: Code generated in 8.8259 ms
18/06/25 10:27:19 INFO CodeGenerator: Code generated in 13.71851 ms
18/06/25 10:27:19 INFO CodeGenerator: Code generated in 16.706022 ms
18/06/25 10:27:19 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:27:19 INFO DAGScheduler: Got job 13 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:27:19 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:196)
18/06/25 10:27:19 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:27:19 INFO DAGScheduler: Missing parents: List()
18/06/25 10:27:19 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[100] at collect at utils.scala:196), which has no missing parents
18/06/25 10:27:19 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 28.6 KB, free 340.3 MB)
18/06/25 10:27:19 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 10.1 KB, free 340.3 MB)
18/06/25 10:27:19 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:52522 (size: 10.1 KB, free: 340.4 MB)
18/06/25 10:27:19 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
18/06/25 10:27:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[100] at collect at utils.scala:196)
18/06/25 10:27:19 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
18/06/25 10:27:19 WARN TaskSetManager: Stage 20 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 10:27:19 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814104 bytes)
18/06/25 10:27:19 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
18/06/25 10:27:19 INFO BlockManager: Found block rdd_65_0 locally
18/06/25 10:27:19 INFO CodeGenerator: Code generated in 19.233256 ms
18/06/25 10:27:20 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 27037 bytes result sent to driver
18/06/25 10:27:20 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 294 ms on localhost (executor driver) (1/1)
18/06/25 10:27:20 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/06/25 10:27:20 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:196) finished in 0.294 s
18/06/25 10:27:20 INFO DAGScheduler: Job 13 finished: collect at utils.scala:196, took 0.306119 s
18/06/25 10:27:20 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:52522 in memory (size: 10.1 KB, free: 340.4 MB)
18/06/25 10:27:20 INFO ContextCleaner: Cleaned accumulator 1143
18/06/25 10:27:20 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:27:20 INFO DAGScheduler: Registering RDD 101 (collect at utils.scala:196)
18/06/25 10:27:20 INFO DAGScheduler: Registering RDD 104 (collect at utils.scala:196)
18/06/25 10:27:20 INFO DAGScheduler: Got job 14 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:27:20 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:196)
18/06/25 10:27:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
18/06/25 10:27:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
18/06/25 10:27:20 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[101] at collect at utils.scala:196), which has no missing parents
18/06/25 10:27:20 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 30.8 KB, free 340.3 MB)
18/06/25 10:27:20 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 11.1 KB, free 340.3 MB)
18/06/25 10:27:20 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:52522 (size: 11.1 KB, free: 340.4 MB)
18/06/25 10:27:20 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
18/06/25 10:27:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[101] at collect at utils.scala:196)
18/06/25 10:27:20 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
18/06/25 10:27:20 WARN TaskSetManager: Stage 21 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 10:27:20 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814006 bytes)
18/06/25 10:27:20 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
18/06/25 10:27:20 INFO BlockManager: Found block rdd_65_0 locally
18/06/25 10:27:20 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 1849 bytes result sent to driver
18/06/25 10:27:20 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 190 ms on localhost (executor driver) (1/1)
18/06/25 10:27:20 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/06/25 10:27:20 INFO DAGScheduler: ShuffleMapStage 21 (collect at utils.scala:196) finished in 0.190 s
18/06/25 10:27:20 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:27:20 INFO DAGScheduler: running: Set()
18/06/25 10:27:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 22, ResultStage 23)
18/06/25 10:27:20 INFO DAGScheduler: failed: Set()
18/06/25 10:27:20 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[104] at collect at utils.scala:196), which has no missing parents
18/06/25 10:27:20 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 11.2 KB, free 340.3 MB)
18/06/25 10:27:20 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.7 KB, free 340.3 MB)
18/06/25 10:27:20 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:52522 (size: 5.7 KB, free: 340.4 MB)
18/06/25 10:27:20 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
18/06/25 10:27:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[104] at collect at utils.scala:196)
18/06/25 10:27:20 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
18/06/25 10:27:20 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, ANY, 5850 bytes)
18/06/25 10:27:20 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 26, localhost, executor driver, partition 1, ANY, 5850 bytes)
18/06/25 10:27:20 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 27, localhost, executor driver, partition 2, ANY, 5850 bytes)
18/06/25 10:27:20 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 28, localhost, executor driver, partition 3, ANY, 5850 bytes)
18/06/25 10:27:20 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
18/06/25 10:27:20 INFO Executor: Running task 1.0 in stage 22.0 (TID 26)
18/06/25 10:27:20 INFO Executor: Running task 3.0 in stage 22.0 (TID 28)
18/06/25 10:27:20 INFO Executor: Running task 2.0 in stage 22.0 (TID 27)
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:27:20 INFO CodeGenerator: Code generated in 15.21151 ms
18/06/25 10:27:20 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:52522 in memory (size: 11.1 KB, free: 340.4 MB)
18/06/25 10:27:20 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 2726 bytes result sent to driver
18/06/25 10:27:20 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 399 ms on localhost (executor driver) (1/4)
18/06/25 10:27:20 INFO Executor: Finished task 3.0 in stage 22.0 (TID 28). 2726 bytes result sent to driver
18/06/25 10:27:20 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 28) in 411 ms on localhost (executor driver) (2/4)
18/06/25 10:27:20 INFO Executor: Finished task 1.0 in stage 22.0 (TID 26). 2726 bytes result sent to driver
18/06/25 10:27:20 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 26) in 422 ms on localhost (executor driver) (3/4)
18/06/25 10:27:20 INFO Executor: Finished task 2.0 in stage 22.0 (TID 27). 2726 bytes result sent to driver
18/06/25 10:27:20 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 27) in 426 ms on localhost (executor driver) (4/4)
18/06/25 10:27:20 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/06/25 10:27:20 INFO DAGScheduler: ShuffleMapStage 22 (collect at utils.scala:196) finished in 0.427 s
18/06/25 10:27:20 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:27:20 INFO DAGScheduler: running: Set()
18/06/25 10:27:20 INFO DAGScheduler: waiting: Set(ResultStage 23)
18/06/25 10:27:20 INFO DAGScheduler: failed: Set()
18/06/25 10:27:20 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[109] at collect at utils.scala:196), which has no missing parents
18/06/25 10:27:20 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 21.4 KB, free 340.3 MB)
18/06/25 10:27:20 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.1 KB, free 340.3 MB)
18/06/25 10:27:20 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:52522 (size: 9.1 KB, free: 340.4 MB)
18/06/25 10:27:20 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
18/06/25 10:27:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[109] at collect at utils.scala:196)
18/06/25 10:27:20 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
18/06/25 10:27:20 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 29, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/06/25 10:27:20 INFO Executor: Running task 0.0 in stage 23.0 (TID 29)
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
18/06/25 10:27:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:27:20 INFO CodeGenerator: Code generated in 7.213857 ms
18/06/25 10:27:20 INFO CodeGenerator: Code generated in 5.080036 ms
18/06/25 10:27:20 INFO CodeGenerator: Code generated in 4.830922 ms
18/06/25 10:27:20 INFO CodeGenerator: Code generated in 7.291217 ms
18/06/25 10:27:20 INFO CodeGenerator: Code generated in 6.408489 ms
18/06/25 10:27:20 INFO Executor: Finished task 0.0 in stage 23.0 (TID 29). 30393 bytes result sent to driver
18/06/25 10:27:20 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 29) in 145 ms on localhost (executor driver) (1/1)
18/06/25 10:27:20 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/06/25 10:27:20 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:196) finished in 0.146 s
18/06/25 10:27:20 INFO DAGScheduler: Job 14 finished: collect at utils.scala:196, took 0.785684 s
18/06/25 10:27:20 INFO CodeGenerator: Code generated in 6.163327 ms
18/06/25 10:27:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:27:31 INFO SparkSqlParser: Parsing command: SELECT * FROM batting LIMIT 10
18/06/25 10:27:31 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:27:31 INFO DAGScheduler: Got job 15 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:27:31 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:196)
18/06/25 10:27:31 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:27:31 INFO DAGScheduler: Missing parents: List()
18/06/25 10:27:31 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[111] at collect at utils.scala:196), which has no missing parents
18/06/25 10:27:31 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 27.6 KB, free 340.3 MB)
18/06/25 10:27:31 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.7 KB, free 340.3 MB)
18/06/25 10:27:31 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:52522 (size: 9.7 KB, free: 340.4 MB)
18/06/25 10:27:31 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
18/06/25 10:27:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[111] at collect at utils.scala:196)
18/06/25 10:27:31 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
18/06/25 10:27:31 WARN TaskSetManager: Stage 24 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 10:27:31 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814017 bytes)
18/06/25 10:27:31 INFO Executor: Running task 0.0 in stage 24.0 (TID 30)
18/06/25 10:27:31 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:52522 in memory (size: 5.7 KB, free: 340.4 MB)
18/06/25 10:27:31 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:52522 in memory (size: 9.1 KB, free: 340.4 MB)
18/06/25 10:27:31 INFO BlockManager: Found block rdd_65_0 locally
18/06/25 10:27:31 WARN Executor: 1 block locks were not released by TID = 30:
[rdd_65_0]
18/06/25 10:27:31 INFO Executor: Finished task 0.0 in stage 24.0 (TID 30). 2130 bytes result sent to driver
18/06/25 10:27:31 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 30) in 138 ms on localhost (executor driver) (1/1)
18/06/25 10:27:31 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/06/25 10:27:31 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:196) finished in 0.141 s
18/06/25 10:27:31 INFO DAGScheduler: Job 15 finished: collect at utils.scala:196, took 0.151481 s
18/06/25 10:28:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:28:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
18/06/25 10:28:03 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b5021f32769
18/06/25 10:28:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:28:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5021f32769` AS `zzz10`
WHERE (0 = 1)
18/06/25 10:28:03 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b5062a06fe8
18/06/25 10:28:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:28:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5062a06fe8` AS `zzz11`
WHERE (0 = 1)
18/06/25 10:28:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:28:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5021f32769`
18/06/25 10:28:04 INFO CodeGenerator: Code generated in 11.46281 ms
18/06/25 10:28:04 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:92
18/06/25 10:28:05 INFO DAGScheduler: Registering RDD 120 (countByValue at StringIndexer.scala:92)
18/06/25 10:28:05 INFO DAGScheduler: Got job 16 (countByValue at StringIndexer.scala:92) with 1 output partitions
18/06/25 10:28:05 INFO DAGScheduler: Final stage: ResultStage 26 (countByValue at StringIndexer.scala:92)
18/06/25 10:28:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
18/06/25 10:28:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
18/06/25 10:28:05 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[120] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 10:28:05 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 36.6 KB, free 340.3 MB)
18/06/25 10:28:05 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 14.3 KB, free 340.3 MB)
18/06/25 10:28:05 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:52522 (size: 14.3 KB, free: 340.4 MB)
18/06/25 10:28:05 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
18/06/25 10:28:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[120] at countByValue at StringIndexer.scala:92)
18/06/25 10:28:05 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
18/06/25 10:28:05 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:52522 in memory (size: 9.7 KB, free: 340.4 MB)
18/06/25 10:28:05 WARN TaskSetManager: Stage 25 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:28:05 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365299 bytes)
18/06/25 10:28:05 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
18/06/25 10:28:05 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:28:05 INFO CodeGenerator: Code generated in 17.367638 ms
18/06/25 10:28:05 INFO CodeGenerator: Code generated in 5.636068 ms
18/06/25 10:28:05 INFO CodeGenerator: Code generated in 6.161742 ms
18/06/25 10:28:06 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 2505 bytes result sent to driver
18/06/25 10:28:06 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 1447 ms on localhost (executor driver) (1/1)
18/06/25 10:28:06 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/06/25 10:28:06 INFO DAGScheduler: ShuffleMapStage 25 (countByValue at StringIndexer.scala:92) finished in 1.447 s
18/06/25 10:28:06 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:28:06 INFO DAGScheduler: running: Set()
18/06/25 10:28:06 INFO DAGScheduler: waiting: Set(ResultStage 26)
18/06/25 10:28:06 INFO DAGScheduler: failed: Set()
18/06/25 10:28:06 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRDD[121] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 10:28:06 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 3.2 KB, free 340.3 MB)
18/06/25 10:28:06 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1970.0 B, free 340.3 MB)
18/06/25 10:28:06 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:52522 (size: 1970.0 B, free: 340.4 MB)
18/06/25 10:28:06 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
18/06/25 10:28:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRDD[121] at countByValue at StringIndexer.scala:92)
18/06/25 10:28:06 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
18/06/25 10:28:06 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/06/25 10:28:06 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
18/06/25 10:28:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:28:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:28:06 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 2244 bytes result sent to driver
18/06/25 10:28:06 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 34 ms on localhost (executor driver) (1/1)
18/06/25 10:28:06 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/06/25 10:28:06 INFO DAGScheduler: ResultStage 26 (countByValue at StringIndexer.scala:92) finished in 0.034 s
18/06/25 10:28:06 INFO DAGScheduler: Job 16 finished: countByValue at StringIndexer.scala:92, took 1.989619 s
18/06/25 10:28:07 INFO CodeGenerator: Code generated in 32.018403 ms
18/06/25 10:28:07 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 10:28:07 INFO DAGScheduler: Got job 17 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 10:28:07 INFO DAGScheduler: Final stage: ResultStage 27 (first at LinearRegression.scala:198)
18/06/25 10:28:07 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:28:07 INFO DAGScheduler: Missing parents: List()
18/06/25 10:28:07 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[124] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 10:28:07 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 53.8 KB, free 340.3 MB)
18/06/25 10:28:07 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 20.2 KB, free 340.2 MB)
18/06/25 10:28:07 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:52522 (size: 20.2 KB, free: 340.4 MB)
18/06/25 10:28:07 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
18/06/25 10:28:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[124] at first at LinearRegression.scala:198)
18/06/25 10:28:07 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
18/06/25 10:28:07 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:52522 in memory (size: 1970.0 B, free: 340.4 MB)
18/06/25 10:28:07 WARN TaskSetManager: Stage 27 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:28:07 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 10:28:07 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
18/06/25 10:28:08 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:28:08 ERROR Executor: Exception in task 0.0 in stage 27.0 (TID 33)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b50fd56f03:double,air_time:double,onehot_18a7c57bec2e:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/06/25 10:28:08 WARN TaskSetManager: Lost task 0.0 in stage 27.0 (TID 33, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b50fd56f03:double,air_time:double,onehot_18a7c57bec2e:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/06/25 10:28:08 ERROR TaskSetManager: Task 0 in stage 27.0 failed 1 times; aborting job
18/06/25 10:28:08 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/06/25 10:28:08 INFO TaskSchedulerImpl: Cancelling stage 27
18/06/25 10:28:08 INFO DAGScheduler: ResultStage 27 (first at LinearRegression.scala:198) failed in 1.033 s due to Job aborted due to stage failure: Task 0 in stage 27.0 failed 1 times, most recent failure: Lost task 0.0 in stage 27.0 (TID 33, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b50fd56f03:double,air_time:double,onehot_18a7c57bec2e:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/06/25 10:28:08 INFO DAGScheduler: Job 17 failed: first at LinearRegression.scala:198, took 1.048598 s
18/06/25 10:28:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:28:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
18/06/25 10:28:39 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b5041ab5dd3
18/06/25 10:28:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:28:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5041ab5dd3` AS `zzz12`
WHERE (0 = 1)
18/06/25 10:28:39 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b50599ce953
18/06/25 10:28:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:28:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b50599ce953` AS `zzz13`
WHERE (0 = 1)
18/06/25 10:28:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:28:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5041ab5dd3`
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1575
18/06/25 10:28:39 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:52522 in memory (size: 20.2 KB, free: 340.4 MB)
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1576
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1574
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1573
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1572
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1571
18/06/25 10:28:39 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:52522 in memory (size: 14.3 KB, free: 340.4 MB)
18/06/25 10:28:39 INFO ContextCleaner: Cleaned shuffle 9
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1474
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1473
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1472
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1471
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1470
18/06/25 10:28:39 INFO ContextCleaner: Cleaned accumulator 1469
18/06/25 10:28:39 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:52522 in memory (size: 9.7 KB, free: 340.5 MB)
18/06/25 10:28:39 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:52522 in memory (size: 19.9 KB, free: 340.5 MB)
18/06/25 10:28:39 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:92
18/06/25 10:28:39 INFO DAGScheduler: Registering RDD 133 (countByValue at StringIndexer.scala:92)
18/06/25 10:28:39 INFO DAGScheduler: Got job 18 (countByValue at StringIndexer.scala:92) with 1 output partitions
18/06/25 10:28:39 INFO DAGScheduler: Final stage: ResultStage 29 (countByValue at StringIndexer.scala:92)
18/06/25 10:28:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
18/06/25 10:28:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
18/06/25 10:28:39 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[133] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 10:28:39 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 36.6 KB, free 340.4 MB)
18/06/25 10:28:39 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 14.3 KB, free 340.4 MB)
18/06/25 10:28:39 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:52522 (size: 14.3 KB, free: 340.5 MB)
18/06/25 10:28:39 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
18/06/25 10:28:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[133] at countByValue at StringIndexer.scala:92)
18/06/25 10:28:39 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
18/06/25 10:28:39 WARN TaskSetManager: Stage 28 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:28:39 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365299 bytes)
18/06/25 10:28:39 INFO Executor: Running task 0.0 in stage 28.0 (TID 34)
18/06/25 10:28:39 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:28:40 INFO Executor: Finished task 0.0 in stage 28.0 (TID 34). 2505 bytes result sent to driver
18/06/25 10:28:40 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 34) in 736 ms on localhost (executor driver) (1/1)
18/06/25 10:28:40 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/06/25 10:28:40 INFO DAGScheduler: ShuffleMapStage 28 (countByValue at StringIndexer.scala:92) finished in 0.736 s
18/06/25 10:28:40 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:28:40 INFO DAGScheduler: running: Set()
18/06/25 10:28:40 INFO DAGScheduler: waiting: Set(ResultStage 29)
18/06/25 10:28:40 INFO DAGScheduler: failed: Set()
18/06/25 10:28:40 INFO DAGScheduler: Submitting ResultStage 29 (ShuffledRDD[134] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 10:28:40 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.2 KB, free 340.4 MB)
18/06/25 10:28:40 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1970.0 B, free 340.4 MB)
18/06/25 10:28:40 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:52522 (size: 1970.0 B, free: 340.5 MB)
18/06/25 10:28:40 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
18/06/25 10:28:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (ShuffledRDD[134] at countByValue at StringIndexer.scala:92)
18/06/25 10:28:40 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
18/06/25 10:28:40 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 35, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/06/25 10:28:40 INFO Executor: Running task 0.0 in stage 29.0 (TID 35)
18/06/25 10:28:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:28:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:28:40 INFO Executor: Finished task 0.0 in stage 29.0 (TID 35). 2244 bytes result sent to driver
18/06/25 10:28:40 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 35) in 8 ms on localhost (executor driver) (1/1)
18/06/25 10:28:40 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/06/25 10:28:40 INFO DAGScheduler: ResultStage 29 (countByValue at StringIndexer.scala:92) finished in 0.010 s
18/06/25 10:28:40 INFO DAGScheduler: Job 18 finished: countByValue at StringIndexer.scala:92, took 0.761811 s
18/06/25 10:28:40 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:52522 in memory (size: 1970.0 B, free: 340.5 MB)
18/06/25 10:28:40 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 10:28:40 INFO DAGScheduler: Got job 19 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 10:28:40 INFO DAGScheduler: Final stage: ResultStage 30 (first at LinearRegression.scala:198)
18/06/25 10:28:40 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:28:40 INFO DAGScheduler: Missing parents: List()
18/06/25 10:28:40 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[137] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 10:28:40 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 53.8 KB, free 340.4 MB)
18/06/25 10:28:40 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 20.1 KB, free 340.4 MB)
18/06/25 10:28:40 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:52522 (size: 20.1 KB, free: 340.4 MB)
18/06/25 10:28:40 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
18/06/25 10:28:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[137] at first at LinearRegression.scala:198)
18/06/25 10:28:40 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
18/06/25 10:28:40 WARN TaskSetManager: Stage 30 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:28:40 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 10:28:40 INFO Executor: Running task 0.0 in stage 30.0 (TID 36)
18/06/25 10:28:40 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:28:41 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:52522 in memory (size: 14.3 KB, free: 340.5 MB)
18/06/25 10:28:41 INFO ContextCleaner: Cleaned shuffle 10
18/06/25 10:28:41 INFO ContextCleaner: Cleaned accumulator 1630
18/06/25 10:28:41 INFO ContextCleaner: Cleaned accumulator 1629
18/06/25 10:28:41 INFO ContextCleaner: Cleaned accumulator 1628
18/06/25 10:28:41 INFO ContextCleaner: Cleaned accumulator 1627
18/06/25 10:28:41 INFO ContextCleaner: Cleaned accumulator 1626
18/06/25 10:28:41 INFO ContextCleaner: Cleaned accumulator 1625
18/06/25 10:28:41 ERROR Executor: Exception in task 0.0 in stage 30.0 (TID 36)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b507d7705bd:double,air_time:double,onehot_85e49ac2fd9b:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/06/25 10:28:41 WARN TaskSetManager: Lost task 0.0 in stage 30.0 (TID 36, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b507d7705bd:double,air_time:double,onehot_85e49ac2fd9b:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/06/25 10:28:41 ERROR TaskSetManager: Task 0 in stage 30.0 failed 1 times; aborting job
18/06/25 10:28:41 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/06/25 10:28:41 INFO TaskSchedulerImpl: Cancelling stage 30
18/06/25 10:28:41 INFO DAGScheduler: ResultStage 30 (first at LinearRegression.scala:198) failed in 0.866 s due to Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 36, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b507d7705bd:double,air_time:double,onehot_85e49ac2fd9b:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/06/25 10:28:41 INFO DAGScheduler: Job 19 failed: first at LinearRegression.scala:198, took 0.870397 s
18/06/25 10:30:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:30:01 INFO SparkSqlParser: Parsing command: SELECT * FROM flights LIMIT 1000
18/06/25 10:30:01 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:30:01 INFO DAGScheduler: Got job 20 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:30:01 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:196)
18/06/25 10:30:01 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:30:01 INFO DAGScheduler: Missing parents: List()
18/06/25 10:30:01 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[139] at collect at utils.scala:196), which has no missing parents
18/06/25 10:30:01 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 26.4 KB, free 340.4 MB)
18/06/25 10:30:01 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.7 KB, free 340.4 MB)
18/06/25 10:30:01 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:52522 (size: 9.7 KB, free: 340.4 MB)
18/06/25 10:30:01 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
18/06/25 10:30:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[139] at collect at utils.scala:196)
18/06/25 10:30:01 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
18/06/25 10:30:02 WARN TaskSetManager: Stage 31 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:30:02 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 10:30:02 INFO Executor: Running task 0.0 in stage 31.0 (TID 37)
18/06/25 10:30:02 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:30:02 WARN Executor: 1 block locks were not released by TID = 37:
[rdd_39_0]
18/06/25 10:30:02 INFO Executor: Finished task 0.0 in stage 31.0 (TID 37). 60938 bytes result sent to driver
18/06/25 10:30:02 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 37) in 400 ms on localhost (executor driver) (1/1)
18/06/25 10:30:02 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/06/25 10:30:02 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:196) finished in 0.400 s
18/06/25 10:30:02 INFO DAGScheduler: Job 20 finished: collect at utils.scala:196, took 0.411347 s
18/06/25 10:44:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:44:39 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:44:39 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:44:39 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:44:39 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:44:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:44:39 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:44:39 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 10:44:39 INFO DAGScheduler: Got job 21 (collect at utils.scala:43) with 1 output partitions
18/06/25 10:44:39 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:43)
18/06/25 10:44:39 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:44:39 INFO DAGScheduler: Missing parents: List()
18/06/25 10:44:39 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[145] at map at utils.scala:40), which has no missing parents
18/06/25 10:44:39 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 8.7 KB, free 340.4 MB)
18/06/25 10:44:39 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.6 KB, free 340.4 MB)
18/06/25 10:44:39 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:52522 (size: 4.6 KB, free: 340.4 MB)
18/06/25 10:44:39 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[145] at map at utils.scala:40)
18/06/25 10:44:39 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
18/06/25 10:44:39 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 6750 bytes)
18/06/25 10:44:39 INFO Executor: Running task 0.0 in stage 32.0 (TID 38)
18/06/25 10:44:39 INFO Executor: Finished task 0.0 in stage 32.0 (TID 38). 1457 bytes result sent to driver
18/06/25 10:44:39 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 38) in 14 ms on localhost (executor driver) (1/1)
18/06/25 10:44:39 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/06/25 10:44:39 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:43) finished in 0.014 s
18/06/25 10:44:39 INFO DAGScheduler: Job 21 finished: collect at utils.scala:43, took 0.040670 s
18/06/25 10:44:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:39 INFO SparkSqlParser: Parsing command: mtcars
18/06/25 10:44:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:39 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
18/06/25 10:44:39 INFO SparkSqlParser: Parsing command: `mtcars`
18/06/25 10:44:39 INFO SparkContext: Starting job: sql at <unknown>:0
18/06/25 10:44:39 INFO DAGScheduler: Registering RDD 154 (sql at <unknown>:0)
18/06/25 10:44:39 INFO DAGScheduler: Got job 22 (sql at <unknown>:0) with 1 output partitions
18/06/25 10:44:39 INFO DAGScheduler: Final stage: ResultStage 34 (sql at <unknown>:0)
18/06/25 10:44:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
18/06/25 10:44:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
18/06/25 10:44:39 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[154] at sql at <unknown>:0), which has no missing parents
18/06/25 10:44:39 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 22.5 KB, free 340.3 MB)
18/06/25 10:44:39 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 9.4 KB, free 340.3 MB)
18/06/25 10:44:39 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:52522 (size: 9.4 KB, free: 340.4 MB)
18/06/25 10:44:39 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[154] at sql at <unknown>:0)
18/06/25 10:44:39 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
18/06/25 10:44:39 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 7345 bytes)
18/06/25 10:44:39 INFO Executor: Running task 0.0 in stage 33.0 (TID 39)
18/06/25 10:44:39 INFO CodeGenerator: Code generated in 21.374843 ms
18/06/25 10:44:40 INFO CodeGenerator: Code generated in 53.562152 ms
18/06/25 10:44:40 INFO MemoryStore: Block rdd_151_0 stored as values in memory (estimated size 4.2 KB, free 340.3 MB)
18/06/25 10:44:40 INFO BlockManagerInfo: Added rdd_151_0 in memory on 127.0.0.1:52522 (size: 4.2 KB, free: 340.4 MB)
18/06/25 10:44:40 INFO Executor: Finished task 0.0 in stage 33.0 (TID 39). 2660 bytes result sent to driver
18/06/25 10:44:40 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 39) in 118 ms on localhost (executor driver) (1/1)
18/06/25 10:44:40 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/06/25 10:44:40 INFO DAGScheduler: ShuffleMapStage 33 (sql at <unknown>:0) finished in 0.119 s
18/06/25 10:44:40 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:44:40 INFO DAGScheduler: running: Set()
18/06/25 10:44:40 INFO DAGScheduler: waiting: Set(ResultStage 34)
18/06/25 10:44:40 INFO DAGScheduler: failed: Set()
18/06/25 10:44:40 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[157] at sql at <unknown>:0), which has no missing parents
18/06/25 10:44:40 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.0 KB, free 340.3 MB)
18/06/25 10:44:40 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.3 MB)
18/06/25 10:44:40 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 340.4 MB)
18/06/25 10:44:40 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[157] at sql at <unknown>:0)
18/06/25 10:44:40 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
18/06/25 10:44:40 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 40, localhost, executor driver, partition 0, ANY, 5955 bytes)
18/06/25 10:44:40 INFO Executor: Running task 0.0 in stage 34.0 (TID 40)
18/06/25 10:44:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:44:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 10:44:40 INFO Executor: Finished task 0.0 in stage 34.0 (TID 40). 2042 bytes result sent to driver
18/06/25 10:44:40 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 40) in 9 ms on localhost (executor driver) (1/1)
18/06/25 10:44:40 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/06/25 10:44:40 INFO DAGScheduler: ResultStage 34 (sql at <unknown>:0) finished in 0.010 s
18/06/25 10:44:40 INFO DAGScheduler: Job 22 finished: sql at <unknown>:0, took 0.164219 s
18/06/25 10:44:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
18/06/25 10:44:40 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 10:44:40 INFO DAGScheduler: Registering RDD 161 (collect at utils.scala:196)
18/06/25 10:44:40 INFO DAGScheduler: Got job 23 (collect at utils.scala:196) with 1 output partitions
18/06/25 10:44:40 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:196)
18/06/25 10:44:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
18/06/25 10:44:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
18/06/25 10:44:40 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[161] at collect at utils.scala:196), which has no missing parents
18/06/25 10:44:40 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 22.5 KB, free 340.3 MB)
18/06/25 10:44:40 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 9.4 KB, free 340.3 MB)
18/06/25 10:44:40 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:52522 (size: 9.4 KB, free: 340.4 MB)
18/06/25 10:44:40 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[161] at collect at utils.scala:196)
18/06/25 10:44:40 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
18/06/25 10:44:40 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 7337 bytes)
18/06/25 10:44:40 INFO Executor: Running task 0.0 in stage 35.0 (TID 41)
18/06/25 10:44:40 INFO BlockManager: Found block rdd_151_0 locally
18/06/25 10:44:40 INFO Executor: Finished task 0.0 in stage 35.0 (TID 41). 2098 bytes result sent to driver
18/06/25 10:44:40 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 41) in 12 ms on localhost (executor driver) (1/1)
18/06/25 10:44:40 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/06/25 10:44:40 INFO DAGScheduler: ShuffleMapStage 35 (collect at utils.scala:196) finished in 0.012 s
18/06/25 10:44:40 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:44:40 INFO DAGScheduler: running: Set()
18/06/25 10:44:40 INFO DAGScheduler: waiting: Set(ResultStage 36)
18/06/25 10:44:40 INFO DAGScheduler: failed: Set()
18/06/25 10:44:40 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[164] at collect at utils.scala:196), which has no missing parents
18/06/25 10:44:40 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.0 KB, free 340.3 MB)
18/06/25 10:44:40 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.3 MB)
18/06/25 10:44:40 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 340.4 MB)
18/06/25 10:44:40 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[164] at collect at utils.scala:196)
18/06/25 10:44:40 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
18/06/25 10:44:40 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 42, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 10:44:40 INFO Executor: Running task 0.0 in stage 36.0 (TID 42)
18/06/25 10:44:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:44:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:44:40 INFO Executor: Finished task 0.0 in stage 36.0 (TID 42). 2042 bytes result sent to driver
18/06/25 10:44:40 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 42) in 5 ms on localhost (executor driver) (1/1)
18/06/25 10:44:40 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/06/25 10:44:40 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:196) finished in 0.006 s
18/06/25 10:44:40 INFO DAGScheduler: Job 23 finished: collect at utils.scala:196, took 0.057151 s
18/06/25 10:44:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz14`
WHERE (0 = 1)
18/06/25 10:44:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: SELECT `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, `cyl` = 8.0 AS `cyl8`
FROM `mtcars`
WHERE (`hp` >= 100.0)
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b5040d81668
18/06/25 10:44:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5040d81668` AS `zzz15`
WHERE (0 = 1)
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b502aa7271a
18/06/25 10:44:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b502aa7271a` AS `zzz16`
WHERE (0 = 1)
18/06/25 10:44:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 10:44:40 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:44:40 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:44:40 INFO HiveMetaStore: 0: get_database: default
18/06/25 10:44:40 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 10:44:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 10:44:40 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 10:44:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5040d81668`
18/06/25 10:44:41 INFO InMemoryTableScanExec: Predicate isnotnull(hp#3274) generates partition filter: ((hp.count#3701 - hp.nullCount#3700) > 0)
18/06/25 10:44:41 INFO InMemoryTableScanExec: Predicate (hp#3274 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#3698)
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 44.938691 ms
18/06/25 10:44:41 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 10:44:41 INFO DAGScheduler: Got job 24 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 10:44:41 INFO DAGScheduler: Final stage: ResultStage 37 (first at LinearRegression.scala:198)
18/06/25 10:44:41 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:44:41 INFO DAGScheduler: Missing parents: List()
18/06/25 10:44:41 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[170] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 40.9 KB, free 340.2 MB)
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 16.2 KB, free 340.2 MB)
18/06/25 10:44:41 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:52522 (size: 16.2 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[170] at first at LinearRegression.scala:198)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
18/06/25 10:44:41 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 7262 bytes)
18/06/25 10:44:41 INFO Executor: Running task 0.0 in stage 37.0 (TID 43)
18/06/25 10:44:41 INFO BlockManager: Found block rdd_151_0 locally
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 10.726919 ms
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 23.243577 ms
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 21.584585 ms
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 11.19129 ms
18/06/25 10:44:41 INFO Executor: Finished task 0.0 in stage 37.0 (TID 43). 2094 bytes result sent to driver
18/06/25 10:44:41 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 43) in 102 ms on localhost (executor driver) (1/1)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/06/25 10:44:41 INFO DAGScheduler: ResultStage 37 (first at LinearRegression.scala:198) finished in 0.103 s
18/06/25 10:44:41 INFO DAGScheduler: Job 24 finished: first at LinearRegression.scala:198, took 0.120664 s
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 8.480518 ms
18/06/25 10:44:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:52522 in memory (size: 9.4 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 2100
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 2101
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 2102
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 2103
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 2104
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 2105
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 2106
18/06/25 10:44:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:52522 in memory (size: 16.2 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:52522 in memory (size: 4.6 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1882
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1883
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1884
18/06/25 10:44:41 INFO InMemoryTableScanExec: Predicate isnotnull(hp#3274) generates partition filter: ((hp.count#3762 - hp.nullCount#3761) > 0)
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1885
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1886
18/06/25 10:44:41 INFO InMemoryTableScanExec: Predicate (hp#3274 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#3759)
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1887
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1888
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1889
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1890
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1891
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1892
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1893
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1894
18/06/25 10:44:41 INFO ContextCleaner: Cleaned shuffle 11
18/06/25 10:44:41 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:52522 in memory (size: 9.4 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO ContextCleaner: Cleaned accumulator 1991
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 26.72295 ms
18/06/25 10:44:41 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
18/06/25 10:44:41 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
18/06/25 10:44:41 INFO DAGScheduler: Got job 25 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
18/06/25 10:44:41 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 10:44:41 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:44:41 INFO DAGScheduler: Missing parents: List()
18/06/25 10:44:41 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[176] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 43.8 KB, free 340.3 MB)
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 17.4 KB, free 340.3 MB)
18/06/25 10:44:41 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:52522 (size: 17.4 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[176] at treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
18/06/25 10:44:41 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 7324 bytes)
18/06/25 10:44:41 INFO Executor: Running task 0.0 in stage 38.0 (TID 44)
18/06/25 10:44:41 INFO BlockManager: Found block rdd_151_0 locally
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 4.054997 ms
18/06/25 10:44:41 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/06/25 10:44:41 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/06/25 10:44:41 INFO Executor: Finished task 0.0 in stage 38.0 (TID 44). 2579 bytes result sent to driver
18/06/25 10:44:41 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 44) in 46 ms on localhost (executor driver) (1/1)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/06/25 10:44:41 INFO DAGScheduler: ResultStage 38 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.047 s
18/06/25 10:44:41 INFO DAGScheduler: Job 25 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.052610 s
18/06/25 10:44:41 INFO WeightedLeastSquares: Number of instances: 8.
18/06/25 10:44:41 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
18/06/25 10:44:41 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
18/06/25 10:44:41 INFO InMemoryTableScanExec: Predicate isnotnull(hp#3274) generates partition filter: ((hp.count#3839 - hp.nullCount#3838) > 0)
18/06/25 10:44:41 INFO InMemoryTableScanExec: Predicate (hp#3274 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#3836)
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 19.217089 ms
18/06/25 10:44:41 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
18/06/25 10:44:41 INFO DAGScheduler: Got job 26 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
18/06/25 10:44:41 INFO DAGScheduler: Final stage: ResultStage 39 (aggregate at RegressionMetrics.scala:57)
18/06/25 10:44:41 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:44:41 INFO DAGScheduler: Missing parents: List()
18/06/25 10:44:41 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[182] at map at RegressionMetrics.scala:55), which has no missing parents
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 44.0 KB, free 340.3 MB)
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.8 KB, free 340.2 MB)
18/06/25 10:44:41 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:52522 (size: 17.8 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[182] at map at RegressionMetrics.scala:55)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
18/06/25 10:44:41 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 7320 bytes)
18/06/25 10:44:41 INFO Executor: Running task 0.0 in stage 39.0 (TID 45)
18/06/25 10:44:41 INFO BlockManager: Found block rdd_151_0 locally
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 6.107167 ms
18/06/25 10:44:41 INFO Executor: Finished task 0.0 in stage 39.0 (TID 45). 2531 bytes result sent to driver
18/06/25 10:44:41 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 45) in 46 ms on localhost (executor driver) (1/1)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/06/25 10:44:41 INFO DAGScheduler: ResultStage 39 (aggregate at RegressionMetrics.scala:57) finished in 0.048 s
18/06/25 10:44:41 INFO DAGScheduler: Job 26 finished: aggregate at RegressionMetrics.scala:57, took 0.057914 s
18/06/25 10:44:41 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
18/06/25 10:44:41 INFO DAGScheduler: Got job 27 (sum at RegressionMetrics.scala:71) with 1 output partitions
18/06/25 10:44:41 INFO DAGScheduler: Final stage: ResultStage 40 (sum at RegressionMetrics.scala:71)
18/06/25 10:44:41 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:44:41 INFO DAGScheduler: Missing parents: List()
18/06/25 10:44:41 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[183] at map at RegressionMetrics.scala:69), which has no missing parents
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 43.7 KB, free 340.2 MB)
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 17.7 KB, free 340.2 MB)
18/06/25 10:44:41 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:52522 (size: 17.7 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[183] at map at RegressionMetrics.scala:69)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
18/06/25 10:44:41 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7314 bytes)
18/06/25 10:44:41 INFO Executor: Running task 0.0 in stage 40.0 (TID 46)
18/06/25 10:44:41 INFO BlockManager: Found block rdd_151_0 locally
18/06/25 10:44:41 INFO Executor: Finished task 0.0 in stage 40.0 (TID 46). 2048 bytes result sent to driver
18/06/25 10:44:41 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 46) in 10 ms on localhost (executor driver) (1/1)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/06/25 10:44:41 INFO DAGScheduler: ResultStage 40 (sum at RegressionMetrics.scala:71) finished in 0.010 s
18/06/25 10:44:41 INFO DAGScheduler: Job 27 finished: sum at RegressionMetrics.scala:71, took 0.017925 s
18/06/25 10:44:41 INFO InMemoryTableScanExec: Predicate isnotnull(hp#3274) generates partition filter: ((hp.count#3914 - hp.nullCount#3913) > 0)
18/06/25 10:44:41 INFO InMemoryTableScanExec: Predicate (hp#3274 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#3911)
18/06/25 10:44:41 INFO CodeGenerator: Code generated in 16.871271 ms
18/06/25 10:44:41 INFO SparkContext: Starting job: count at LinearRegression.scala:683
18/06/25 10:44:41 INFO DAGScheduler: Registering RDD 186 (count at LinearRegression.scala:683)
18/06/25 10:44:41 INFO DAGScheduler: Got job 28 (count at LinearRegression.scala:683) with 1 output partitions
18/06/25 10:44:41 INFO DAGScheduler: Final stage: ResultStage 42 (count at LinearRegression.scala:683)
18/06/25 10:44:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
18/06/25 10:44:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
18/06/25 10:44:41 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[186] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 36.5 KB, free 340.1 MB)
18/06/25 10:44:41 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 14.7 KB, free 340.1 MB)
18/06/25 10:44:41 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:52522 (size: 14.7 KB, free: 340.4 MB)
18/06/25 10:44:41 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[186] at count at LinearRegression.scala:683)
18/06/25 10:44:41 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
18/06/25 10:44:41 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7337 bytes)
18/06/25 10:44:41 INFO Executor: Running task 0.0 in stage 41.0 (TID 47)
18/06/25 10:44:41 INFO BlockManager: Found block rdd_151_0 locally
18/06/25 10:44:41 INFO Executor: Finished task 0.0 in stage 41.0 (TID 47). 2766 bytes result sent to driver
18/06/25 10:44:41 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 47) in 15 ms on localhost (executor driver) (1/1)
18/06/25 10:44:41 INFO DAGScheduler: ShuffleMapStage 41 (count at LinearRegression.scala:683) finished in 0.015 s
18/06/25 10:44:42 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:44:42 INFO DAGScheduler: running: Set()
18/06/25 10:44:42 INFO DAGScheduler: waiting: Set(ResultStage 42)
18/06/25 10:44:42 INFO DAGScheduler: failed: Set()
18/06/25 10:44:42 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[189] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 10:44:42 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 7.0 KB, free 340.1 MB)
18/06/25 10:44:42 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.1 MB)
18/06/25 10:44:42 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/06/25 10:44:42 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:52522 (size: 3.7 KB, free: 340.4 MB)
18/06/25 10:44:42 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[189] at count at LinearRegression.scala:683)
18/06/25 10:44:42 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
18/06/25 10:44:42 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 48, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 10:44:42 INFO Executor: Running task 0.0 in stage 42.0 (TID 48)
18/06/25 10:44:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:44:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:44:42 INFO Executor: Finished task 0.0 in stage 42.0 (TID 48). 2042 bytes result sent to driver
18/06/25 10:44:42 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 48) in 6 ms on localhost (executor driver) (1/1)
18/06/25 10:44:42 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/06/25 10:44:42 INFO DAGScheduler: ResultStage 42 (count at LinearRegression.scala:683) finished in 0.006 s
18/06/25 10:44:42 INFO DAGScheduler: Job 28 finished: count at LinearRegression.scala:683, took 0.034382 s
18/06/25 10:44:42 INFO InMemoryTableScanExec: Predicate isnotnull(hp#3274) generates partition filter: ((hp.count#3982 - hp.nullCount#3981) > 0)
18/06/25 10:44:42 INFO InMemoryTableScanExec: Predicate (hp#3274 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#3979)
18/06/25 10:44:42 INFO CodeGenerator: Code generated in 13.295141 ms
18/06/25 10:44:42 INFO CodeGenerator: Code generated in 32.583659 ms
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2313
18/06/25 10:44:42 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:52522 in memory (size: 14.7 KB, free: 340.4 MB)
18/06/25 10:44:42 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:52522 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2427
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2155
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2156
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2157
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2158
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2159
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2160
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2161
18/06/25 10:44:42 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:52522 in memory (size: 17.4 KB, free: 340.4 MB)
18/06/25 10:44:42 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:52522 in memory (size: 17.8 KB, free: 340.4 MB)
18/06/25 10:44:42 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:52522 in memory (size: 17.7 KB, free: 340.4 MB)
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2314
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2315
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2316
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2317
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2318
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2319
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2320
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2321
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2322
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2323
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2324
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2325
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2326
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2327
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2328
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2329
18/06/25 10:44:42 INFO ContextCleaner: Cleaned accumulator 2330
18/06/25 10:44:42 INFO ContextCleaner: Cleaned shuffle 13
18/06/25 10:44:42 INFO SparkContext: Starting job: first at LinearRegression.scala:707
18/06/25 10:44:42 INFO DAGScheduler: Registering RDD 192 (first at LinearRegression.scala:707)
18/06/25 10:44:42 INFO DAGScheduler: Got job 29 (first at LinearRegression.scala:707) with 1 output partitions
18/06/25 10:44:42 INFO DAGScheduler: Final stage: ResultStage 44 (first at LinearRegression.scala:707)
18/06/25 10:44:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
18/06/25 10:44:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
18/06/25 10:44:42 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[192] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 10:44:42 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 50.8 KB, free 340.3 MB)
18/06/25 10:44:42 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 20.7 KB, free 340.3 MB)
18/06/25 10:44:42 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:52522 (size: 20.7 KB, free: 340.4 MB)
18/06/25 10:44:42 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[192] at first at LinearRegression.scala:707)
18/06/25 10:44:42 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
18/06/25 10:44:42 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 7251 bytes)
18/06/25 10:44:42 INFO Executor: Running task 0.0 in stage 43.0 (TID 49)
18/06/25 10:44:42 INFO BlockManager: Found block rdd_151_0 locally
18/06/25 10:44:42 INFO Executor: Finished task 0.0 in stage 43.0 (TID 49). 2766 bytes result sent to driver
18/06/25 10:44:42 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 49) in 14 ms on localhost (executor driver) (1/1)
18/06/25 10:44:42 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/06/25 10:44:42 INFO DAGScheduler: ShuffleMapStage 43 (first at LinearRegression.scala:707) finished in 0.015 s
18/06/25 10:44:42 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:44:42 INFO DAGScheduler: running: Set()
18/06/25 10:44:42 INFO DAGScheduler: waiting: Set(ResultStage 44)
18/06/25 10:44:42 INFO DAGScheduler: failed: Set()
18/06/25 10:44:42 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[195] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 10:44:42 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 7.9 KB, free 340.3 MB)
18/06/25 10:44:42 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 4.0 KB, free 340.3 MB)
18/06/25 10:44:42 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:52522 (size: 4.0 KB, free: 340.4 MB)
18/06/25 10:44:42 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
18/06/25 10:44:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[195] at first at LinearRegression.scala:707)
18/06/25 10:44:42 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
18/06/25 10:44:42 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 50, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/06/25 10:44:42 INFO Executor: Running task 0.0 in stage 44.0 (TID 50)
18/06/25 10:44:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:44:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:44:42 INFO Executor: Finished task 0.0 in stage 44.0 (TID 50). 2027 bytes result sent to driver
18/06/25 10:44:42 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 50) in 7 ms on localhost (executor driver) (1/1)
18/06/25 10:44:42 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/06/25 10:44:42 INFO DAGScheduler: ResultStage 44 (first at LinearRegression.scala:707) finished in 0.007 s
18/06/25 10:44:42 INFO DAGScheduler: Job 29 finished: first at LinearRegression.scala:707, took 0.033203 s
18/06/25 10:44:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b5075d5899a
18/06/25 10:44:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5075d5899a` AS `zzz17`
WHERE (0 = 1)
18/06/25 10:44:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b50163d19e6
18/06/25 10:44:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b50163d19e6` AS `zzz18`
WHERE (0 = 1)
18/06/25 10:44:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5040d81668`
18/06/25 10:44:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b5056f5672
18/06/25 10:44:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5056f5672` AS `zzz19`
WHERE (0 = 1)
18/06/25 10:44:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:44:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5056f5672`
18/06/25 10:45:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:45:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
18/06/25 10:45:18 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b5050945927
18/06/25 10:45:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:45:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5050945927` AS `zzz20`
WHERE (0 = 1)
18/06/25 10:45:18 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b503b6938c5
18/06/25 10:45:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:45:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b503b6938c5` AS `zzz21`
WHERE (0 = 1)
18/06/25 10:45:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:45:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b5050945927`
18/06/25 10:45:18 INFO CodeGenerator: Code generated in 18.846553 ms
18/06/25 10:45:18 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 10:45:18 INFO DAGScheduler: Got job 30 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 10:45:18 INFO DAGScheduler: Final stage: ResultStage 45 (first at LinearRegression.scala:198)
18/06/25 10:45:18 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:45:18 INFO DAGScheduler: Missing parents: List()
18/06/25 10:45:18 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[203] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 10:45:18 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 43.4 KB, free 340.2 MB)
18/06/25 10:45:18 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 16.7 KB, free 340.2 MB)
18/06/25 10:45:18 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:52522 (size: 16.7 KB, free: 340.4 MB)
18/06/25 10:45:18 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
18/06/25 10:45:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[203] at first at LinearRegression.scala:198)
18/06/25 10:45:18 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
18/06/25 10:45:18 INFO ContextCleaner: Cleaned shuffle 14
18/06/25 10:45:18 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:52522 in memory (size: 20.7 KB, free: 340.4 MB)
18/06/25 10:45:18 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:52522 in memory (size: 4.0 KB, free: 340.4 MB)
18/06/25 10:45:18 WARN TaskSetManager: Stage 45 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:45:18 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 10:45:18 INFO Executor: Running task 0.0 in stage 45.0 (TID 51)
18/06/25 10:45:18 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:45:19 ERROR Executor: Exception in task 0.0 in stage 45.0 (TID 51)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b50e75427b:double,air_time:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/06/25 10:45:19 WARN TaskSetManager: Lost task 0.0 in stage 45.0 (TID 51, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b50e75427b:double,air_time:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/06/25 10:45:19 ERROR TaskSetManager: Task 0 in stage 45.0 failed 1 times; aborting job
18/06/25 10:45:19 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/06/25 10:45:19 INFO TaskSchedulerImpl: Cancelling stage 45
18/06/25 10:45:19 INFO DAGScheduler: ResultStage 45 (first at LinearRegression.scala:198) failed in 0.692 s due to Job aborted due to stage failure: Task 0 in stage 45.0 failed 1 times, most recent failure: Lost task 0.0 in stage 45.0 (TID 51, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b50e75427b:double,air_time:double>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/06/25 10:45:19 INFO DAGScheduler: Job 30 failed: first at LinearRegression.scala:198, took 0.701663 s
18/06/25 10:45:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:45:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
18/06/25 10:45:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b50722c4ecd
18/06/25 10:45:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:45:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b50722c4ecd` AS `zzz22`
WHERE (0 = 1)
18/06/25 10:45:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b503ae9af4a
18/06/25 10:45:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:45:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b503ae9af4a` AS `zzz23`
WHERE (0 = 1)
18/06/25 10:45:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:45:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b50722c4ecd`
18/06/25 10:45:29 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:92
18/06/25 10:45:29 INFO DAGScheduler: Registering RDD 212 (countByValue at StringIndexer.scala:92)
18/06/25 10:45:29 INFO DAGScheduler: Got job 31 (countByValue at StringIndexer.scala:92) with 1 output partitions
18/06/25 10:45:29 INFO DAGScheduler: Final stage: ResultStage 47 (countByValue at StringIndexer.scala:92)
18/06/25 10:45:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
18/06/25 10:45:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
18/06/25 10:45:29 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[212] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 10:45:29 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 36.6 KB, free 340.3 MB)
18/06/25 10:45:29 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 14.3 KB, free 340.3 MB)
18/06/25 10:45:29 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:52522 (size: 14.3 KB, free: 340.4 MB)
18/06/25 10:45:29 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
18/06/25 10:45:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[212] at countByValue at StringIndexer.scala:92)
18/06/25 10:45:29 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
18/06/25 10:45:29 WARN TaskSetManager: Stage 46 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:45:29 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365299 bytes)
18/06/25 10:45:29 INFO Executor: Running task 0.0 in stage 46.0 (TID 52)
18/06/25 10:45:30 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 1727
18/06/25 10:45:30 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:52522 in memory (size: 16.7 KB, free: 340.4 MB)
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2546
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2545
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2544
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2543
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2542
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2541
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2444
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2443
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2442
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2441
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2440
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2439
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2438
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2437
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2436
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2435
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2434
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2433
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2432
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2431
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2430
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2429
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 2428
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 1831
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 1830
18/06/25 10:45:30 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:52522 in memory (size: 9.7 KB, free: 340.4 MB)
18/06/25 10:45:30 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:52522 in memory (size: 20.1 KB, free: 340.5 MB)
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 1732
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 1731
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 1730
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 1729
18/06/25 10:45:30 INFO ContextCleaner: Cleaned accumulator 1728
18/06/25 10:45:30 INFO Executor: Finished task 0.0 in stage 46.0 (TID 52). 2505 bytes result sent to driver
18/06/25 10:45:30 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 52) in 1151 ms on localhost (executor driver) (1/1)
18/06/25 10:45:30 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
18/06/25 10:45:30 INFO DAGScheduler: ShuffleMapStage 46 (countByValue at StringIndexer.scala:92) finished in 1.151 s
18/06/25 10:45:30 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:45:30 INFO DAGScheduler: running: Set()
18/06/25 10:45:30 INFO DAGScheduler: waiting: Set(ResultStage 47)
18/06/25 10:45:30 INFO DAGScheduler: failed: Set()
18/06/25 10:45:30 INFO DAGScheduler: Submitting ResultStage 47 (ShuffledRDD[213] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 10:45:30 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 3.2 KB, free 340.4 MB)
18/06/25 10:45:30 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1970.0 B, free 340.4 MB)
18/06/25 10:45:30 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:52522 (size: 1970.0 B, free: 340.5 MB)
18/06/25 10:45:30 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
18/06/25 10:45:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (ShuffledRDD[213] at countByValue at StringIndexer.scala:92)
18/06/25 10:45:30 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
18/06/25 10:45:30 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 53, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/06/25 10:45:30 INFO Executor: Running task 0.0 in stage 47.0 (TID 53)
18/06/25 10:45:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:45:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:45:30 INFO Executor: Finished task 0.0 in stage 47.0 (TID 53). 2244 bytes result sent to driver
18/06/25 10:45:30 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 53) in 11 ms on localhost (executor driver) (1/1)
18/06/25 10:45:30 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/06/25 10:45:30 INFO DAGScheduler: ResultStage 47 (countByValue at StringIndexer.scala:92) finished in 0.011 s
18/06/25 10:45:30 INFO DAGScheduler: Job 31 finished: countByValue at StringIndexer.scala:92, took 1.175782 s
18/06/25 10:45:31 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 10:45:31 INFO DAGScheduler: Got job 32 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 10:45:31 INFO DAGScheduler: Final stage: ResultStage 48 (first at LinearRegression.scala:198)
18/06/25 10:45:31 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:45:31 INFO DAGScheduler: Missing parents: List()
18/06/25 10:45:31 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[216] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 10:45:31 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 53.8 KB, free 340.4 MB)
18/06/25 10:45:31 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 20.2 KB, free 340.3 MB)
18/06/25 10:45:31 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:52522 (size: 20.2 KB, free: 340.4 MB)
18/06/25 10:45:31 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
18/06/25 10:45:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[216] at first at LinearRegression.scala:198)
18/06/25 10:45:31 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
18/06/25 10:45:31 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:52522 in memory (size: 1970.0 B, free: 340.4 MB)
18/06/25 10:45:31 WARN TaskSetManager: Stage 48 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:45:31 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 10:45:31 INFO Executor: Running task 0.0 in stage 48.0 (TID 54)
18/06/25 10:45:31 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:45:31 ERROR Executor: Exception in task 0.0 in stage 48.0 (TID 54)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b506ce5719c:double,air_time:double,onehot_f5a6dcab5a4f:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more
18/06/25 10:45:31 WARN TaskSetManager: Lost task 0.0 in stage 48.0 (TID 54, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b506ce5719c:double,air_time:double,onehot_f5a6dcab5a4f:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

18/06/25 10:45:31 ERROR TaskSetManager: Task 0 in stage 48.0 failed 1 times; aborting job
18/06/25 10:45:31 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/06/25 10:45:31 INFO TaskSchedulerImpl: Cancelling stage 48
18/06/25 10:45:31 INFO DAGScheduler: ResultStage 48 (first at LinearRegression.scala:198) failed in 0.587 s due to Job aborted due to stage failure: Task 0 in stage 48.0 failed 1 times, most recent failure: Lost task 0.0 in stage 48.0 (TID 54, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b506ce5719c:double,air_time:double,onehot_f5a6dcab5a4f:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 16 more

Driver stacktrace:
18/06/25 10:45:31 INFO DAGScheduler: Job 32 failed: first at LinearRegression.scala:198, took 0.591985 s
18/06/25 10:46:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:46:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
18/06/25 10:46:47 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b507f9e7586
18/06/25 10:46:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:46:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b507f9e7586` AS `zzz24`
WHERE (0 = 1)
18/06/25 10:46:47 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8b507c35f1de
18/06/25 10:46:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:46:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b507c35f1de` AS `zzz25`
WHERE (0 = 1)
18/06/25 10:46:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:46:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
18/06/25 10:46:47 INFO CodeGenerator: Code generated in 12.474428 ms
18/06/25 10:46:47 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:92
18/06/25 10:46:47 INFO DAGScheduler: Registering RDD 225 (countByValue at StringIndexer.scala:92)
18/06/25 10:46:47 INFO DAGScheduler: Got job 33 (countByValue at StringIndexer.scala:92) with 1 output partitions
18/06/25 10:46:47 INFO DAGScheduler: Final stage: ResultStage 50 (countByValue at StringIndexer.scala:92)
18/06/25 10:46:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
18/06/25 10:46:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 49)
18/06/25 10:46:47 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[225] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 10:46:47 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 32.0 KB, free 340.3 MB)
18/06/25 10:46:48 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 12.3 KB, free 340.3 MB)
18/06/25 10:46:48 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:52522 (size: 12.3 KB, free: 340.4 MB)
18/06/25 10:46:48 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
18/06/25 10:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[225] at countByValue at StringIndexer.scala:92)
18/06/25 10:46:48 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
18/06/25 10:46:48 WARN TaskSetManager: Stage 49 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:46:48 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365299 bytes)
18/06/25 10:46:48 INFO Executor: Running task 0.0 in stage 49.0 (TID 55)
18/06/25 10:46:48 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:46:48 INFO CodeGenerator: Code generated in 9.588799 ms
18/06/25 10:46:48 INFO Executor: Finished task 0.0 in stage 49.0 (TID 55). 2165 bytes result sent to driver
18/06/25 10:46:48 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 55) in 696 ms on localhost (executor driver) (1/1)
18/06/25 10:46:48 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
18/06/25 10:46:48 INFO DAGScheduler: ShuffleMapStage 49 (countByValue at StringIndexer.scala:92) finished in 0.696 s
18/06/25 10:46:48 INFO DAGScheduler: looking for newly runnable stages
18/06/25 10:46:48 INFO DAGScheduler: running: Set()
18/06/25 10:46:48 INFO DAGScheduler: waiting: Set(ResultStage 50)
18/06/25 10:46:48 INFO DAGScheduler: failed: Set()
18/06/25 10:46:48 INFO DAGScheduler: Submitting ResultStage 50 (ShuffledRDD[226] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 10:46:48 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 3.2 KB, free 340.3 MB)
18/06/25 10:46:48 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 1970.0 B, free 340.3 MB)
18/06/25 10:46:48 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:52522 (size: 1970.0 B, free: 340.4 MB)
18/06/25 10:46:48 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
18/06/25 10:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (ShuffledRDD[226] at countByValue at StringIndexer.scala:92)
18/06/25 10:46:48 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
18/06/25 10:46:48 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 56, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/06/25 10:46:48 INFO Executor: Running task 0.0 in stage 50.0 (TID 56)
18/06/25 10:46:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 10:46:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 10:46:48 INFO Executor: Finished task 0.0 in stage 50.0 (TID 56). 2244 bytes result sent to driver
18/06/25 10:46:48 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 56) in 6 ms on localhost (executor driver) (1/1)
18/06/25 10:46:48 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/06/25 10:46:48 INFO DAGScheduler: ResultStage 50 (countByValue at StringIndexer.scala:92) finished in 0.007 s
18/06/25 10:46:48 INFO DAGScheduler: Job 33 finished: countByValue at StringIndexer.scala:92, took 0.734388 s
18/06/25 10:46:48 INFO CodeGenerator: Code generated in 15.228216 ms
18/06/25 10:46:48 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 10:46:48 INFO DAGScheduler: Got job 34 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 10:46:48 INFO DAGScheduler: Final stage: ResultStage 51 (first at LinearRegression.scala:198)
18/06/25 10:46:48 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:46:48 INFO DAGScheduler: Missing parents: List()
18/06/25 10:46:48 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[229] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 10:46:48 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 46.2 KB, free 340.3 MB)
18/06/25 10:46:48 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.3 KB, free 340.2 MB)
18/06/25 10:46:48 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:52522 (size: 17.3 KB, free: 340.4 MB)
18/06/25 10:46:48 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:996
18/06/25 10:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[229] at first at LinearRegression.scala:198)
18/06/25 10:46:48 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
18/06/25 10:46:48 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:52522 in memory (size: 1970.0 B, free: 340.4 MB)
18/06/25 10:46:49 WARN TaskSetManager: Stage 51 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:46:49 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 10:46:49 INFO Executor: Running task 0.0 in stage 51.0 (TID 57)
18/06/25 10:46:49 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:46:49 INFO CodeGenerator: Code generated in 8.793103 ms
18/06/25 10:46:49 WARN Executor: 1 block locks were not released by TID = 57:
[rdd_39_0]
18/06/25 10:46:49 INFO Executor: Finished task 0.0 in stage 51.0 (TID 57). 1695 bytes result sent to driver
18/06/25 10:46:49 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 57) in 391 ms on localhost (executor driver) (1/1)
18/06/25 10:46:49 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/06/25 10:46:49 INFO DAGScheduler: ResultStage 51 (first at LinearRegression.scala:198) finished in 0.391 s
18/06/25 10:46:49 INFO DAGScheduler: Job 34 finished: first at LinearRegression.scala:198, took 0.396714 s
18/06/25 10:46:49 INFO CodeGenerator: Code generated in 13.501109 ms
18/06/25 10:46:49 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
18/06/25 10:46:49 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
18/06/25 10:46:49 INFO DAGScheduler: Got job 35 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
18/06/25 10:46:49 INFO DAGScheduler: Final stage: ResultStage 52 (treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 10:46:49 INFO DAGScheduler: Parents of final stage: List()
18/06/25 10:46:49 INFO DAGScheduler: Missing parents: List()
18/06/25 10:46:49 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[235] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
18/06/25 10:46:49 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 51.4 KB, free 340.2 MB)
18/06/25 10:46:49 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 19.5 KB, free 340.2 MB)
18/06/25 10:46:49 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:52522 (size: 19.5 KB, free: 340.4 MB)
18/06/25 10:46:49 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
18/06/25 10:46:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[235] at treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 10:46:49 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
18/06/25 10:46:49 WARN TaskSetManager: Stage 52 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 10:46:49 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365311 bytes)
18/06/25 10:46:49 INFO Executor: Running task 0.0 in stage 52.0 (TID 58)
18/06/25 10:46:49 INFO BlockManager: Found block rdd_39_0 locally
18/06/25 10:46:49 INFO CodeGenerator: Code generated in 8.668925 ms
18/06/25 10:46:49 ERROR Executor: Exception in task 0.0 in stage 52.0 (TID 58)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b506f1e381a:double,air_time:double,onehot_30219b923ac6:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1135)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1135)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1136)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1136)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 27 more
18/06/25 10:46:49 WARN TaskSetManager: Lost task 0.0 in stage 52.0 (TID 58, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b506f1e381a:double,air_time:double,onehot_30219b923ac6:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1135)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1135)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1136)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1136)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 27 more

18/06/25 10:46:49 ERROR TaskSetManager: Task 0 in stage 52.0 failed 1 times; aborting job
18/06/25 10:46:49 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
18/06/25 10:46:49 INFO TaskSchedulerImpl: Cancelling stage 52
18/06/25 10:46:49 INFO DAGScheduler: ResultStage 52 (treeAggregate at WeightedLeastSquares.scala:100) failed in 0.457 s due to Job aborted due to stage failure: Task 0 in stage 52.0 failed 1 times, most recent failure: Lost task 0.0 in stage 52.0 (TID 58, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<dep_time_double_r_formula_8b506f1e381a:double,air_time:double,onehot_30219b923ac6:vector>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1135)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1135)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1136)
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1136)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Values to assemble cannot be null.
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:160)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:143)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	at org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:143)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)
	at org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)
	... 27 more

Driver stacktrace:
18/06/25 10:46:49 INFO DAGScheduler: Job 35 failed: treeAggregate at WeightedLeastSquares.scala:100, took 0.468450 s
18/06/25 10:48:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 10:48:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8b507f9e7586`
18/06/25 10:52:08 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:52522 in memory (size: 19.5 KB, free: 340.4 MB)
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2900
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2899
18/06/25 10:52:08 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:52522 in memory (size: 17.3 KB, free: 340.4 MB)
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2850
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2849
18/06/25 10:52:08 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:52522 in memory (size: 12.3 KB, free: 340.4 MB)
18/06/25 10:52:08 INFO ContextCleaner: Cleaned shuffle 16
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2752
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2751
18/06/25 10:52:08 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:52522 in memory (size: 20.2 KB, free: 340.5 MB)
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2702
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2701
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2700
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2699
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2698
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2697
18/06/25 10:52:08 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:52522 in memory (size: 14.3 KB, free: 340.5 MB)
18/06/25 10:52:08 INFO ContextCleaner: Cleaned shuffle 15
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2600
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2599
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2598
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2597
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2596
18/06/25 10:52:08 INFO ContextCleaner: Cleaned accumulator 2595
18/06/25 11:26:52 INFO SparkContext: Invoking stop() from shutdown hook
18/06/25 11:26:52 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/06/25 11:26:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/06/25 11:26:52 INFO MemoryStore: MemoryStore cleared
18/06/25 11:26:52 INFO BlockManager: BlockManager stopped
18/06/25 11:26:52 INFO BlockManagerMaster: BlockManagerMaster stopped
18/06/25 11:26:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/06/25 11:26:52 INFO SparkContext: Successfully stopped SparkContext
18/06/25 11:26:52 INFO ShutdownHookManager: Shutdown hook called
18/06/25 11:26:52 INFO ShutdownHookManager: Deleting directory /private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/spark-ce1c91b7-c54e-4245-b8fb-847fb524ad52
18/06/25 11:43:15 INFO SparkContext: Running Spark version 2.1.0
18/06/25 11:43:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/06/25 11:43:15 INFO SecurityManager: Changing view acls to: JBRickert
18/06/25 11:43:15 INFO SecurityManager: Changing modify acls to: JBRickert
18/06/25 11:43:15 INFO SecurityManager: Changing view acls groups to: 
18/06/25 11:43:15 INFO SecurityManager: Changing modify acls groups to: 
18/06/25 11:43:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JBRickert); groups with view permissions: Set(); users  with modify permissions: Set(JBRickert); groups with modify permissions: Set()
18/06/25 11:43:15 INFO Utils: Successfully started service 'sparkDriver' on port 53972.
18/06/25 11:43:15 INFO SparkEnv: Registering MapOutputTracker
18/06/25 11:43:15 INFO SparkEnv: Registering BlockManagerMaster
18/06/25 11:43:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/06/25 11:43:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/06/25 11:43:15 INFO DiskBlockManager: Created local directory at /private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/blockmgr-79ec8850-b48f-4f49-a65b-949072b1d160
18/06/25 11:43:15 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/06/25 11:43:15 INFO SparkEnv: Registering OutputCommitCoordinator
18/06/25 11:43:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/06/25 11:43:16 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/06/25 11:43:16 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:53972/jars/sparklyr-2.1-2.11.jar with timestamp 1529952196186
18/06/25 11:43:16 INFO Executor: Starting executor ID driver on host localhost
18/06/25 11:43:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53973.
18/06/25 11:43:16 INFO NettyBlockTransferService: Server created on 127.0.0.1:53973
18/06/25 11:43:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/06/25 11:43:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53973, None)
18/06/25 11:43:16 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53973 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53973, None)
18/06/25 11:43:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53973, None)
18/06/25 11:43:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53973, None)
18/06/25 11:43:16 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/06/25 11:43:16 INFO SharedState: Warehouse path is 'file:/Users/JBRickert/Documents/RStudio_Projects/useR_2018/spark-warehouse'.
18/06/25 11:43:16 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/06/25 11:43:17 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/06/25 11:43:17 INFO ObjectStore: ObjectStore, initialize called
18/06/25 11:43:18 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/06/25 11:43:18 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/06/25 11:43:19 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/06/25 11:43:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 11:43:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 11:43:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 11:43:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 11:43:21 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/06/25 11:43:21 INFO ObjectStore: Initialized ObjectStore
18/06/25 11:43:21 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/06/25 11:43:21 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/06/25 11:43:21 INFO HiveMetaStore: Added admin role in metastore
18/06/25 11:43:21 INFO HiveMetaStore: Added public role in metastore
18/06/25 11:43:22 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/06/25 11:43:22 INFO HiveMetaStore: 0: get_all_databases
18/06/25 11:43:22 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_all_databases	
18/06/25 11:43:22 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/06/25 11:43:22 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/06/25 11:43:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 11:43:22 INFO SessionState: Created local directory: /var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/499778e7-5019-463e-a6c4-a2313cfeaedd_resources
18/06/25 11:43:22 INFO SessionState: Created HDFS directory: /tmp/hive/JBRickert/499778e7-5019-463e-a6c4-a2313cfeaedd
18/06/25 11:43:22 INFO SessionState: Created local directory: /var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/JBRickert/499778e7-5019-463e-a6c4-a2313cfeaedd
18/06/25 11:43:22 INFO SessionState: Created HDFS directory: /tmp/hive/JBRickert/499778e7-5019-463e-a6c4-a2313cfeaedd/_tmp_space.db
18/06/25 11:43:22 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/JBRickert/Documents/RStudio_Projects/useR_2018/spark-warehouse
18/06/25 11:43:22 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:22 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:22 INFO HiveMetaStore: 0: get_database: global_temp
18/06/25 11:43:22 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/06/25 11:43:22 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/06/25 11:43:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 11:43:24 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:24 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:24 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:24 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 11:43:24 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 11:43:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 11:43:42 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:42 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:42 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:42 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 11:43:42 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 11:43:42 INFO CodeGenerator: Code generated in 306.696282 ms
18/06/25 11:43:42 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 11:43:42 INFO DAGScheduler: Got job 0 (collect at utils.scala:43) with 1 output partitions
18/06/25 11:43:42 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:43)
18/06/25 11:43:42 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:43:42 INFO DAGScheduler: Missing parents: List()
18/06/25 11:43:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:40), which has no missing parents
18/06/25 11:43:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
18/06/25 11:43:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
18/06/25 11:43:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53973 (size: 4.6 KB, free: 366.3 MB)
18/06/25 11:43:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:40)
18/06/25 11:43:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/06/25 11:43:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
18/06/25 11:43:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/06/25 11:43:42 INFO Executor: Fetching spark://127.0.0.1:53972/jars/sparklyr-2.1-2.11.jar with timestamp 1529952196186
18/06/25 11:43:42 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53972 after 14 ms (0 ms spent in bootstraps)
18/06/25 11:43:42 INFO Utils: Fetching spark://127.0.0.1:53972/jars/sparklyr-2.1-2.11.jar to /private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/spark-12cec62f-cd1f-413a-af35-091a2a9cdd74/userFiles-14bcd333-1032-49ee-a007-77b451b54574/fetchFileTemp7042403056449722311.tmp
18/06/25 11:43:43 INFO Executor: Adding file:/private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/spark-12cec62f-cd1f-413a-af35-091a2a9cdd74/userFiles-14bcd333-1032-49ee-a007-77b451b54574/sparklyr-2.1-2.11.jar to class loader
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 16.196884 ms
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 15.114293 ms
18/06/25 11:43:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
18/06/25 11:43:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 258 ms on localhost (executor driver) (1/1)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/06/25 11:43:43 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:43) finished in 0.274 s
18/06/25 11:43:43 INFO DAGScheduler: Job 0 finished: collect at utils.scala:43, took 0.435251 s
18/06/25 11:43:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:43 INFO SparkSqlParser: Parsing command: iris
18/06/25 11:43:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:43 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
18/06/25 11:43:43 INFO SparkSqlParser: Parsing command: `iris`
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 17.254338 ms
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 13.444596 ms
18/06/25 11:43:43 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 11:43:43 INFO DAGScheduler: Registering RDD 15 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:43 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 11:43:43 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/06/25 11:43:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/06/25 11:43:43 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:43:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 366.3 MB)
18/06/25 11:43:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 366.3 MB)
18/06/25 11:43:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53973 (size: 8.4 KB, free: 366.3 MB)
18/06/25 11:43:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/06/25 11:43:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 10001 bytes)
18/06/25 11:43:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 9.560675 ms
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 49.14756 ms
18/06/25 11:43:43 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 5.6 KB, free 366.3 MB)
18/06/25 11:43:43 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:53973 (size: 5.6 KB, free: 366.3 MB)
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 4.668955 ms
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 19.056387 ms
18/06/25 11:43:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2747 bytes result sent to driver
18/06/25 11:43:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 225 ms on localhost (executor driver) (1/1)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/06/25 11:43:43 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.227 s
18/06/25 11:43:43 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:43:43 INFO DAGScheduler: running: Set()
18/06/25 11:43:43 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/06/25 11:43:43 INFO DAGScheduler: failed: Set()
18/06/25 11:43:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:43:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/06/25 11:43:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/06/25 11:43:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 366.3 MB)
18/06/25 11:43:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/06/25 11:43:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
18/06/25 11:43:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/06/25 11:43:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:43:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/06/25 11:43:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
18/06/25 11:43:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (executor driver) (1/1)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/06/25 11:43:43 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.029 s
18/06/25 11:43:43 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.301354 s
18/06/25 11:43:43 INFO CodeGenerator: Code generated in 7.124816 ms
18/06/25 11:43:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:43 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
18/06/25 11:43:43 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 11:43:43 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
18/06/25 11:43:43 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
18/06/25 11:43:43 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
18/06/25 11:43:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/06/25 11:43:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/06/25 11:43:43 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
18/06/25 11:43:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 366.2 MB)
18/06/25 11:43:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.4 KB, free 366.2 MB)
18/06/25 11:43:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53973 (size: 8.4 KB, free: 366.3 MB)
18/06/25 11:43:43 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at utils.scala:196)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/06/25 11:43:43 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 9993 bytes)
18/06/25 11:43:43 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/06/25 11:43:43 INFO BlockManager: Found block rdd_12_0 locally
18/06/25 11:43:43 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2098 bytes result sent to driver
18/06/25 11:43:43 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 15 ms on localhost (executor driver) (1/1)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/06/25 11:43:43 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.016 s
18/06/25 11:43:43 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:43:43 INFO DAGScheduler: running: Set()
18/06/25 11:43:43 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/06/25 11:43:43 INFO DAGScheduler: failed: Set()
18/06/25 11:43:43 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
18/06/25 11:43:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/06/25 11:43:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/06/25 11:43:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 366.3 MB)
18/06/25 11:43:43 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[25] at collect at utils.scala:196)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/06/25 11:43:43 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
18/06/25 11:43:43 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/06/25 11:43:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:43:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 11:43:43 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
18/06/25 11:43:43 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
18/06/25 11:43:43 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/06/25 11:43:43 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.007 s
18/06/25 11:43:43 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.043089 s
18/06/25 11:43:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
18/06/25 11:43:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:44 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 11:43:44 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:44 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:44 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:44 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:44 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 11:43:44 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 11:43:44 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 11:43:44 INFO DAGScheduler: Got job 3 (collect at utils.scala:43) with 1 output partitions
18/06/25 11:43:44 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:43)
18/06/25 11:43:44 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:43:44 INFO DAGScheduler: Missing parents: List()
18/06/25 11:43:44 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[31] at map at utils.scala:40), which has no missing parents
18/06/25 11:43:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 366.2 MB)
18/06/25 11:43:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.2 MB)
18/06/25 11:43:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53973 (size: 4.6 KB, free: 366.3 MB)
18/06/25 11:43:44 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[31] at map at utils.scala:40)
18/06/25 11:43:44 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/06/25 11:43:44 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
18/06/25 11:43:44 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/06/25 11:43:44 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1238 bytes result sent to driver
18/06/25 11:43:44 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
18/06/25 11:43:44 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/06/25 11:43:44 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:43) finished in 0.011 s
18/06/25 11:43:44 INFO DAGScheduler: Job 3 finished: collect at utils.scala:43, took 0.019624 s
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 1
18/06/25 11:43:50 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53973 in memory (size: 4.6 KB, free: 366.3 MB)
18/06/25 11:43:50 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53973 in memory (size: 4.6 KB, free: 366.3 MB)
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 52
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 53
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 54
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 55
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 56
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 57
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 58
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 59
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 60
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 61
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 62
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 63
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 64
18/06/25 11:43:50 INFO ContextCleaner: Cleaned shuffle 0
18/06/25 11:43:50 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53973 in memory (size: 8.4 KB, free: 366.3 MB)
18/06/25 11:43:50 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 366.3 MB)
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 161
18/06/25 11:43:50 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53973 in memory (size: 8.4 KB, free: 366.3 MB)
18/06/25 11:43:50 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 366.3 MB)
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 270
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 271
18/06/25 11:43:50 INFO ContextCleaner: Cleaned accumulator 0
18/06/25 11:43:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:50 INFO SparkSqlParser: Parsing command: flights
18/06/25 11:43:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:50 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
18/06/25 11:43:50 INFO SparkSqlParser: Parsing command: `flights`
18/06/25 11:43:50 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 11:43:50 INFO DAGScheduler: Registering RDD 40 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:50 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 11:43:50 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
18/06/25 11:43:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
18/06/25 11:43:50 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:43:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 30.7 KB, free 366.3 MB)
18/06/25 11:43:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.7 KB, free 366.3 MB)
18/06/25 11:43:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53973 (size: 11.7 KB, free: 366.3 MB)
18/06/25 11:43:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:50 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/06/25 11:43:51 WARN TaskSetManager: Stage 6 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:43:51 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365330 bytes)
18/06/25 11:43:51 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/06/25 11:43:51 INFO ContextCleaner: Cleaned accumulator 322
18/06/25 11:43:51 INFO CodeGenerator: Code generated in 22.586637 ms
18/06/25 11:43:51 INFO CodeGenerator: Code generated in 125.653503 ms
18/06/25 11:43:55 INFO MemoryStore: Block rdd_37_0 stored as values in memory (estimated size 22.5 MB, free 343.8 MB)
18/06/25 11:43:55 INFO BlockManagerInfo: Added rdd_37_0 in memory on 127.0.0.1:53973 (size: 22.5 MB, free: 343.8 MB)
18/06/25 11:43:55 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2733 bytes result sent to driver
18/06/25 11:43:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4599 ms on localhost (executor driver) (1/1)
18/06/25 11:43:55 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/06/25 11:43:55 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 4.601 s
18/06/25 11:43:55 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:43:55 INFO DAGScheduler: running: Set()
18/06/25 11:43:55 INFO DAGScheduler: waiting: Set(ResultStage 7)
18/06/25 11:43:55 INFO DAGScheduler: failed: Set()
18/06/25 11:43:55 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[43] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:43:55 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 343.8 MB)
18/06/25 11:43:55 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 343.7 MB)
18/06/25 11:43:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 343.8 MB)
18/06/25 11:43:55 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[43] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:55 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/06/25 11:43:55 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, ANY, 5953 bytes)
18/06/25 11:43:55 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
18/06/25 11:43:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:43:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:43:55 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2042 bytes result sent to driver
18/06/25 11:43:55 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 5 ms on localhost (executor driver) (1/1)
18/06/25 11:43:55 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/06/25 11:43:55 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
18/06/25 11:43:55 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 4.629113 s
18/06/25 11:43:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
18/06/25 11:43:55 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 11:43:55 INFO DAGScheduler: Registering RDD 47 (collect at utils.scala:196)
18/06/25 11:43:55 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
18/06/25 11:43:55 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
18/06/25 11:43:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
18/06/25 11:43:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
18/06/25 11:43:55 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
18/06/25 11:43:55 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 30.7 KB, free 343.7 MB)
18/06/25 11:43:55 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.8 KB, free 343.7 MB)
18/06/25 11:43:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53973 (size: 11.8 KB, free: 343.8 MB)
18/06/25 11:43:55 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[47] at collect at utils.scala:196)
18/06/25 11:43:55 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/06/25 11:43:55 WARN TaskSetManager: Stage 8 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:43:55 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365323 bytes)
18/06/25 11:43:55 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
18/06/25 11:43:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 343.8 MB)
18/06/25 11:43:55 INFO ContextCleaner: Cleaned accumulator 431
18/06/25 11:43:56 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:43:56 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2171 bytes result sent to driver
18/06/25 11:43:56 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 528 ms on localhost (executor driver) (1/1)
18/06/25 11:43:56 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/06/25 11:43:56 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.528 s
18/06/25 11:43:56 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:43:56 INFO DAGScheduler: running: Set()
18/06/25 11:43:56 INFO DAGScheduler: waiting: Set(ResultStage 9)
18/06/25 11:43:56 INFO DAGScheduler: failed: Set()
18/06/25 11:43:56 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[50] at collect at utils.scala:196), which has no missing parents
18/06/25 11:43:56 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 343.7 MB)
18/06/25 11:43:56 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 343.7 MB)
18/06/25 11:43:56 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 343.8 MB)
18/06/25 11:43:56 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[50] at collect at utils.scala:196)
18/06/25 11:43:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/06/25 11:43:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 5946 bytes)
18/06/25 11:43:56 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
18/06/25 11:43:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:43:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 11:43:56 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2042 bytes result sent to driver
18/06/25 11:43:56 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
18/06/25 11:43:56 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/06/25 11:43:56 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.008 s
18/06/25 11:43:56 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.552207 s
18/06/25 11:43:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
18/06/25 11:43:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 11:43:56 INFO CodeGenerator: Code generated in 12.864287 ms
18/06/25 11:43:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 11:43:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:43:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 11:43:56 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 11:43:56 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 11:43:56 INFO DAGScheduler: Got job 6 (collect at utils.scala:43) with 1 output partitions
18/06/25 11:43:56 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:43)
18/06/25 11:43:56 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:43:56 INFO DAGScheduler: Missing parents: List()
18/06/25 11:43:56 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[58] at map at utils.scala:40), which has no missing parents
18/06/25 11:43:56 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.7 KB, free 343.7 MB)
18/06/25 11:43:56 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KB, free 343.7 MB)
18/06/25 11:43:56 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53973 (size: 4.6 KB, free: 343.8 MB)
18/06/25 11:43:56 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[58] at map at utils.scala:40)
18/06/25 11:43:56 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/06/25 11:43:56 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
18/06/25 11:43:56 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
18/06/25 11:43:56 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1248 bytes result sent to driver
18/06/25 11:43:56 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 9 ms on localhost (executor driver) (1/1)
18/06/25 11:43:56 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/06/25 11:43:56 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:43) finished in 0.011 s
18/06/25 11:43:56 INFO DAGScheduler: Job 6 finished: collect at utils.scala:43, took 0.022283 s
18/06/25 11:43:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:57 INFO SparkSqlParser: Parsing command: batting
18/06/25 11:43:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:57 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
18/06/25 11:43:57 INFO SparkSqlParser: Parsing command: `batting`
18/06/25 11:43:57 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 11:43:57 INFO DAGScheduler: Registering RDD 67 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:57 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 11:43:57 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/06/25 11:43:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/06/25 11:43:57 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[67] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:43:57 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 31.9 KB, free 343.7 MB)
18/06/25 11:43:57 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.7 KB, free 343.6 MB)
18/06/25 11:43:57 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53973 (size: 11.7 KB, free: 343.8 MB)
18/06/25 11:43:57 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 343.8 MB)
18/06/25 11:43:57 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[67] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:57 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
18/06/25 11:43:57 INFO ContextCleaner: Cleaned accumulator 540
18/06/25 11:43:57 INFO ContextCleaner: Cleaned accumulator 541
18/06/25 11:43:57 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53973 in memory (size: 4.6 KB, free: 343.8 MB)
18/06/25 11:43:57 INFO ContextCleaner: Cleaned accumulator 592
18/06/25 11:43:57 WARN TaskSetManager: Stage 11 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 11:43:57 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814099 bytes)
18/06/25 11:43:57 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
18/06/25 11:43:57 INFO CodeGenerator: Code generated in 17.958178 ms
18/06/25 11:43:57 INFO CodeGenerator: Code generated in 102.361276 ms
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 323
18/06/25 11:43:59 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53973 in memory (size: 11.8 KB, free: 343.8 MB)
18/06/25 11:43:59 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53973 in memory (size: 11.7 KB, free: 343.8 MB)
18/06/25 11:43:59 INFO ContextCleaner: Cleaned shuffle 2
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 334
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 333
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 332
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 331
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 330
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 329
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 328
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 327
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 326
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 325
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 324
18/06/25 11:43:59 INFO MemoryStore: Block rdd_64_0 stored as values in memory (estimated size 3.3 MB, free 340.4 MB)
18/06/25 11:43:59 INFO BlockManagerInfo: Added rdd_64_0 in memory on 127.0.0.1:53973 (size: 3.3 MB, free: 340.5 MB)
18/06/25 11:43:59 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2733 bytes result sent to driver
18/06/25 11:43:59 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 2040 ms on localhost (executor driver) (1/1)
18/06/25 11:43:59 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/06/25 11:43:59 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 2.042 s
18/06/25 11:43:59 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:43:59 INFO DAGScheduler: running: Set()
18/06/25 11:43:59 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/06/25 11:43:59 INFO DAGScheduler: failed: Set()
18/06/25 11:43:59 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[70] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:43:59 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
18/06/25 11:43:59 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
18/06/25 11:43:59 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.5 MB)
18/06/25 11:43:59 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[70] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 11:43:59 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/06/25 11:43:59 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, ANY, 5954 bytes)
18/06/25 11:43:59 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
18/06/25 11:43:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:43:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:43:59 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2042 bytes result sent to driver
18/06/25 11:43:59 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 11 ms on localhost (executor driver) (1/1)
18/06/25 11:43:59 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/06/25 11:43:59 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.011 s
18/06/25 11:43:59 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 2.120282 s
18/06/25 11:43:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:59 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
18/06/25 11:43:59 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 11:43:59 INFO DAGScheduler: Registering RDD 74 (collect at utils.scala:196)
18/06/25 11:43:59 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
18/06/25 11:43:59 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
18/06/25 11:43:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/06/25 11:43:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/06/25 11:43:59 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[74] at collect at utils.scala:196), which has no missing parents
18/06/25 11:43:59 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.9 KB, free 340.4 MB)
18/06/25 11:43:59 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 11.7 KB, free 340.4 MB)
18/06/25 11:43:59 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53973 (size: 11.7 KB, free: 340.4 MB)
18/06/25 11:43:59 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[74] at collect at utils.scala:196)
18/06/25 11:43:59 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/06/25 11:43:59 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.5 MB)
18/06/25 11:43:59 INFO ContextCleaner: Cleaned accumulator 701
18/06/25 11:43:59 WARN TaskSetManager: Stage 13 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 11:43:59 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814091 bytes)
18/06/25 11:43:59 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
18/06/25 11:43:59 INFO BlockManager: Found block rdd_64_0 locally
18/06/25 11:43:59 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2098 bytes result sent to driver
18/06/25 11:43:59 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 98 ms on localhost (executor driver) (1/1)
18/06/25 11:43:59 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/06/25 11:43:59 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.099 s
18/06/25 11:43:59 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:43:59 INFO DAGScheduler: running: Set()
18/06/25 11:43:59 INFO DAGScheduler: waiting: Set(ResultStage 14)
18/06/25 11:43:59 INFO DAGScheduler: failed: Set()
18/06/25 11:43:59 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[77] at collect at utils.scala:196), which has no missing parents
18/06/25 11:43:59 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
18/06/25 11:43:59 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
18/06/25 11:43:59 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.4 MB)
18/06/25 11:43:59 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
18/06/25 11:43:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[77] at collect at utils.scala:196)
18/06/25 11:43:59 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
18/06/25 11:43:59 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 5946 bytes)
18/06/25 11:43:59 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
18/06/25 11:43:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:43:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 11:43:59 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2042 bytes result sent to driver
18/06/25 11:43:59 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
18/06/25 11:43:59 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/06/25 11:43:59 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.006 s
18/06/25 11:43:59 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.119050 s
18/06/25 11:43:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:43:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
18/06/25 11:44:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 11:44:00 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:44:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:44:00 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:44:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:44:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 11:44:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 11:44:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 11:44:00 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:44:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:44:00 INFO HiveMetaStore: 0: get_database: default
18/06/25 11:44:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 11:44:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 11:44:00 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 11:44:00 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 11:44:00 INFO DAGScheduler: Got job 9 (collect at utils.scala:43) with 1 output partitions
18/06/25 11:44:00 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:43)
18/06/25 11:44:00 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:44:00 INFO DAGScheduler: Missing parents: List()
18/06/25 11:44:00 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[84] at map at utils.scala:40), which has no missing parents
18/06/25 11:44:00 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 8.7 KB, free 340.4 MB)
18/06/25 11:44:00 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.6 KB, free 340.4 MB)
18/06/25 11:44:00 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53973 (size: 4.6 KB, free: 340.4 MB)
18/06/25 11:44:00 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[84] at map at utils.scala:40)
18/06/25 11:44:00 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/06/25 11:44:00 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6462 bytes)
18/06/25 11:44:00 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
18/06/25 11:44:00 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1258 bytes result sent to driver
18/06/25 11:44:00 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (executor driver) (1/1)
18/06/25 11:44:00 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/06/25 11:44:00 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:43) finished in 0.009 s
18/06/25 11:44:00 INFO DAGScheduler: Job 9 finished: collect at utils.scala:43, took 0.017571 s
18/06/25 11:44:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 11:44:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 11:44:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 11:44:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 11:44:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
18/06/25 11:44:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 1000
18/06/25 11:44:06 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#186) generates partition filter: ((dep_delay.count#1327 - dep_delay.nullCount#1326) > 0)
18/06/25 11:44:06 INFO InMemoryTableScanExec: Predicate (dep_delay#186 = 2.0) generates partition filter: ((dep_delay.lowerBound#1325 <= 2.0) && (2.0 <= dep_delay.upperBound#1324))
18/06/25 11:44:06 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53973 in memory (size: 4.6 KB, free: 340.4 MB)
18/06/25 11:44:06 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53973 in memory (size: 11.7 KB, free: 340.5 MB)
18/06/25 11:44:06 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.5 MB)
18/06/25 11:44:06 INFO ContextCleaner: Cleaned accumulator 810
18/06/25 11:44:06 INFO ContextCleaner: Cleaned accumulator 811
18/06/25 11:44:06 INFO CodeGenerator: Code generated in 15.599713 ms
18/06/25 11:44:06 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 11:44:06 INFO DAGScheduler: Got job 10 (collect at utils.scala:196) with 1 output partitions
18/06/25 11:44:06 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
18/06/25 11:44:06 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:44:06 INFO DAGScheduler: Missing parents: List()
18/06/25 11:44:06 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[87] at collect at utils.scala:196), which has no missing parents
18/06/25 11:44:06 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 34.7 KB, free 340.4 MB)
18/06/25 11:44:06 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 12.6 KB, free 340.4 MB)
18/06/25 11:44:06 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53973 (size: 12.6 KB, free: 340.5 MB)
18/06/25 11:44:06 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[87] at collect at utils.scala:196)
18/06/25 11:44:06 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/06/25 11:44:06 WARN TaskSetManager: Stage 16 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:06 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 11:44:06 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
18/06/25 11:44:06 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:06 INFO CodeGenerator: Code generated in 7.914367 ms
18/06/25 11:44:06 INFO CodeGenerator: Code generated in 18.522451 ms
18/06/25 11:44:06 WARN Executor: 1 block locks were not released by TID = 16:
[rdd_37_0]
18/06/25 11:44:06 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 67599 bytes result sent to driver
18/06/25 11:44:06 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 689 ms on localhost (executor driver) (1/1)
18/06/25 11:44:06 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/06/25 11:44:06 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 0.690 s
18/06/25 11:44:06 INFO DAGScheduler: Job 10 finished: collect at utils.scala:196, took 0.706565 s
18/06/25 11:44:06 INFO CodeGenerator: Code generated in 18.667275 ms
18/06/25 11:44:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `wdvhkylqlp`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
18/06/25 11:44:14 INFO ContextCleaner: Cleaned accumulator 911
18/06/25 11:44:14 INFO CodeGenerator: Code generated in 68.358941 ms
18/06/25 11:44:14 INFO CodeGenerator: Code generated in 44.481364 ms
18/06/25 11:44:14 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 11:44:14 INFO DAGScheduler: Registering RDD 90 (collect at utils.scala:196)
18/06/25 11:44:14 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 4 output partitions
18/06/25 11:44:14 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
18/06/25 11:44:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
18/06/25 11:44:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
18/06/25 11:44:14 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[90] at collect at utils.scala:196), which has no missing parents
18/06/25 11:44:14 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 50.3 KB, free 340.3 MB)
18/06/25 11:44:14 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 19.9 KB, free 340.3 MB)
18/06/25 11:44:14 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53973 (size: 19.9 KB, free: 340.4 MB)
18/06/25 11:44:14 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[90] at collect at utils.scala:196)
18/06/25 11:44:14 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/06/25 11:44:15 WARN TaskSetManager: Stage 17 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:15 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 11:44:15 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
18/06/25 11:44:15 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:15 INFO CodeGenerator: Code generated in 15.433558 ms
18/06/25 11:44:15 INFO CodeGenerator: Code generated in 7.285437 ms
18/06/25 11:44:15 INFO CodeGenerator: Code generated in 7.163908 ms
18/06/25 11:44:15 INFO CodeGenerator: Code generated in 7.724399 ms
18/06/25 11:44:15 INFO CodeGenerator: Code generated in 11.943623 ms
18/06/25 11:44:15 INFO CodeGenerator: Code generated in 5.887883 ms
18/06/25 11:44:16 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53973 in memory (size: 12.6 KB, free: 340.4 MB)
18/06/25 11:44:16 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53973 in memory (size: 11.7 KB, free: 340.5 MB)
18/06/25 11:44:16 INFO ContextCleaner: Cleaned shuffle 4
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 604
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 603
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 602
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 601
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 600
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 599
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 598
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 597
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 596
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 595
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 594
18/06/25 11:44:16 INFO ContextCleaner: Cleaned accumulator 593
18/06/25 11:44:16 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2442 bytes result sent to driver
18/06/25 11:44:16 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 1250 ms on localhost (executor driver) (1/1)
18/06/25 11:44:16 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/06/25 11:44:16 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:196) finished in 1.251 s
18/06/25 11:44:16 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:44:16 INFO DAGScheduler: running: Set()
18/06/25 11:44:16 INFO DAGScheduler: waiting: Set(ResultStage 18)
18/06/25 11:44:16 INFO DAGScheduler: failed: Set()
18/06/25 11:44:16 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[93] at collect at utils.scala:196), which has no missing parents
18/06/25 11:44:16 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 27.3 KB, free 340.4 MB)
18/06/25 11:44:16 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.7 KB, free 340.4 MB)
18/06/25 11:44:16 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53973 (size: 11.7 KB, free: 340.4 MB)
18/06/25 11:44:16 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[93] at collect at utils.scala:196)
18/06/25 11:44:16 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
18/06/25 11:44:16 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 11:44:16 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 19, localhost, executor driver, partition 1, ANY, 5947 bytes)
18/06/25 11:44:16 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 20, localhost, executor driver, partition 2, ANY, 5947 bytes)
18/06/25 11:44:16 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 21, localhost, executor driver, partition 3, ANY, 5947 bytes)
18/06/25 11:44:16 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
18/06/25 11:44:16 INFO Executor: Running task 1.0 in stage 18.0 (TID 19)
18/06/25 11:44:16 INFO Executor: Running task 2.0 in stage 18.0 (TID 20)
18/06/25 11:44:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:44:16 INFO Executor: Running task 3.0 in stage 18.0 (TID 21)
18/06/25 11:44:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:44:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:44:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:44:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 11:44:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 11:44:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:44:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:44:16 INFO Executor: Finished task 3.0 in stage 18.0 (TID 21). 21386 bytes result sent to driver
18/06/25 11:44:16 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 21) in 44 ms on localhost (executor driver) (1/4)
18/06/25 11:44:16 INFO Executor: Finished task 1.0 in stage 18.0 (TID 19). 22319 bytes result sent to driver
18/06/25 11:44:16 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 19) in 49 ms on localhost (executor driver) (2/4)
18/06/25 11:44:16 INFO Executor: Finished task 2.0 in stage 18.0 (TID 20). 23246 bytes result sent to driver
18/06/25 11:44:16 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 20) in 52 ms on localhost (executor driver) (3/4)
18/06/25 11:44:16 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 22143 bytes result sent to driver
18/06/25 11:44:16 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 59 ms on localhost (executor driver) (4/4)
18/06/25 11:44:16 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/06/25 11:44:16 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.060 s
18/06/25 11:44:16 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 1.325438 s
18/06/25 11:44:16 INFO CodeGenerator: Code generated in 9.098843 ms
18/06/25 11:44:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/06/25 11:44:47 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa7ce9ea42
18/06/25 11:44:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa7ce9ea42` AS `zzz4`
WHERE (0 = 1)
18/06/25 11:44:48 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa6112d31f
18/06/25 11:44:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa6112d31f` AS `zzz5`
WHERE (0 = 1)
18/06/25 11:44:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa7ce9ea42`
18/06/25 11:44:48 INFO CodeGenerator: Code generated in 23.318284 ms
18/06/25 11:44:48 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:92
18/06/25 11:44:48 INFO DAGScheduler: Registering RDD 102 (countByValue at StringIndexer.scala:92)
18/06/25 11:44:48 INFO DAGScheduler: Got job 12 (countByValue at StringIndexer.scala:92) with 1 output partitions
18/06/25 11:44:48 INFO DAGScheduler: Final stage: ResultStage 20 (countByValue at StringIndexer.scala:92)
18/06/25 11:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
18/06/25 11:44:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
18/06/25 11:44:48 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[102] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 11:44:48 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 43.2 KB, free 340.3 MB)
18/06/25 11:44:48 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 15.9 KB, free 340.3 MB)
18/06/25 11:44:48 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53973 (size: 15.9 KB, free: 340.4 MB)
18/06/25 11:44:48 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[102] at countByValue at StringIndexer.scala:92)
18/06/25 11:44:48 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
18/06/25 11:44:48 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53973 in memory (size: 11.7 KB, free: 340.4 MB)
18/06/25 11:44:48 WARN TaskSetManager: Stage 19 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:48 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365299 bytes)
18/06/25 11:44:48 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
18/06/25 11:44:49 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:49 INFO CodeGenerator: Code generated in 32.108634 ms
18/06/25 11:44:49 INFO CodeGenerator: Code generated in 4.290449 ms
18/06/25 11:44:49 INFO CodeGenerator: Code generated in 6.196831 ms
18/06/25 11:44:50 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 2567 bytes result sent to driver
18/06/25 11:44:50 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 1355 ms on localhost (executor driver) (1/1)
18/06/25 11:44:50 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/06/25 11:44:50 INFO DAGScheduler: ShuffleMapStage 19 (countByValue at StringIndexer.scala:92) finished in 1.356 s
18/06/25 11:44:50 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:44:50 INFO DAGScheduler: running: Set()
18/06/25 11:44:50 INFO DAGScheduler: waiting: Set(ResultStage 20)
18/06/25 11:44:50 INFO DAGScheduler: failed: Set()
18/06/25 11:44:50 INFO DAGScheduler: Submitting ResultStage 20 (ShuffledRDD[103] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 11:44:50 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.2 KB, free 340.3 MB)
18/06/25 11:44:50 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1970.0 B, free 340.3 MB)
18/06/25 11:44:50 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53973 (size: 1970.0 B, free: 340.4 MB)
18/06/25 11:44:50 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (ShuffledRDD[103] at countByValue at StringIndexer.scala:92)
18/06/25 11:44:50 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
18/06/25 11:44:50 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/06/25 11:44:50 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
18/06/25 11:44:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:44:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:44:50 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 2244 bytes result sent to driver
18/06/25 11:44:50 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 22 ms on localhost (executor driver) (1/1)
18/06/25 11:44:50 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/06/25 11:44:50 INFO DAGScheduler: ResultStage 20 (countByValue at StringIndexer.scala:92) finished in 0.022 s
18/06/25 11:44:50 INFO DAGScheduler: Job 12 finished: countByValue at StringIndexer.scala:92, took 1.541869 s
18/06/25 11:44:50 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53973 in memory (size: 1970.0 B, free: 340.4 MB)
18/06/25 11:44:50 INFO CodeGenerator: Code generated in 34.731836 ms
18/06/25 11:44:50 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 11:44:50 INFO DAGScheduler: Got job 13 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 11:44:50 INFO DAGScheduler: Final stage: ResultStage 21 (first at LinearRegression.scala:198)
18/06/25 11:44:50 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:44:50 INFO DAGScheduler: Missing parents: List()
18/06/25 11:44:50 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[106] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 11:44:50 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 60.4 KB, free 340.3 MB)
18/06/25 11:44:50 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 21.8 KB, free 340.3 MB)
18/06/25 11:44:50 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53973 (size: 21.8 KB, free: 340.4 MB)
18/06/25 11:44:50 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[106] at first at LinearRegression.scala:198)
18/06/25 11:44:50 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
18/06/25 11:44:50 WARN TaskSetManager: Stage 21 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:50 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 11:44:50 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
18/06/25 11:44:51 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:51 INFO ContextCleaner: Cleaned accumulator 1099
18/06/25 11:44:51 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53973 in memory (size: 15.9 KB, free: 340.4 MB)
18/06/25 11:44:51 INFO ContextCleaner: Cleaned shuffle 7
18/06/25 11:44:51 INFO ContextCleaner: Cleaned accumulator 1098
18/06/25 11:44:51 INFO ContextCleaner: Cleaned accumulator 1097
18/06/25 11:44:51 INFO ContextCleaner: Cleaned accumulator 1096
18/06/25 11:44:51 INFO ContextCleaner: Cleaned accumulator 1095
18/06/25 11:44:51 INFO ContextCleaner: Cleaned accumulator 1094
18/06/25 11:44:51 INFO ContextCleaner: Cleaned accumulator 1093
18/06/25 11:44:51 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53973 in memory (size: 19.9 KB, free: 340.5 MB)
18/06/25 11:44:52 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 2178 bytes result sent to driver
18/06/25 11:44:52 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 1253 ms on localhost (executor driver) (1/1)
18/06/25 11:44:52 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/06/25 11:44:52 INFO DAGScheduler: ResultStage 21 (first at LinearRegression.scala:198) finished in 1.253 s
18/06/25 11:44:52 INFO DAGScheduler: Job 13 finished: first at LinearRegression.scala:198, took 1.260762 s
18/06/25 11:44:52 INFO CodeGenerator: Code generated in 10.199721 ms
18/06/25 11:44:52 INFO CodeGenerator: Code generated in 30.085348 ms
18/06/25 11:44:52 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
18/06/25 11:44:52 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
18/06/25 11:44:52 INFO DAGScheduler: Got job 14 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
18/06/25 11:44:52 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 11:44:52 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:44:52 INFO DAGScheduler: Missing parents: List()
18/06/25 11:44:52 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[112] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
18/06/25 11:44:52 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 63.3 KB, free 340.3 MB)
18/06/25 11:44:52 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.1 KB, free 340.3 MB)
18/06/25 11:44:52 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53973 (size: 23.1 KB, free: 340.4 MB)
18/06/25 11:44:52 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[112] at treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 11:44:52 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
18/06/25 11:44:52 WARN TaskSetManager: Stage 22 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:52 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365311 bytes)
18/06/25 11:44:52 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
18/06/25 11:44:52 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:52 INFO CodeGenerator: Code generated in 7.334821 ms
18/06/25 11:44:53 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53973 in memory (size: 21.8 KB, free: 340.5 MB)
18/06/25 11:44:53 INFO ContextCleaner: Cleaned accumulator 1202
18/06/25 11:44:53 INFO ContextCleaner: Cleaned accumulator 1201
18/06/25 11:44:53 INFO ContextCleaner: Cleaned accumulator 1200
18/06/25 11:44:53 INFO ContextCleaner: Cleaned accumulator 1199
18/06/25 11:44:53 INFO ContextCleaner: Cleaned accumulator 1198
18/06/25 11:44:53 INFO ContextCleaner: Cleaned accumulator 1197
18/06/25 11:44:53 INFO ContextCleaner: Cleaned accumulator 1196
18/06/25 11:44:54 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 4097 bytes result sent to driver
18/06/25 11:44:54 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 1869 ms on localhost (executor driver) (1/1)
18/06/25 11:44:54 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/06/25 11:44:54 INFO DAGScheduler: ResultStage 22 (treeAggregate at WeightedLeastSquares.scala:100) finished in 1.870 s
18/06/25 11:44:54 INFO DAGScheduler: Job 14 finished: treeAggregate at WeightedLeastSquares.scala:100, took 1.878390 s
18/06/25 11:44:54 INFO WeightedLeastSquares: Number of instances: 190884.
18/06/25 11:44:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/06/25 11:44:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/06/25 11:44:54 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
18/06/25 11:44:54 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
18/06/25 11:44:54 INFO CodeGenerator: Code generated in 29.500684 ms
18/06/25 11:44:54 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
18/06/25 11:44:54 INFO DAGScheduler: Got job 15 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
18/06/25 11:44:54 INFO DAGScheduler: Final stage: ResultStage 23 (aggregate at RegressionMetrics.scala:57)
18/06/25 11:44:54 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:44:54 INFO DAGScheduler: Missing parents: List()
18/06/25 11:44:54 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[118] at map at RegressionMetrics.scala:55), which has no missing parents
18/06/25 11:44:54 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 62.0 KB, free 340.3 MB)
18/06/25 11:44:54 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.1 KB, free 340.3 MB)
18/06/25 11:44:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53973 (size: 23.1 KB, free: 340.4 MB)
18/06/25 11:44:54 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[118] at map at RegressionMetrics.scala:55)
18/06/25 11:44:54 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
18/06/25 11:44:54 WARN TaskSetManager: Stage 23 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:54 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365307 bytes)
18/06/25 11:44:54 INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
18/06/25 11:44:54 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:54 INFO CodeGenerator: Code generated in 6.461166 ms
18/06/25 11:44:55 INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 2691 bytes result sent to driver
18/06/25 11:44:55 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 1319 ms on localhost (executor driver) (1/1)
18/06/25 11:44:55 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/06/25 11:44:55 INFO DAGScheduler: ResultStage 23 (aggregate at RegressionMetrics.scala:57) finished in 1.319 s
18/06/25 11:44:55 INFO DAGScheduler: Job 15 finished: aggregate at RegressionMetrics.scala:57, took 1.325995 s
18/06/25 11:44:55 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
18/06/25 11:44:55 INFO DAGScheduler: Got job 16 (sum at RegressionMetrics.scala:71) with 1 output partitions
18/06/25 11:44:55 INFO DAGScheduler: Final stage: ResultStage 24 (sum at RegressionMetrics.scala:71)
18/06/25 11:44:55 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:44:55 INFO DAGScheduler: Missing parents: List()
18/06/25 11:44:55 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[119] at map at RegressionMetrics.scala:69), which has no missing parents
18/06/25 11:44:55 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 61.5 KB, free 340.2 MB)
18/06/25 11:44:55 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.0 KB, free 340.2 MB)
18/06/25 11:44:55 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53973 (size: 23.0 KB, free: 340.4 MB)
18/06/25 11:44:55 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[119] at map at RegressionMetrics.scala:69)
18/06/25 11:44:55 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
18/06/25 11:44:55 WARN TaskSetManager: Stage 24 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:55 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365301 bytes)
18/06/25 11:44:55 INFO Executor: Running task 0.0 in stage 24.0 (TID 27)
18/06/25 11:44:55 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:56 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53973 in memory (size: 23.1 KB, free: 340.4 MB)
18/06/25 11:44:56 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53973 in memory (size: 23.1 KB, free: 340.5 MB)
18/06/25 11:44:56 INFO Executor: Finished task 0.0 in stage 24.0 (TID 27). 2121 bytes result sent to driver
18/06/25 11:44:56 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 27) in 1223 ms on localhost (executor driver) (1/1)
18/06/25 11:44:56 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/06/25 11:44:56 INFO DAGScheduler: ResultStage 24 (sum at RegressionMetrics.scala:71) finished in 1.224 s
18/06/25 11:44:56 INFO DAGScheduler: Job 16 finished: sum at RegressionMetrics.scala:71, took 1.231032 s
18/06/25 11:44:56 INFO CodeGenerator: Code generated in 18.871368 ms
18/06/25 11:44:56 INFO SparkContext: Starting job: count at LinearRegression.scala:683
18/06/25 11:44:56 INFO DAGScheduler: Registering RDD 122 (count at LinearRegression.scala:683)
18/06/25 11:44:56 INFO DAGScheduler: Got job 17 (count at LinearRegression.scala:683) with 1 output partitions
18/06/25 11:44:56 INFO DAGScheduler: Final stage: ResultStage 26 (count at LinearRegression.scala:683)
18/06/25 11:44:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
18/06/25 11:44:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
18/06/25 11:44:56 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[122] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 11:44:56 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 45.4 KB, free 340.3 MB)
18/06/25 11:44:56 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 17.0 KB, free 340.3 MB)
18/06/25 11:44:56 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53973 (size: 17.0 KB, free: 340.4 MB)
18/06/25 11:44:56 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[122] at count at LinearRegression.scala:683)
18/06/25 11:44:56 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
18/06/25 11:44:57 INFO ContextCleaner: Cleaned accumulator 1409
18/06/25 11:44:57 WARN TaskSetManager: Stage 25 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:57 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 11:44:57 INFO Executor: Running task 0.0 in stage 25.0 (TID 28)
18/06/25 11:44:57 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:57 INFO Executor: Finished task 0.0 in stage 25.0 (TID 28). 2839 bytes result sent to driver
18/06/25 11:44:57 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 28) in 756 ms on localhost (executor driver) (1/1)
18/06/25 11:44:57 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/06/25 11:44:57 INFO DAGScheduler: ShuffleMapStage 25 (count at LinearRegression.scala:683) finished in 0.757 s
18/06/25 11:44:57 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:44:57 INFO DAGScheduler: running: Set()
18/06/25 11:44:57 INFO DAGScheduler: waiting: Set(ResultStage 26)
18/06/25 11:44:57 INFO DAGScheduler: failed: Set()
18/06/25 11:44:57 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[125] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 11:44:57 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 340.3 MB)
18/06/25 11:44:57 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.3 MB)
18/06/25 11:44:57 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.4 MB)
18/06/25 11:44:57 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[125] at count at LinearRegression.scala:683)
18/06/25 11:44:57 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
18/06/25 11:44:57 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 29, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 11:44:57 INFO Executor: Running task 0.0 in stage 26.0 (TID 29)
18/06/25 11:44:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:44:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 11:44:57 INFO Executor: Finished task 0.0 in stage 26.0 (TID 29). 2042 bytes result sent to driver
18/06/25 11:44:57 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 29) in 4 ms on localhost (executor driver) (1/1)
18/06/25 11:44:57 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/06/25 11:44:57 INFO DAGScheduler: ResultStage 26 (count at LinearRegression.scala:683) finished in 0.005 s
18/06/25 11:44:57 INFO DAGScheduler: Job 17 finished: count at LinearRegression.scala:683, took 0.773443 s
18/06/25 11:44:57 INFO CodeGenerator: Code generated in 11.299916 ms
18/06/25 11:44:57 INFO CodeGenerator: Code generated in 29.560116 ms
18/06/25 11:44:57 INFO SparkContext: Starting job: first at LinearRegression.scala:707
18/06/25 11:44:57 INFO DAGScheduler: Registering RDD 128 (first at LinearRegression.scala:707)
18/06/25 11:44:57 INFO DAGScheduler: Got job 18 (first at LinearRegression.scala:707) with 1 output partitions
18/06/25 11:44:57 INFO DAGScheduler: Final stage: ResultStage 28 (first at LinearRegression.scala:707)
18/06/25 11:44:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
18/06/25 11:44:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
18/06/25 11:44:57 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[128] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 11:44:57 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 69.1 KB, free 340.3 MB)
18/06/25 11:44:57 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 26.6 KB, free 340.2 MB)
18/06/25 11:44:57 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53973 (size: 26.6 KB, free: 340.4 MB)
18/06/25 11:44:57 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[128] at first at LinearRegression.scala:707)
18/06/25 11:44:57 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
18/06/25 11:44:57 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 11:44:57 INFO ContextCleaner: Cleaned accumulator 1523
18/06/25 11:44:58 WARN TaskSetManager: Stage 27 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:44:58 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365238 bytes)
18/06/25 11:44:58 INFO Executor: Running task 0.0 in stage 27.0 (TID 30)
18/06/25 11:44:58 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:44:59 INFO Executor: Finished task 0.0 in stage 27.0 (TID 30). 2839 bytes result sent to driver
18/06/25 11:44:59 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 30) in 1277 ms on localhost (executor driver) (1/1)
18/06/25 11:44:59 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/06/25 11:44:59 INFO DAGScheduler: ShuffleMapStage 27 (first at LinearRegression.scala:707) finished in 1.279 s
18/06/25 11:44:59 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:44:59 INFO DAGScheduler: running: Set()
18/06/25 11:44:59 INFO DAGScheduler: waiting: Set(ResultStage 28)
18/06/25 11:44:59 INFO DAGScheduler: failed: Set()
18/06/25 11:44:59 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[131] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 11:44:59 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.9 KB, free 340.2 MB)
18/06/25 11:44:59 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.0 KB, free 340.2 MB)
18/06/25 11:44:59 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53973 (size: 4.0 KB, free: 340.4 MB)
18/06/25 11:44:59 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
18/06/25 11:44:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[131] at first at LinearRegression.scala:707)
18/06/25 11:44:59 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
18/06/25 11:44:59 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 31, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/06/25 11:44:59 INFO Executor: Running task 0.0 in stage 28.0 (TID 31)
18/06/25 11:44:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:44:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 11:44:59 INFO Executor: Finished task 0.0 in stage 28.0 (TID 31). 2027 bytes result sent to driver
18/06/25 11:44:59 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 31) in 6 ms on localhost (executor driver) (1/1)
18/06/25 11:44:59 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/06/25 11:44:59 INFO DAGScheduler: ResultStage 28 (first at LinearRegression.scala:707) finished in 0.008 s
18/06/25 11:44:59 INFO DAGScheduler: Job 18 finished: first at LinearRegression.scala:707, took 1.298598 s
18/06/25 11:44:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa4a78a734
18/06/25 11:44:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa4a78a734` AS `zzz6`
WHERE (0 = 1)
18/06/25 11:44:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa37296d1e
18/06/25 11:44:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa37296d1e` AS `zzz7`
WHERE (0 = 1)
18/06/25 11:44:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa7ce9ea42`
18/06/25 11:44:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfabae8dd
18/06/25 11:44:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfabae8dd` AS `zzz8`
WHERE (0 = 1)
18/06/25 11:44:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:44:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfabae8dd`
18/06/25 11:45:16 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53973 in memory (size: 4.0 KB, free: 340.4 MB)
18/06/25 11:56:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:56:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa37296d1e`
18/06/25 11:56:58 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
18/06/25 11:56:58 INFO DAGScheduler: Registering RDD 137 (count at NativeMethodAccessorImpl.java:0)
18/06/25 11:56:58 INFO DAGScheduler: Got job 19 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 11:56:58 INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
18/06/25 11:56:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
18/06/25 11:56:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
18/06/25 11:56:58 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[137] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:56:58 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 45.4 KB, free 340.2 MB)
18/06/25 11:56:58 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 17.0 KB, free 340.2 MB)
18/06/25 11:56:58 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53973 (size: 17.0 KB, free: 340.4 MB)
18/06/25 11:56:58 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
18/06/25 11:56:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[137] at count at NativeMethodAccessorImpl.java:0)
18/06/25 11:56:58 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
18/06/25 11:56:58 WARN TaskSetManager: Stage 29 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:56:58 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 11:56:58 INFO Executor: Running task 0.0 in stage 29.0 (TID 32)
18/06/25 11:56:58 INFO ContextCleaner: Cleaned accumulator 1637
18/06/25 11:56:58 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:56:59 INFO Executor: Finished task 0.0 in stage 29.0 (TID 32). 2839 bytes result sent to driver
18/06/25 11:56:59 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 32) in 658 ms on localhost (executor driver) (1/1)
18/06/25 11:56:59 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/06/25 11:56:59 INFO DAGScheduler: ShuffleMapStage 29 (count at NativeMethodAccessorImpl.java:0) finished in 0.659 s
18/06/25 11:56:59 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:56:59 INFO DAGScheduler: running: Set()
18/06/25 11:56:59 INFO DAGScheduler: waiting: Set(ResultStage 30)
18/06/25 11:56:59 INFO DAGScheduler: failed: Set()
18/06/25 11:56:59 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[140] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:56:59 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 7.0 KB, free 340.2 MB)
18/06/25 11:56:59 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.2 MB)
18/06/25 11:56:59 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.4 MB)
18/06/25 11:56:59 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
18/06/25 11:56:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[140] at count at NativeMethodAccessorImpl.java:0)
18/06/25 11:56:59 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
18/06/25 11:56:59 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 33, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 11:56:59 INFO Executor: Running task 0.0 in stage 30.0 (TID 33)
18/06/25 11:56:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:56:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 11:56:59 INFO Executor: Finished task 0.0 in stage 30.0 (TID 33). 2042 bytes result sent to driver
18/06/25 11:56:59 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 33) in 4 ms on localhost (executor driver) (1/1)
18/06/25 11:56:59 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/06/25 11:56:59 INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0.004 s
18/06/25 11:56:59 INFO DAGScheduler: Job 19 finished: count at NativeMethodAccessorImpl.java:0, took 0.678698 s
18/06/25 11:56:59 INFO CodeGenerator: Code generated in 34.681793 ms
18/06/25 11:56:59 INFO SparkContext: Starting job: collect at utils.scala:36
18/06/25 11:56:59 INFO DAGScheduler: Got job 20 (collect at utils.scala:36) with 1 output partitions
18/06/25 11:56:59 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:36)
18/06/25 11:56:59 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:56:59 INFO DAGScheduler: Missing parents: List()
18/06/25 11:56:59 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[145] at map at utils.scala:33), which has no missing parents
18/06/25 11:56:59 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 75.2 KB, free 340.1 MB)
18/06/25 11:56:59 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 26.7 KB, free 340.1 MB)
18/06/25 11:56:59 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53973 (size: 26.7 KB, free: 340.4 MB)
18/06/25 11:56:59 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
18/06/25 11:56:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[145] at map at utils.scala:33)
18/06/25 11:56:59 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
18/06/25 11:56:59 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 11:56:59 WARN TaskSetManager: Stage 31 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:56:59 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365305 bytes)
18/06/25 11:56:59 INFO Executor: Running task 0.0 in stage 31.0 (TID 34)
18/06/25 11:56:59 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:56:59 INFO CodeGenerator: Code generated in 4.919421 ms
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1413
18/06/25 11:56:59 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53973 in memory (size: 17.0 KB, free: 340.4 MB)
18/06/25 11:56:59 INFO ContextCleaner: Cleaned shuffle 10
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1654
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1653
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1652
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1651
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1650
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1649
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1648
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1647
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1646
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1645
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1644
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1643
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1642
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1641
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1640
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1639
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1638
18/06/25 11:56:59 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:53973 in memory (size: 26.6 KB, free: 340.4 MB)
18/06/25 11:56:59 INFO ContextCleaner: Cleaned shuffle 9
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1540
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1539
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1538
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1537
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1536
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1535
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1534
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1533
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1532
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1531
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1530
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1529
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1528
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1527
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1526
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1525
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1524
18/06/25 11:56:59 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53973 in memory (size: 17.0 KB, free: 340.4 MB)
18/06/25 11:56:59 INFO ContextCleaner: Cleaned shuffle 8
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1426
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1425
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1424
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1423
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1422
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1421
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1420
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1419
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1418
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1417
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1416
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1415
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1414
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1412
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1411
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1410
18/06/25 11:56:59 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53973 in memory (size: 23.0 KB, free: 340.5 MB)
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1257
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1256
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1255
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1254
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1253
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1252
18/06/25 11:56:59 INFO ContextCleaner: Cleaned accumulator 1251
18/06/25 11:57:00 INFO Executor: Finished task 0.0 in stage 31.0 (TID 34). 803098 bytes result sent to driver
18/06/25 11:57:00 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 34) in 1766 ms on localhost (executor driver) (1/1)
18/06/25 11:57:00 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/06/25 11:57:00 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:36) finished in 1.766 s
18/06/25 11:57:00 INFO DAGScheduler: Job 20 finished: collect at utils.scala:36, took 1.773067 s
18/06/25 11:58:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/06/25 11:58:10 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa96c1a30
18/06/25 11:58:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa96c1a30` AS `zzz9`
WHERE (0 = 1)
18/06/25 11:58:11 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa182b4a25
18/06/25 11:58:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa182b4a25` AS `zzz10`
WHERE (0 = 1)
18/06/25 11:58:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa96c1a30`
18/06/25 11:58:14 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:92
18/06/25 11:58:14 INFO DAGScheduler: Registering RDD 154 (countByValue at StringIndexer.scala:92)
18/06/25 11:58:14 INFO DAGScheduler: Got job 21 (countByValue at StringIndexer.scala:92) with 1 output partitions
18/06/25 11:58:14 INFO DAGScheduler: Final stage: ResultStage 33 (countByValue at StringIndexer.scala:92)
18/06/25 11:58:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
18/06/25 11:58:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
18/06/25 11:58:14 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[154] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 11:58:14 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 43.2 KB, free 340.3 MB)
18/06/25 11:58:14 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 16.0 KB, free 340.3 MB)
18/06/25 11:58:14 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53973 (size: 16.0 KB, free: 340.4 MB)
18/06/25 11:58:14 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[154] at countByValue at StringIndexer.scala:92)
18/06/25 11:58:14 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
18/06/25 11:58:14 WARN TaskSetManager: Stage 32 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:14 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365299 bytes)
18/06/25 11:58:14 INFO Executor: Running task 0.0 in stage 32.0 (TID 35)
18/06/25 11:58:15 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:15 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53973 in memory (size: 26.7 KB, free: 340.5 MB)
18/06/25 11:58:15 INFO ContextCleaner: Cleaned accumulator 1758
18/06/25 11:58:15 INFO ContextCleaner: Cleaned accumulator 1757
18/06/25 11:58:15 INFO ContextCleaner: Cleaned accumulator 1756
18/06/25 11:58:15 INFO ContextCleaner: Cleaned accumulator 1755
18/06/25 11:58:15 INFO ContextCleaner: Cleaned accumulator 1754
18/06/25 11:58:15 INFO ContextCleaner: Cleaned accumulator 1753
18/06/25 11:58:15 INFO ContextCleaner: Cleaned accumulator 1752
18/06/25 11:58:15 INFO ContextCleaner: Cleaned accumulator 1751
18/06/25 11:58:15 INFO Executor: Finished task 0.0 in stage 32.0 (TID 35). 2654 bytes result sent to driver
18/06/25 11:58:15 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 35) in 1075 ms on localhost (executor driver) (1/1)
18/06/25 11:58:15 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/06/25 11:58:15 INFO DAGScheduler: ShuffleMapStage 32 (countByValue at StringIndexer.scala:92) finished in 1.076 s
18/06/25 11:58:15 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:58:15 INFO DAGScheduler: running: Set()
18/06/25 11:58:15 INFO DAGScheduler: waiting: Set(ResultStage 33)
18/06/25 11:58:15 INFO DAGScheduler: failed: Set()
18/06/25 11:58:15 INFO DAGScheduler: Submitting ResultStage 33 (ShuffledRDD[155] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 11:58:15 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 3.2 KB, free 340.4 MB)
18/06/25 11:58:15 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 1970.0 B, free 340.4 MB)
18/06/25 11:58:15 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53973 (size: 1970.0 B, free: 340.5 MB)
18/06/25 11:58:15 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (ShuffledRDD[155] at countByValue at StringIndexer.scala:92)
18/06/25 11:58:15 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
18/06/25 11:58:15 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 36, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/06/25 11:58:15 INFO Executor: Running task 0.0 in stage 33.0 (TID 36)
18/06/25 11:58:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:58:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:58:15 INFO Executor: Finished task 0.0 in stage 33.0 (TID 36). 2331 bytes result sent to driver
18/06/25 11:58:15 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 36) in 8 ms on localhost (executor driver) (1/1)
18/06/25 11:58:15 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/06/25 11:58:15 INFO DAGScheduler: ResultStage 33 (countByValue at StringIndexer.scala:92) finished in 0.010 s
18/06/25 11:58:15 INFO DAGScheduler: Job 21 finished: countByValue at StringIndexer.scala:92, took 1.098714 s
18/06/25 11:58:15 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 11:58:15 INFO DAGScheduler: Got job 22 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 11:58:15 INFO DAGScheduler: Final stage: ResultStage 34 (first at LinearRegression.scala:198)
18/06/25 11:58:15 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:58:15 INFO DAGScheduler: Missing parents: List()
18/06/25 11:58:15 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[158] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 11:58:15 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 60.4 KB, free 340.4 MB)
18/06/25 11:58:15 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 21.8 KB, free 340.3 MB)
18/06/25 11:58:15 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53973 (size: 21.8 KB, free: 340.4 MB)
18/06/25 11:58:15 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[158] at first at LinearRegression.scala:198)
18/06/25 11:58:15 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
18/06/25 11:58:16 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53973 in memory (size: 1970.0 B, free: 340.4 MB)
18/06/25 11:58:16 WARN TaskSetManager: Stage 34 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:16 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 11:58:16 INFO Executor: Running task 0.0 in stage 34.0 (TID 37)
18/06/25 11:58:16 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:16 INFO Executor: Finished task 0.0 in stage 34.0 (TID 37). 2178 bytes result sent to driver
18/06/25 11:58:16 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 37) in 728 ms on localhost (executor driver) (1/1)
18/06/25 11:58:16 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/06/25 11:58:16 INFO DAGScheduler: ResultStage 34 (first at LinearRegression.scala:198) finished in 0.728 s
18/06/25 11:58:16 INFO DAGScheduler: Job 22 finished: first at LinearRegression.scala:198, took 0.734986 s
18/06/25 11:58:16 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
18/06/25 11:58:16 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
18/06/25 11:58:16 INFO DAGScheduler: Got job 23 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
18/06/25 11:58:16 INFO DAGScheduler: Final stage: ResultStage 35 (treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 11:58:16 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:58:16 INFO DAGScheduler: Missing parents: List()
18/06/25 11:58:16 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[164] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
18/06/25 11:58:16 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 63.3 KB, free 340.3 MB)
18/06/25 11:58:16 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 23.1 KB, free 340.3 MB)
18/06/25 11:58:16 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53973 (size: 23.1 KB, free: 340.4 MB)
18/06/25 11:58:16 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[164] at treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 11:58:16 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
18/06/25 11:58:16 WARN TaskSetManager: Stage 35 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:16 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365311 bytes)
18/06/25 11:58:16 INFO Executor: Running task 0.0 in stage 35.0 (TID 38)
18/06/25 11:58:17 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1911
18/06/25 11:58:17 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53973 in memory (size: 21.8 KB, free: 340.4 MB)
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1916
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1915
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1914
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1913
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1912
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1910
18/06/25 11:58:17 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53973 in memory (size: 16.0 KB, free: 340.5 MB)
18/06/25 11:58:17 INFO ContextCleaner: Cleaned shuffle 11
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1813
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1812
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1811
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1810
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1809
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1808
18/06/25 11:58:17 INFO ContextCleaner: Cleaned accumulator 1807
18/06/25 11:58:17 INFO Executor: Finished task 0.0 in stage 35.0 (TID 38). 4010 bytes result sent to driver
18/06/25 11:58:17 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 38) in 1257 ms on localhost (executor driver) (1/1)
18/06/25 11:58:17 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/06/25 11:58:17 INFO DAGScheduler: ResultStage 35 (treeAggregate at WeightedLeastSquares.scala:100) finished in 1.257 s
18/06/25 11:58:17 INFO DAGScheduler: Job 23 finished: treeAggregate at WeightedLeastSquares.scala:100, took 1.262723 s
18/06/25 11:58:17 INFO WeightedLeastSquares: Number of instances: 190884.
18/06/25 11:58:18 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
18/06/25 11:58:18 INFO DAGScheduler: Got job 24 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
18/06/25 11:58:18 INFO DAGScheduler: Final stage: ResultStage 36 (aggregate at RegressionMetrics.scala:57)
18/06/25 11:58:18 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:58:18 INFO DAGScheduler: Missing parents: List()
18/06/25 11:58:18 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[170] at map at RegressionMetrics.scala:55), which has no missing parents
18/06/25 11:58:18 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 62.0 KB, free 340.3 MB)
18/06/25 11:58:18 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 23.1 KB, free 340.3 MB)
18/06/25 11:58:18 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53973 (size: 23.1 KB, free: 340.4 MB)
18/06/25 11:58:18 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[170] at map at RegressionMetrics.scala:55)
18/06/25 11:58:18 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
18/06/25 11:58:18 WARN TaskSetManager: Stage 36 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:18 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365307 bytes)
18/06/25 11:58:18 INFO Executor: Running task 0.0 in stage 36.0 (TID 39)
18/06/25 11:58:18 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:18 INFO Executor: Finished task 0.0 in stage 36.0 (TID 39). 2604 bytes result sent to driver
18/06/25 11:58:18 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 959 ms on localhost (executor driver) (1/1)
18/06/25 11:58:18 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/06/25 11:58:18 INFO DAGScheduler: ResultStage 36 (aggregate at RegressionMetrics.scala:57) finished in 0.960 s
18/06/25 11:58:18 INFO DAGScheduler: Job 24 finished: aggregate at RegressionMetrics.scala:57, took 0.963934 s
18/06/25 11:58:18 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
18/06/25 11:58:18 INFO DAGScheduler: Got job 25 (sum at RegressionMetrics.scala:71) with 1 output partitions
18/06/25 11:58:18 INFO DAGScheduler: Final stage: ResultStage 37 (sum at RegressionMetrics.scala:71)
18/06/25 11:58:18 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:58:18 INFO DAGScheduler: Missing parents: List()
18/06/25 11:58:18 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[171] at map at RegressionMetrics.scala:69), which has no missing parents
18/06/25 11:58:18 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 61.5 KB, free 340.2 MB)
18/06/25 11:58:18 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 22.9 KB, free 340.2 MB)
18/06/25 11:58:18 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53973 (size: 22.9 KB, free: 340.4 MB)
18/06/25 11:58:18 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[171] at map at RegressionMetrics.scala:69)
18/06/25 11:58:18 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
18/06/25 11:58:19 WARN TaskSetManager: Stage 37 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:19 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365301 bytes)
18/06/25 11:58:19 INFO Executor: Running task 0.0 in stage 37.0 (TID 40)
18/06/25 11:58:19 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:19 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53973 in memory (size: 23.1 KB, free: 340.4 MB)
18/06/25 11:58:19 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53973 in memory (size: 23.1 KB, free: 340.5 MB)
18/06/25 11:58:20 INFO Executor: Finished task 0.0 in stage 37.0 (TID 40). 2121 bytes result sent to driver
18/06/25 11:58:20 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 40) in 1104 ms on localhost (executor driver) (1/1)
18/06/25 11:58:20 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/06/25 11:58:20 INFO DAGScheduler: ResultStage 37 (sum at RegressionMetrics.scala:71) finished in 1.105 s
18/06/25 11:58:20 INFO DAGScheduler: Job 25 finished: sum at RegressionMetrics.scala:71, took 1.109936 s
18/06/25 11:58:20 INFO SparkContext: Starting job: count at LinearRegression.scala:683
18/06/25 11:58:20 INFO DAGScheduler: Registering RDD 174 (count at LinearRegression.scala:683)
18/06/25 11:58:20 INFO DAGScheduler: Got job 26 (count at LinearRegression.scala:683) with 1 output partitions
18/06/25 11:58:20 INFO DAGScheduler: Final stage: ResultStage 39 (count at LinearRegression.scala:683)
18/06/25 11:58:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
18/06/25 11:58:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
18/06/25 11:58:20 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[174] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 11:58:20 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 45.4 KB, free 340.3 MB)
18/06/25 11:58:20 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 17.0 KB, free 340.3 MB)
18/06/25 11:58:20 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53973 (size: 17.0 KB, free: 340.4 MB)
18/06/25 11:58:20 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[174] at count at LinearRegression.scala:683)
18/06/25 11:58:20 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
18/06/25 11:58:20 WARN TaskSetManager: Stage 38 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:20 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 11:58:20 INFO Executor: Running task 0.0 in stage 38.0 (TID 41)
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2123
18/06/25 11:58:20 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:20 INFO Executor: Finished task 0.0 in stage 38.0 (TID 41). 2839 bytes result sent to driver
18/06/25 11:58:20 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 41) in 592 ms on localhost (executor driver) (1/1)
18/06/25 11:58:20 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/06/25 11:58:20 INFO DAGScheduler: ShuffleMapStage 38 (count at LinearRegression.scala:683) finished in 0.592 s
18/06/25 11:58:20 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:58:20 INFO DAGScheduler: running: Set()
18/06/25 11:58:20 INFO DAGScheduler: waiting: Set(ResultStage 39)
18/06/25 11:58:20 INFO DAGScheduler: failed: Set()
18/06/25 11:58:20 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[177] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 11:58:20 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 7.0 KB, free 340.3 MB)
18/06/25 11:58:20 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.3 MB)
18/06/25 11:58:20 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.4 MB)
18/06/25 11:58:20 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[177] at count at LinearRegression.scala:683)
18/06/25 11:58:20 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
18/06/25 11:58:20 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 42, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 11:58:20 INFO Executor: Running task 0.0 in stage 39.0 (TID 42)
18/06/25 11:58:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:58:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:58:20 INFO Executor: Finished task 0.0 in stage 39.0 (TID 42). 2042 bytes result sent to driver
18/06/25 11:58:20 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 42) in 3 ms on localhost (executor driver) (1/1)
18/06/25 11:58:20 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/06/25 11:58:20 INFO DAGScheduler: ResultStage 39 (count at LinearRegression.scala:683) finished in 0.004 s
18/06/25 11:58:20 INFO DAGScheduler: Job 26 finished: count at LinearRegression.scala:683, took 0.605558 s
18/06/25 11:58:20 INFO SparkContext: Starting job: first at LinearRegression.scala:707
18/06/25 11:58:20 INFO DAGScheduler: Registering RDD 180 (first at LinearRegression.scala:707)
18/06/25 11:58:20 INFO DAGScheduler: Got job 27 (first at LinearRegression.scala:707) with 1 output partitions
18/06/25 11:58:20 INFO DAGScheduler: Final stage: ResultStage 41 (first at LinearRegression.scala:707)
18/06/25 11:58:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
18/06/25 11:58:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
18/06/25 11:58:20 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[180] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 11:58:20 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 69.1 KB, free 340.3 MB)
18/06/25 11:58:20 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 26.6 KB, free 340.2 MB)
18/06/25 11:58:20 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53973 (size: 26.6 KB, free: 340.4 MB)
18/06/25 11:58:20 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[180] at first at LinearRegression.scala:707)
18/06/25 11:58:20 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2130
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2124
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2125
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2126
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2127
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2128
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2129
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2131
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2132
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2133
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2134
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2135
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2136
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2137
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2138
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2139
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2140
18/06/25 11:58:20 INFO ContextCleaner: Cleaned shuffle 12
18/06/25 11:58:20 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53973 in memory (size: 17.0 KB, free: 340.4 MB)
18/06/25 11:58:20 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 11:58:20 INFO ContextCleaner: Cleaned accumulator 2237
18/06/25 11:58:20 WARN TaskSetManager: Stage 40 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:20 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365238 bytes)
18/06/25 11:58:20 INFO Executor: Running task 0.0 in stage 40.0 (TID 43)
18/06/25 11:58:21 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:21 INFO Executor: Finished task 0.0 in stage 40.0 (TID 43). 2839 bytes result sent to driver
18/06/25 11:58:21 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 43) in 959 ms on localhost (executor driver) (1/1)
18/06/25 11:58:21 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/06/25 11:58:21 INFO DAGScheduler: ShuffleMapStage 40 (first at LinearRegression.scala:707) finished in 0.960 s
18/06/25 11:58:21 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:58:21 INFO DAGScheduler: running: Set()
18/06/25 11:58:21 INFO DAGScheduler: waiting: Set(ResultStage 41)
18/06/25 11:58:21 INFO DAGScheduler: failed: Set()
18/06/25 11:58:21 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[183] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 11:58:21 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 7.9 KB, free 340.3 MB)
18/06/25 11:58:21 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 4.0 KB, free 340.3 MB)
18/06/25 11:58:21 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53973 (size: 4.0 KB, free: 340.4 MB)
18/06/25 11:58:21 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[183] at first at LinearRegression.scala:707)
18/06/25 11:58:21 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
18/06/25 11:58:21 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 44, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/06/25 11:58:21 INFO Executor: Running task 0.0 in stage 41.0 (TID 44)
18/06/25 11:58:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:58:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:58:21 INFO Executor: Finished task 0.0 in stage 41.0 (TID 44). 2027 bytes result sent to driver
18/06/25 11:58:21 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 44) in 6 ms on localhost (executor driver) (1/1)
18/06/25 11:58:21 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/06/25 11:58:21 INFO DAGScheduler: ResultStage 41 (first at LinearRegression.scala:707) finished in 0.006 s
18/06/25 11:58:21 INFO DAGScheduler: Job 27 finished: first at LinearRegression.scala:707, took 0.977120 s
18/06/25 11:58:21 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfad1e3277
18/06/25 11:58:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfad1e3277` AS `zzz11`
WHERE (0 = 1)
18/06/25 11:58:21 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa3983295b
18/06/25 11:58:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa3983295b` AS `zzz12`
WHERE (0 = 1)
18/06/25 11:58:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa96c1a30`
18/06/25 11:58:21 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa521032dc
18/06/25 11:58:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa521032dc` AS `zzz13`
WHERE (0 = 1)
18/06/25 11:58:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa521032dc`
18/06/25 11:58:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 11:58:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa3983295b`
18/06/25 11:58:24 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
18/06/25 11:58:24 INFO DAGScheduler: Registering RDD 189 (count at NativeMethodAccessorImpl.java:0)
18/06/25 11:58:24 INFO DAGScheduler: Got job 28 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 11:58:24 INFO DAGScheduler: Final stage: ResultStage 43 (count at NativeMethodAccessorImpl.java:0)
18/06/25 11:58:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
18/06/25 11:58:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 42)
18/06/25 11:58:24 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[189] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:58:24 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 45.4 KB, free 340.2 MB)
18/06/25 11:58:24 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 17.0 KB, free 340.2 MB)
18/06/25 11:58:24 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53973 (size: 17.0 KB, free: 340.4 MB)
18/06/25 11:58:24 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[189] at count at NativeMethodAccessorImpl.java:0)
18/06/25 11:58:24 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
18/06/25 11:58:24 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53973 in memory (size: 4.0 KB, free: 340.4 MB)
18/06/25 11:58:24 INFO ContextCleaner: Cleaned accumulator 2351
18/06/25 11:58:24 WARN TaskSetManager: Stage 42 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:24 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 11:58:24 INFO Executor: Running task 0.0 in stage 42.0 (TID 45)
18/06/25 11:58:24 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 1971
18/06/25 11:58:25 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:53973 in memory (size: 26.6 KB, free: 340.4 MB)
18/06/25 11:58:25 INFO ContextCleaner: Cleaned shuffle 13
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2254
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2253
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2252
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2251
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2250
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2249
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2248
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2247
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2246
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2245
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2244
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2243
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2242
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2241
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2240
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2239
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 2238
18/06/25 11:58:25 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53973 in memory (size: 22.9 KB, free: 340.5 MB)
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 1970
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 1969
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 1968
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 1967
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 1966
18/06/25 11:58:25 INFO ContextCleaner: Cleaned accumulator 1965
18/06/25 11:58:25 INFO Executor: Finished task 0.0 in stage 42.0 (TID 45). 2926 bytes result sent to driver
18/06/25 11:58:25 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 45) in 863 ms on localhost (executor driver) (1/1)
18/06/25 11:58:25 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/06/25 11:58:25 INFO DAGScheduler: ShuffleMapStage 42 (count at NativeMethodAccessorImpl.java:0) finished in 0.864 s
18/06/25 11:58:25 INFO DAGScheduler: looking for newly runnable stages
18/06/25 11:58:25 INFO DAGScheduler: running: Set()
18/06/25 11:58:25 INFO DAGScheduler: waiting: Set(ResultStage 43)
18/06/25 11:58:25 INFO DAGScheduler: failed: Set()
18/06/25 11:58:25 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[192] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 11:58:25 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
18/06/25 11:58:25 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
18/06/25 11:58:25 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.5 MB)
18/06/25 11:58:25 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[192] at count at NativeMethodAccessorImpl.java:0)
18/06/25 11:58:25 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
18/06/25 11:58:25 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 46, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 11:58:25 INFO Executor: Running task 0.0 in stage 43.0 (TID 46)
18/06/25 11:58:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 11:58:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 11:58:25 INFO Executor: Finished task 0.0 in stage 43.0 (TID 46). 2042 bytes result sent to driver
18/06/25 11:58:25 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 46) in 4 ms on localhost (executor driver) (1/1)
18/06/25 11:58:25 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/06/25 11:58:25 INFO DAGScheduler: ResultStage 43 (count at NativeMethodAccessorImpl.java:0) finished in 0.004 s
18/06/25 11:58:25 INFO DAGScheduler: Job 28 finished: count at NativeMethodAccessorImpl.java:0, took 0.880454 s
18/06/25 11:58:25 INFO CodeGenerator: Code generated in 40.548208 ms
18/06/25 11:58:25 INFO SparkContext: Starting job: collect at utils.scala:36
18/06/25 11:58:25 INFO DAGScheduler: Got job 29 (collect at utils.scala:36) with 1 output partitions
18/06/25 11:58:25 INFO DAGScheduler: Final stage: ResultStage 44 (collect at utils.scala:36)
18/06/25 11:58:25 INFO DAGScheduler: Parents of final stage: List()
18/06/25 11:58:25 INFO DAGScheduler: Missing parents: List()
18/06/25 11:58:25 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[197] at map at utils.scala:33), which has no missing parents
18/06/25 11:58:25 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 75.2 KB, free 340.3 MB)
18/06/25 11:58:25 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 26.7 KB, free 340.3 MB)
18/06/25 11:58:25 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53973 (size: 26.7 KB, free: 340.4 MB)
18/06/25 11:58:25 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
18/06/25 11:58:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[197] at map at utils.scala:33)
18/06/25 11:58:25 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
18/06/25 11:58:25 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 11:58:25 WARN TaskSetManager: Stage 44 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 11:58:25 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365305 bytes)
18/06/25 11:58:25 INFO Executor: Running task 0.0 in stage 44.0 (TID 47)
18/06/25 11:58:25 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 11:58:26 INFO Executor: Finished task 0.0 in stage 44.0 (TID 47). 805180 bytes result sent to driver
18/06/25 11:58:26 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 47) in 1278 ms on localhost (executor driver) (1/1)
18/06/25 11:58:26 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/06/25 11:58:26 INFO DAGScheduler: ResultStage 44 (collect at utils.scala:36) finished in 1.278 s
18/06/25 11:58:26 INFO DAGScheduler: Job 29 finished: collect at utils.scala:36, took 1.285507 s
18/06/25 12:01:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:01:40 INFO SparkSqlParser: Parsing command: SELECT * FROM flights LIMIT 1000
18/06/25 12:01:40 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 12:01:40 INFO DAGScheduler: Got job 30 (collect at utils.scala:196) with 1 output partitions
18/06/25 12:01:40 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:196)
18/06/25 12:01:40 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:01:40 INFO DAGScheduler: Missing parents: List()
18/06/25 12:01:40 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[199] at collect at utils.scala:196), which has no missing parents
18/06/25 12:01:40 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 26.4 KB, free 340.3 MB)
18/06/25 12:01:40 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 9.8 KB, free 340.3 MB)
18/06/25 12:01:40 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53973 (size: 9.8 KB, free: 340.4 MB)
18/06/25 12:01:40 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
18/06/25 12:01:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[199] at collect at utils.scala:196)
18/06/25 12:01:40 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
18/06/25 12:01:41 WARN TaskSetManager: Stage 45 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:01:41 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 12:01:41 INFO Executor: Running task 0.0 in stage 45.0 (TID 48)
18/06/25 12:01:41 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:01:41 WARN Executor: 1 block locks were not released by TID = 48:
[rdd_37_0]
18/06/25 12:01:41 INFO Executor: Finished task 0.0 in stage 45.0 (TID 48). 60938 bytes result sent to driver
18/06/25 12:01:41 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 48) in 482 ms on localhost (executor driver) (1/1)
18/06/25 12:01:41 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/06/25 12:01:41 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:196) finished in 0.483 s
18/06/25 12:01:41 INFO DAGScheduler: Job 30 finished: collect at utils.scala:196, took 0.489072 s
18/06/25 12:01:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:01:41 INFO SparkSqlParser: Parsing command: SELECT * FROM flights LIMIT 1000
18/06/25 12:01:41 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 12:01:41 INFO DAGScheduler: Got job 31 (collect at utils.scala:196) with 1 output partitions
18/06/25 12:01:41 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:196)
18/06/25 12:01:41 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:01:41 INFO DAGScheduler: Missing parents: List()
18/06/25 12:01:41 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[201] at collect at utils.scala:196), which has no missing parents
18/06/25 12:01:41 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 26.4 KB, free 340.3 MB)
18/06/25 12:01:41 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 9.7 KB, free 340.2 MB)
18/06/25 12:01:41 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53973 (size: 9.7 KB, free: 340.4 MB)
18/06/25 12:01:41 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
18/06/25 12:01:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[201] at collect at utils.scala:196)
18/06/25 12:01:41 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
18/06/25 12:01:41 WARN TaskSetManager: Stage 46 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:01:41 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 12:01:41 INFO Executor: Running task 0.0 in stage 46.0 (TID 49)
18/06/25 12:01:41 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:01:41 WARN Executor: 1 block locks were not released by TID = 49:
[rdd_37_0]
18/06/25 12:01:41 INFO Executor: Finished task 0.0 in stage 46.0 (TID 49). 60938 bytes result sent to driver
18/06/25 12:01:41 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 49) in 376 ms on localhost (executor driver) (1/1)
18/06/25 12:01:41 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
18/06/25 12:01:41 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:196) finished in 0.376 s
18/06/25 12:01:41 INFO DAGScheduler: Job 31 finished: collect at utils.scala:196, took 0.382770 s
18/06/25 12:03:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:03:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa96c1a30`
18/06/25 12:03:01 INFO CodeGenerator: Code generated in 18.573124 ms
18/06/25 12:03:01 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 12:03:01 INFO DAGScheduler: Got job 32 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 12:03:01 INFO DAGScheduler: Final stage: ResultStage 47 (first at LinearRegression.scala:198)
18/06/25 12:03:01 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:03:01 INFO DAGScheduler: Missing parents: List()
18/06/25 12:03:01 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[204] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 12:03:01 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 50.4 KB, free 340.2 MB)
18/06/25 12:03:01 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 18.3 KB, free 340.2 MB)
18/06/25 12:03:01 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53973 (size: 18.3 KB, free: 340.4 MB)
18/06/25 12:03:01 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[204] at first at LinearRegression.scala:198)
18/06/25 12:03:01 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
18/06/25 12:03:02 WARN TaskSetManager: Stage 47 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:03:02 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 12:03:02 INFO Executor: Running task 0.0 in stage 47.0 (TID 50)
18/06/25 12:03:02 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2362
18/06/25 12:03:02 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53973 in memory (size: 9.7 KB, free: 340.4 MB)
18/06/25 12:03:02 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53973 in memory (size: 9.8 KB, free: 340.4 MB)
18/06/25 12:03:02 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53973 in memory (size: 26.7 KB, free: 340.4 MB)
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2472
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2471
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2470
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2469
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2468
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2467
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2466
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2465
18/06/25 12:03:02 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53973 in memory (size: 17.0 KB, free: 340.5 MB)
18/06/25 12:03:02 INFO ContextCleaner: Cleaned shuffle 14
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2368
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2367
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2366
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2365
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2364
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2363
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2361
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2360
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2359
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2358
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2357
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2356
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2355
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2354
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2353
18/06/25 12:03:02 INFO ContextCleaner: Cleaned accumulator 2352
18/06/25 12:03:02 INFO Executor: Finished task 0.0 in stage 47.0 (TID 50). 2164 bytes result sent to driver
18/06/25 12:03:02 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 50) in 1121 ms on localhost (executor driver) (1/1)
18/06/25 12:03:02 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/06/25 12:03:02 INFO DAGScheduler: ResultStage 47 (first at LinearRegression.scala:198) finished in 1.121 s
18/06/25 12:03:02 INFO DAGScheduler: Job 32 finished: first at LinearRegression.scala:198, took 1.129562 s
18/06/25 12:03:03 INFO CodeGenerator: Code generated in 14.927017 ms
18/06/25 12:03:03 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
18/06/25 12:03:03 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
18/06/25 12:03:03 INFO DAGScheduler: Got job 33 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
18/06/25 12:03:03 INFO DAGScheduler: Final stage: ResultStage 48 (treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 12:03:03 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:03:03 INFO DAGScheduler: Missing parents: List()
18/06/25 12:03:03 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[210] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
18/06/25 12:03:03 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 53.3 KB, free 340.4 MB)
18/06/25 12:03:03 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 19.6 KB, free 340.3 MB)
18/06/25 12:03:03 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53973 (size: 19.6 KB, free: 340.4 MB)
18/06/25 12:03:03 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[210] at treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 12:03:03 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
18/06/25 12:03:03 WARN TaskSetManager: Stage 48 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:03:03 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365311 bytes)
18/06/25 12:03:03 INFO Executor: Running task 0.0 in stage 48.0 (TID 51)
18/06/25 12:03:03 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:03:04 INFO Executor: Finished task 0.0 in stage 48.0 (TID 51). 2605 bytes result sent to driver
18/06/25 12:03:04 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 51) in 1133 ms on localhost (executor driver) (1/1)
18/06/25 12:03:04 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/06/25 12:03:04 INFO DAGScheduler: ResultStage 48 (treeAggregate at WeightedLeastSquares.scala:100) finished in 1.133 s
18/06/25 12:03:04 INFO DAGScheduler: Job 33 finished: treeAggregate at WeightedLeastSquares.scala:100, took 1.139272 s
18/06/25 12:03:04 INFO WeightedLeastSquares: Number of instances: 190884.
18/06/25 12:03:04 INFO CodeGenerator: Code generated in 12.998308 ms
18/06/25 12:03:04 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
18/06/25 12:03:04 INFO DAGScheduler: Got job 34 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
18/06/25 12:03:04 INFO DAGScheduler: Final stage: ResultStage 49 (aggregate at RegressionMetrics.scala:57)
18/06/25 12:03:04 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:03:04 INFO DAGScheduler: Missing parents: List()
18/06/25 12:03:04 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[216] at map at RegressionMetrics.scala:55), which has no missing parents
18/06/25 12:03:04 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 53.5 KB, free 340.3 MB)
18/06/25 12:03:04 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 20.2 KB, free 340.3 MB)
18/06/25 12:03:04 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53973 (size: 20.2 KB, free: 340.4 MB)
18/06/25 12:03:04 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[216] at map at RegressionMetrics.scala:55)
18/06/25 12:03:04 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
18/06/25 12:03:04 WARN TaskSetManager: Stage 49 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:03:04 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365307 bytes)
18/06/25 12:03:04 INFO Executor: Running task 0.0 in stage 49.0 (TID 52)
18/06/25 12:03:04 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:03:05 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53973 in memory (size: 19.6 KB, free: 340.4 MB)
18/06/25 12:03:05 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53973 in memory (size: 18.3 KB, free: 340.5 MB)
18/06/25 12:03:05 INFO ContextCleaner: Cleaned accumulator 2625
18/06/25 12:03:05 INFO ContextCleaner: Cleaned accumulator 2624
18/06/25 12:03:05 INFO ContextCleaner: Cleaned accumulator 2623
18/06/25 12:03:05 INFO ContextCleaner: Cleaned accumulator 2622
18/06/25 12:03:05 INFO ContextCleaner: Cleaned accumulator 2621
18/06/25 12:03:05 INFO ContextCleaner: Cleaned accumulator 2620
18/06/25 12:03:05 INFO ContextCleaner: Cleaned accumulator 2619
18/06/25 12:03:05 INFO Executor: Finished task 0.0 in stage 49.0 (TID 52). 2691 bytes result sent to driver
18/06/25 12:03:05 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 52) in 1178 ms on localhost (executor driver) (1/1)
18/06/25 12:03:05 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
18/06/25 12:03:05 INFO DAGScheduler: ResultStage 49 (aggregate at RegressionMetrics.scala:57) finished in 1.178 s
18/06/25 12:03:05 INFO DAGScheduler: Job 34 finished: aggregate at RegressionMetrics.scala:57, took 1.186638 s
18/06/25 12:03:05 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
18/06/25 12:03:05 INFO DAGScheduler: Got job 35 (sum at RegressionMetrics.scala:71) with 1 output partitions
18/06/25 12:03:05 INFO DAGScheduler: Final stage: ResultStage 50 (sum at RegressionMetrics.scala:71)
18/06/25 12:03:05 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:03:05 INFO DAGScheduler: Missing parents: List()
18/06/25 12:03:05 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[217] at map at RegressionMetrics.scala:69), which has no missing parents
18/06/25 12:03:05 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 53.1 KB, free 340.4 MB)
18/06/25 12:03:05 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 20.2 KB, free 340.3 MB)
18/06/25 12:03:05 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53973 (size: 20.2 KB, free: 340.4 MB)
18/06/25 12:03:05 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[217] at map at RegressionMetrics.scala:69)
18/06/25 12:03:05 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
18/06/25 12:03:05 WARN TaskSetManager: Stage 50 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:03:05 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365301 bytes)
18/06/25 12:03:05 INFO Executor: Running task 0.0 in stage 50.0 (TID 53)
18/06/25 12:03:05 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:03:06 INFO Executor: Finished task 0.0 in stage 50.0 (TID 53). 2121 bytes result sent to driver
18/06/25 12:03:06 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 53) in 766 ms on localhost (executor driver) (1/1)
18/06/25 12:03:06 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/06/25 12:03:06 INFO DAGScheduler: ResultStage 50 (sum at RegressionMetrics.scala:71) finished in 0.766 s
18/06/25 12:03:06 INFO DAGScheduler: Job 35 finished: sum at RegressionMetrics.scala:71, took 0.771412 s
18/06/25 12:03:06 INFO SparkContext: Starting job: count at LinearRegression.scala:683
18/06/25 12:03:06 INFO DAGScheduler: Registering RDD 220 (count at LinearRegression.scala:683)
18/06/25 12:03:06 INFO DAGScheduler: Got job 36 (count at LinearRegression.scala:683) with 1 output partitions
18/06/25 12:03:06 INFO DAGScheduler: Final stage: ResultStage 52 (count at LinearRegression.scala:683)
18/06/25 12:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
18/06/25 12:03:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 51)
18/06/25 12:03:06 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[220] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 12:03:06 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 45.4 KB, free 340.3 MB)
18/06/25 12:03:06 INFO ContextCleaner: Cleaned accumulator 2832
18/06/25 12:03:06 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.0 KB, free 340.3 MB)
18/06/25 12:03:06 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53973 (size: 17.0 KB, free: 340.4 MB)
18/06/25 12:03:06 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[220] at count at LinearRegression.scala:683)
18/06/25 12:03:06 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
18/06/25 12:03:06 WARN TaskSetManager: Stage 51 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:03:06 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 12:03:06 INFO Executor: Running task 0.0 in stage 51.0 (TID 54)
18/06/25 12:03:06 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:03:06 INFO Executor: Finished task 0.0 in stage 51.0 (TID 54). 2839 bytes result sent to driver
18/06/25 12:03:06 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 54) in 615 ms on localhost (executor driver) (1/1)
18/06/25 12:03:06 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/06/25 12:03:06 INFO DAGScheduler: ShuffleMapStage 51 (count at LinearRegression.scala:683) finished in 0.616 s
18/06/25 12:03:06 INFO DAGScheduler: looking for newly runnable stages
18/06/25 12:03:06 INFO DAGScheduler: running: Set()
18/06/25 12:03:06 INFO DAGScheduler: waiting: Set(ResultStage 52)
18/06/25 12:03:06 INFO DAGScheduler: failed: Set()
18/06/25 12:03:06 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[223] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 12:03:06 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 7.0 KB, free 340.3 MB)
18/06/25 12:03:06 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.3 MB)
18/06/25 12:03:06 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.4 MB)
18/06/25 12:03:06 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[223] at count at LinearRegression.scala:683)
18/06/25 12:03:06 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
18/06/25 12:03:06 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 55, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 12:03:06 INFO Executor: Running task 0.0 in stage 52.0 (TID 55)
18/06/25 12:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 12:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 12:03:06 INFO Executor: Finished task 0.0 in stage 52.0 (TID 55). 2042 bytes result sent to driver
18/06/25 12:03:06 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 55) in 3 ms on localhost (executor driver) (1/1)
18/06/25 12:03:06 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
18/06/25 12:03:06 INFO DAGScheduler: ResultStage 52 (count at LinearRegression.scala:683) finished in 0.004 s
18/06/25 12:03:06 INFO DAGScheduler: Job 36 finished: count at LinearRegression.scala:683, took 0.635932 s
18/06/25 12:03:06 INFO CodeGenerator: Code generated in 21.618064 ms
18/06/25 12:03:06 INFO SparkContext: Starting job: first at LinearRegression.scala:707
18/06/25 12:03:06 INFO DAGScheduler: Registering RDD 226 (first at LinearRegression.scala:707)
18/06/25 12:03:06 INFO DAGScheduler: Got job 37 (first at LinearRegression.scala:707) with 1 output partitions
18/06/25 12:03:06 INFO DAGScheduler: Final stage: ResultStage 54 (first at LinearRegression.scala:707)
18/06/25 12:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
18/06/25 12:03:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
18/06/25 12:03:06 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[226] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 12:03:06 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 60.4 KB, free 340.2 MB)
18/06/25 12:03:06 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 23.2 KB, free 340.2 MB)
18/06/25 12:03:06 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53973 (size: 23.2 KB, free: 340.4 MB)
18/06/25 12:03:06 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[226] at first at LinearRegression.scala:707)
18/06/25 12:03:06 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2839
18/06/25 12:03:07 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2946
18/06/25 12:03:07 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53973 in memory (size: 17.0 KB, free: 340.4 MB)
18/06/25 12:03:07 INFO ContextCleaner: Cleaned shuffle 15
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2849
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2848
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2847
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2846
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2845
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2844
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2843
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2842
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2841
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2840
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2838
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2837
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2836
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2835
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2834
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2833
18/06/25 12:03:07 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53973 in memory (size: 20.2 KB, free: 340.4 MB)
18/06/25 12:03:07 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53973 in memory (size: 20.2 KB, free: 340.5 MB)
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2680
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2679
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2678
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2677
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2676
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2675
18/06/25 12:03:07 INFO ContextCleaner: Cleaned accumulator 2674
18/06/25 12:03:07 WARN TaskSetManager: Stage 53 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:03:07 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365238 bytes)
18/06/25 12:03:07 INFO Executor: Running task 0.0 in stage 53.0 (TID 56)
18/06/25 12:03:07 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:03:08 INFO Executor: Finished task 0.0 in stage 53.0 (TID 56). 2926 bytes result sent to driver
18/06/25 12:03:08 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 56) in 1187 ms on localhost (executor driver) (1/1)
18/06/25 12:03:08 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/06/25 12:03:08 INFO DAGScheduler: ShuffleMapStage 53 (first at LinearRegression.scala:707) finished in 1.188 s
18/06/25 12:03:08 INFO DAGScheduler: looking for newly runnable stages
18/06/25 12:03:08 INFO DAGScheduler: running: Set()
18/06/25 12:03:08 INFO DAGScheduler: waiting: Set(ResultStage 54)
18/06/25 12:03:08 INFO DAGScheduler: failed: Set()
18/06/25 12:03:08 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[229] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 12:03:08 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 7.9 KB, free 340.4 MB)
18/06/25 12:03:08 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 4.0 KB, free 340.4 MB)
18/06/25 12:03:08 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53973 (size: 4.0 KB, free: 340.4 MB)
18/06/25 12:03:08 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[229] at first at LinearRegression.scala:707)
18/06/25 12:03:08 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
18/06/25 12:03:08 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 57, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/06/25 12:03:08 INFO Executor: Running task 0.0 in stage 54.0 (TID 57)
18/06/25 12:03:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 12:03:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 12:03:08 INFO Executor: Finished task 0.0 in stage 54.0 (TID 57). 2027 bytes result sent to driver
18/06/25 12:03:08 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 57) in 3 ms on localhost (executor driver) (1/1)
18/06/25 12:03:08 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
18/06/25 12:03:08 INFO DAGScheduler: ResultStage 54 (first at LinearRegression.scala:707) finished in 0.004 s
18/06/25 12:03:08 INFO DAGScheduler: Job 37 finished: first at LinearRegression.scala:707, took 1.202557 s
18/06/25 12:03:08 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa3b170406
18/06/25 12:03:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:03:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa3b170406` AS `zzz14`
WHERE (0 = 1)
18/06/25 12:03:08 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa64094438
18/06/25 12:03:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:03:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa64094438` AS `zzz15`
WHERE (0 = 1)
18/06/25 12:03:08 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53973 in memory (size: 4.0 KB, free: 340.5 MB)
18/06/25 12:03:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:03:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa96c1a30`
18/06/25 12:03:08 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa1c5debd7
18/06/25 12:03:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:03:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa1c5debd7` AS `zzz16`
WHERE (0 = 1)
18/06/25 12:03:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:03:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa1c5debd7`
18/06/25 12:03:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:03:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa64094438`
18/06/25 12:03:12 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
18/06/25 12:03:12 INFO DAGScheduler: Registering RDD 235 (count at NativeMethodAccessorImpl.java:0)
18/06/25 12:03:12 INFO DAGScheduler: Got job 38 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 12:03:12 INFO DAGScheduler: Final stage: ResultStage 56 (count at NativeMethodAccessorImpl.java:0)
18/06/25 12:03:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
18/06/25 12:03:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 55)
18/06/25 12:03:12 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[235] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 12:03:12 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 45.4 KB, free 340.4 MB)
18/06/25 12:03:12 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 17.0 KB, free 340.3 MB)
18/06/25 12:03:12 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53973 (size: 17.0 KB, free: 340.4 MB)
18/06/25 12:03:12 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[235] at count at NativeMethodAccessorImpl.java:0)
18/06/25 12:03:12 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 3060
18/06/25 12:03:12 WARN TaskSetManager: Stage 55 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:03:12 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 12:03:12 INFO Executor: Running task 0.0 in stage 55.0 (TID 58)
18/06/25 12:03:12 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:03:12 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:53973 in memory (size: 23.2 KB, free: 340.5 MB)
18/06/25 12:03:12 INFO ContextCleaner: Cleaned shuffle 16
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2963
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2962
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2961
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2960
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2959
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2958
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2957
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2956
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2955
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2954
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2953
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2952
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2951
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2950
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2949
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2948
18/06/25 12:03:12 INFO ContextCleaner: Cleaned accumulator 2947
18/06/25 12:03:13 INFO Executor: Finished task 0.0 in stage 55.0 (TID 58). 2839 bytes result sent to driver
18/06/25 12:03:13 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 58) in 952 ms on localhost (executor driver) (1/1)
18/06/25 12:03:13 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
18/06/25 12:03:13 INFO DAGScheduler: ShuffleMapStage 55 (count at NativeMethodAccessorImpl.java:0) finished in 0.952 s
18/06/25 12:03:13 INFO DAGScheduler: looking for newly runnable stages
18/06/25 12:03:13 INFO DAGScheduler: running: Set()
18/06/25 12:03:13 INFO DAGScheduler: waiting: Set(ResultStage 56)
18/06/25 12:03:13 INFO DAGScheduler: failed: Set()
18/06/25 12:03:13 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[238] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 12:03:13 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
18/06/25 12:03:13 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
18/06/25 12:03:13 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.5 MB)
18/06/25 12:03:13 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[238] at count at NativeMethodAccessorImpl.java:0)
18/06/25 12:03:13 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
18/06/25 12:03:13 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 59, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 12:03:13 INFO Executor: Running task 0.0 in stage 56.0 (TID 59)
18/06/25 12:03:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 12:03:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 12:03:13 INFO Executor: Finished task 0.0 in stage 56.0 (TID 59). 2042 bytes result sent to driver
18/06/25 12:03:13 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 59) in 5 ms on localhost (executor driver) (1/1)
18/06/25 12:03:13 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/06/25 12:03:13 INFO DAGScheduler: ResultStage 56 (count at NativeMethodAccessorImpl.java:0) finished in 0.006 s
18/06/25 12:03:13 INFO DAGScheduler: Job 38 finished: count at NativeMethodAccessorImpl.java:0, took 0.970265 s
18/06/25 12:03:13 INFO CodeGenerator: Code generated in 16.17126 ms
18/06/25 12:03:13 INFO SparkContext: Starting job: collect at utils.scala:36
18/06/25 12:03:13 INFO DAGScheduler: Got job 39 (collect at utils.scala:36) with 1 output partitions
18/06/25 12:03:13 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:36)
18/06/25 12:03:13 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:03:13 INFO DAGScheduler: Missing parents: List()
18/06/25 12:03:13 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[243] at map at utils.scala:33), which has no missing parents
18/06/25 12:03:13 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 61.1 KB, free 340.3 MB)
18/06/25 12:03:13 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 22.1 KB, free 340.3 MB)
18/06/25 12:03:13 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53973 (size: 22.1 KB, free: 340.4 MB)
18/06/25 12:03:13 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:996
18/06/25 12:03:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[243] at map at utils.scala:33)
18/06/25 12:03:13 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
18/06/25 12:03:13 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 12:03:13 WARN TaskSetManager: Stage 57 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:03:13 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365305 bytes)
18/06/25 12:03:13 INFO Executor: Running task 0.0 in stage 57.0 (TID 60)
18/06/25 12:03:13 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:03:14 INFO Executor: Finished task 0.0 in stage 57.0 (TID 60). 805830 bytes result sent to driver
18/06/25 12:03:14 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 60) in 912 ms on localhost (executor driver) (1/1)
18/06/25 12:03:14 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
18/06/25 12:03:14 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:36) finished in 0.913 s
18/06/25 12:03:14 INFO DAGScheduler: Job 39 finished: collect at utils.scala:36, took 0.917506 s
18/06/25 12:05:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:05:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa96c1a30`
18/06/25 12:05:19 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:92
18/06/25 12:05:19 INFO DAGScheduler: Registering RDD 250 (countByValue at StringIndexer.scala:92)
18/06/25 12:05:19 INFO DAGScheduler: Got job 40 (countByValue at StringIndexer.scala:92) with 1 output partitions
18/06/25 12:05:19 INFO DAGScheduler: Final stage: ResultStage 59 (countByValue at StringIndexer.scala:92)
18/06/25 12:05:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
18/06/25 12:05:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
18/06/25 12:05:19 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[250] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 12:05:19 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 43.2 KB, free 340.3 MB)
18/06/25 12:05:19 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 16.0 KB, free 340.3 MB)
18/06/25 12:05:19 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53973 (size: 16.0 KB, free: 340.4 MB)
18/06/25 12:05:19 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[250] at countByValue at StringIndexer.scala:92)
18/06/25 12:05:19 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
18/06/25 12:05:19 WARN TaskSetManager: Stage 58 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:19 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365299 bytes)
18/06/25 12:05:19 INFO Executor: Running task 0.0 in stage 58.0 (TID 61)
18/06/25 12:05:19 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:20 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53973 in memory (size: 22.1 KB, free: 340.4 MB)
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3181
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3180
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3179
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3178
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3177
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3176
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3175
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3174
18/06/25 12:05:20 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53973 in memory (size: 17.0 KB, free: 340.5 MB)
18/06/25 12:05:20 INFO ContextCleaner: Cleaned shuffle 17
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3077
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3076
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3075
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3074
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3073
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3072
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3071
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3070
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3069
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3068
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3067
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3066
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3065
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3064
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3063
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3062
18/06/25 12:05:20 INFO ContextCleaner: Cleaned accumulator 3061
18/06/25 12:05:20 INFO Executor: Finished task 0.0 in stage 58.0 (TID 61). 2654 bytes result sent to driver
18/06/25 12:05:20 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 61) in 943 ms on localhost (executor driver) (1/1)
18/06/25 12:05:20 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
18/06/25 12:05:20 INFO DAGScheduler: ShuffleMapStage 58 (countByValue at StringIndexer.scala:92) finished in 0.944 s
18/06/25 12:05:20 INFO DAGScheduler: looking for newly runnable stages
18/06/25 12:05:20 INFO DAGScheduler: running: Set()
18/06/25 12:05:20 INFO DAGScheduler: waiting: Set(ResultStage 59)
18/06/25 12:05:20 INFO DAGScheduler: failed: Set()
18/06/25 12:05:20 INFO DAGScheduler: Submitting ResultStage 59 (ShuffledRDD[251] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 12:05:20 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 3.2 KB, free 340.4 MB)
18/06/25 12:05:20 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 1970.0 B, free 340.4 MB)
18/06/25 12:05:20 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53973 (size: 1970.0 B, free: 340.5 MB)
18/06/25 12:05:20 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (ShuffledRDD[251] at countByValue at StringIndexer.scala:92)
18/06/25 12:05:20 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
18/06/25 12:05:20 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 62, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/06/25 12:05:20 INFO Executor: Running task 0.0 in stage 59.0 (TID 62)
18/06/25 12:05:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 12:05:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 12:05:20 INFO Executor: Finished task 0.0 in stage 59.0 (TID 62). 2244 bytes result sent to driver
18/06/25 12:05:20 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 62) in 7 ms on localhost (executor driver) (1/1)
18/06/25 12:05:20 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/06/25 12:05:20 INFO DAGScheduler: ResultStage 59 (countByValue at StringIndexer.scala:92) finished in 0.008 s
18/06/25 12:05:20 INFO DAGScheduler: Job 40 finished: countByValue at StringIndexer.scala:92, took 0.961171 s
18/06/25 12:05:20 INFO CodeGenerator: Code generated in 15.394719 ms
18/06/25 12:05:20 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 12:05:20 INFO DAGScheduler: Got job 41 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 12:05:20 INFO DAGScheduler: Final stage: ResultStage 60 (first at LinearRegression.scala:198)
18/06/25 12:05:20 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:05:20 INFO DAGScheduler: Missing parents: List()
18/06/25 12:05:20 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[254] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 12:05:20 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 60.9 KB, free 340.4 MB)
18/06/25 12:05:20 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 21.9 KB, free 340.3 MB)
18/06/25 12:05:20 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53973 (size: 21.9 KB, free: 340.4 MB)
18/06/25 12:05:20 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[254] at first at LinearRegression.scala:198)
18/06/25 12:05:20 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
18/06/25 12:05:20 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53973 in memory (size: 1970.0 B, free: 340.4 MB)
18/06/25 12:05:20 WARN TaskSetManager: Stage 60 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:20 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 12:05:20 INFO Executor: Running task 0.0 in stage 60.0 (TID 63)
18/06/25 12:05:20 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:21 INFO Executor: Finished task 0.0 in stage 60.0 (TID 63). 2195 bytes result sent to driver
18/06/25 12:05:21 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 63) in 715 ms on localhost (executor driver) (1/1)
18/06/25 12:05:21 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
18/06/25 12:05:21 INFO DAGScheduler: ResultStage 60 (first at LinearRegression.scala:198) finished in 0.715 s
18/06/25 12:05:21 INFO DAGScheduler: Job 41 finished: first at LinearRegression.scala:198, took 0.720573 s
18/06/25 12:05:21 INFO CodeGenerator: Code generated in 19.977356 ms
18/06/25 12:05:21 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
18/06/25 12:05:21 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
18/06/25 12:05:21 INFO DAGScheduler: Got job 42 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
18/06/25 12:05:21 INFO DAGScheduler: Final stage: ResultStage 61 (treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 12:05:21 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:05:21 INFO DAGScheduler: Missing parents: List()
18/06/25 12:05:21 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[260] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
18/06/25 12:05:21 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 63.8 KB, free 340.3 MB)
18/06/25 12:05:21 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 23.4 KB, free 340.3 MB)
18/06/25 12:05:21 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53973 (size: 23.4 KB, free: 340.4 MB)
18/06/25 12:05:21 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[260] at treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 12:05:21 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
18/06/25 12:05:21 WARN TaskSetManager: Stage 61 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:21 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365311 bytes)
18/06/25 12:05:21 INFO Executor: Running task 0.0 in stage 61.0 (TID 64)
18/06/25 12:05:21 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:22 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53973 in memory (size: 21.9 KB, free: 340.4 MB)
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3339
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3338
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3337
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3336
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3335
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3334
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3333
18/06/25 12:05:22 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53973 in memory (size: 16.0 KB, free: 340.5 MB)
18/06/25 12:05:22 INFO ContextCleaner: Cleaned shuffle 18
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3236
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3235
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3234
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3233
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3232
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3231
18/06/25 12:05:22 INFO ContextCleaner: Cleaned accumulator 3230
18/06/25 12:05:22 INFO Executor: Finished task 0.0 in stage 61.0 (TID 64). 4172 bytes result sent to driver
18/06/25 12:05:22 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 64) in 1342 ms on localhost (executor driver) (1/1)
18/06/25 12:05:22 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
18/06/25 12:05:22 INFO DAGScheduler: ResultStage 61 (treeAggregate at WeightedLeastSquares.scala:100) finished in 1.342 s
18/06/25 12:05:22 INFO DAGScheduler: Job 42 finished: treeAggregate at WeightedLeastSquares.scala:100, took 1.347892 s
18/06/25 12:05:22 INFO WeightedLeastSquares: Number of instances: 190884.
18/06/25 12:05:22 INFO CodeGenerator: Code generated in 16.640937 ms
18/06/25 12:05:22 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
18/06/25 12:05:22 INFO DAGScheduler: Got job 43 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
18/06/25 12:05:22 INFO DAGScheduler: Final stage: ResultStage 62 (aggregate at RegressionMetrics.scala:57)
18/06/25 12:05:22 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:05:22 INFO DAGScheduler: Missing parents: List()
18/06/25 12:05:22 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[266] at map at RegressionMetrics.scala:55), which has no missing parents
18/06/25 12:05:22 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 62.6 KB, free 340.3 MB)
18/06/25 12:05:22 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 23.3 KB, free 340.3 MB)
18/06/25 12:05:22 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53973 (size: 23.3 KB, free: 340.4 MB)
18/06/25 12:05:22 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[266] at map at RegressionMetrics.scala:55)
18/06/25 12:05:22 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
18/06/25 12:05:22 WARN TaskSetManager: Stage 62 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:22 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365307 bytes)
18/06/25 12:05:22 INFO Executor: Running task 0.0 in stage 62.0 (TID 65)
18/06/25 12:05:23 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:23 INFO Executor: Finished task 0.0 in stage 62.0 (TID 65). 2604 bytes result sent to driver
18/06/25 12:05:23 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 65) in 1077 ms on localhost (executor driver) (1/1)
18/06/25 12:05:23 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
18/06/25 12:05:23 INFO DAGScheduler: ResultStage 62 (aggregate at RegressionMetrics.scala:57) finished in 1.077 s
18/06/25 12:05:23 INFO DAGScheduler: Job 43 finished: aggregate at RegressionMetrics.scala:57, took 1.082693 s
18/06/25 12:05:23 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
18/06/25 12:05:23 INFO DAGScheduler: Got job 44 (sum at RegressionMetrics.scala:71) with 1 output partitions
18/06/25 12:05:23 INFO DAGScheduler: Final stage: ResultStage 63 (sum at RegressionMetrics.scala:71)
18/06/25 12:05:23 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:05:23 INFO DAGScheduler: Missing parents: List()
18/06/25 12:05:23 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[267] at map at RegressionMetrics.scala:69), which has no missing parents
18/06/25 12:05:23 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 62.1 KB, free 340.2 MB)
18/06/25 12:05:23 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 23.1 KB, free 340.2 MB)
18/06/25 12:05:23 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53973 (size: 23.1 KB, free: 340.4 MB)
18/06/25 12:05:23 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[267] at map at RegressionMetrics.scala:69)
18/06/25 12:05:23 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
18/06/25 12:05:24 WARN TaskSetManager: Stage 63 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:24 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365301 bytes)
18/06/25 12:05:24 INFO Executor: Running task 0.0 in stage 63.0 (TID 66)
18/06/25 12:05:24 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:24 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:53973 in memory (size: 23.3 KB, free: 340.4 MB)
18/06/25 12:05:24 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53973 in memory (size: 23.4 KB, free: 340.5 MB)
18/06/25 12:05:25 INFO Executor: Finished task 0.0 in stage 63.0 (TID 66). 2121 bytes result sent to driver
18/06/25 12:05:25 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 66) in 1191 ms on localhost (executor driver) (1/1)
18/06/25 12:05:25 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
18/06/25 12:05:25 INFO DAGScheduler: ResultStage 63 (sum at RegressionMetrics.scala:71) finished in 1.193 s
18/06/25 12:05:25 INFO DAGScheduler: Job 44 finished: sum at RegressionMetrics.scala:71, took 1.199700 s
18/06/25 12:05:25 INFO SparkContext: Starting job: count at LinearRegression.scala:683
18/06/25 12:05:25 INFO DAGScheduler: Registering RDD 270 (count at LinearRegression.scala:683)
18/06/25 12:05:25 INFO DAGScheduler: Got job 45 (count at LinearRegression.scala:683) with 1 output partitions
18/06/25 12:05:25 INFO DAGScheduler: Final stage: ResultStage 65 (count at LinearRegression.scala:683)
18/06/25 12:05:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
18/06/25 12:05:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)
18/06/25 12:05:25 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[270] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 12:05:25 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 45.4 KB, free 340.3 MB)
18/06/25 12:05:25 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 17.0 KB, free 340.3 MB)
18/06/25 12:05:25 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53973 (size: 17.0 KB, free: 340.4 MB)
18/06/25 12:05:25 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[270] at count at LinearRegression.scala:683)
18/06/25 12:05:25 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
18/06/25 12:05:25 INFO ContextCleaner: Cleaned accumulator 3546
18/06/25 12:05:25 WARN TaskSetManager: Stage 64 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:25 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 12:05:25 INFO Executor: Running task 0.0 in stage 64.0 (TID 67)
18/06/25 12:05:25 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:25 INFO Executor: Finished task 0.0 in stage 64.0 (TID 67). 2839 bytes result sent to driver
18/06/25 12:05:25 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 67) in 573 ms on localhost (executor driver) (1/1)
18/06/25 12:05:25 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
18/06/25 12:05:25 INFO DAGScheduler: ShuffleMapStage 64 (count at LinearRegression.scala:683) finished in 0.573 s
18/06/25 12:05:25 INFO DAGScheduler: looking for newly runnable stages
18/06/25 12:05:25 INFO DAGScheduler: running: Set()
18/06/25 12:05:25 INFO DAGScheduler: waiting: Set(ResultStage 65)
18/06/25 12:05:25 INFO DAGScheduler: failed: Set()
18/06/25 12:05:25 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[273] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 12:05:25 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 7.0 KB, free 340.3 MB)
18/06/25 12:05:25 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.3 MB)
18/06/25 12:05:25 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.4 MB)
18/06/25 12:05:25 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[273] at count at LinearRegression.scala:683)
18/06/25 12:05:25 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
18/06/25 12:05:25 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 68, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 12:05:25 INFO Executor: Running task 0.0 in stage 65.0 (TID 68)
18/06/25 12:05:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 12:05:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 12:05:25 INFO Executor: Finished task 0.0 in stage 65.0 (TID 68). 1963 bytes result sent to driver
18/06/25 12:05:25 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 68) in 3 ms on localhost (executor driver) (1/1)
18/06/25 12:05:25 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/06/25 12:05:25 INFO DAGScheduler: ResultStage 65 (count at LinearRegression.scala:683) finished in 0.003 s
18/06/25 12:05:25 INFO DAGScheduler: Job 45 finished: count at LinearRegression.scala:683, took 0.591540 s
18/06/25 12:05:25 INFO CodeGenerator: Code generated in 18.860231 ms
18/06/25 12:05:25 INFO SparkContext: Starting job: first at LinearRegression.scala:707
18/06/25 12:05:25 INFO DAGScheduler: Registering RDD 276 (first at LinearRegression.scala:707)
18/06/25 12:05:25 INFO DAGScheduler: Got job 46 (first at LinearRegression.scala:707) with 1 output partitions
18/06/25 12:05:25 INFO DAGScheduler: Final stage: ResultStage 67 (first at LinearRegression.scala:707)
18/06/25 12:05:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
18/06/25 12:05:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
18/06/25 12:05:25 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[276] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 12:05:25 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 69.6 KB, free 340.3 MB)
18/06/25 12:05:25 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 26.9 KB, free 340.2 MB)
18/06/25 12:05:25 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53973 (size: 26.9 KB, free: 340.4 MB)
18/06/25 12:05:25 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[276] at first at LinearRegression.scala:707)
18/06/25 12:05:25 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
18/06/25 12:05:25 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 12:05:25 INFO ContextCleaner: Cleaned accumulator 3660
18/06/25 12:05:25 WARN TaskSetManager: Stage 66 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:25 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365238 bytes)
18/06/25 12:05:25 INFO Executor: Running task 0.0 in stage 66.0 (TID 69)
18/06/25 12:05:26 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:26 INFO Executor: Finished task 0.0 in stage 66.0 (TID 69). 2839 bytes result sent to driver
18/06/25 12:05:26 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 69) in 1122 ms on localhost (executor driver) (1/1)
18/06/25 12:05:26 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
18/06/25 12:05:26 INFO DAGScheduler: ShuffleMapStage 66 (first at LinearRegression.scala:707) finished in 1.123 s
18/06/25 12:05:26 INFO DAGScheduler: looking for newly runnable stages
18/06/25 12:05:26 INFO DAGScheduler: running: Set()
18/06/25 12:05:26 INFO DAGScheduler: waiting: Set(ResultStage 67)
18/06/25 12:05:26 INFO DAGScheduler: failed: Set()
18/06/25 12:05:26 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[279] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 12:05:26 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 7.9 KB, free 340.2 MB)
18/06/25 12:05:26 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.0 KB, free 340.2 MB)
18/06/25 12:05:26 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53973 (size: 4.0 KB, free: 340.4 MB)
18/06/25 12:05:26 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[279] at first at LinearRegression.scala:707)
18/06/25 12:05:26 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
18/06/25 12:05:26 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 70, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/06/25 12:05:26 INFO Executor: Running task 0.0 in stage 67.0 (TID 70)
18/06/25 12:05:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 12:05:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 12:05:26 INFO Executor: Finished task 0.0 in stage 67.0 (TID 70). 2027 bytes result sent to driver
18/06/25 12:05:26 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 70) in 3 ms on localhost (executor driver) (1/1)
18/06/25 12:05:26 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
18/06/25 12:05:26 INFO DAGScheduler: ResultStage 67 (first at LinearRegression.scala:707) finished in 0.003 s
18/06/25 12:05:26 INFO DAGScheduler: Job 46 finished: first at LinearRegression.scala:707, took 1.134280 s
18/06/25 12:05:26 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa35756672
18/06/25 12:05:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:05:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa35756672` AS `zzz17`
WHERE (0 = 1)
18/06/25 12:05:26 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa2e98e1c9
18/06/25 12:05:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:05:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa2e98e1c9` AS `zzz18`
WHERE (0 = 1)
18/06/25 12:05:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:05:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa96c1a30`
18/06/25 12:05:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa370f6b05
18/06/25 12:05:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:05:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa370f6b05` AS `zzz19`
WHERE (0 = 1)
18/06/25 12:05:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:05:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa370f6b05`
18/06/25 12:05:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 12:05:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa2e98e1c9`
18/06/25 12:05:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
18/06/25 12:05:30 INFO DAGScheduler: Registering RDD 285 (count at NativeMethodAccessorImpl.java:0)
18/06/25 12:05:30 INFO DAGScheduler: Got job 47 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 12:05:30 INFO DAGScheduler: Final stage: ResultStage 69 (count at NativeMethodAccessorImpl.java:0)
18/06/25 12:05:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
18/06/25 12:05:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
18/06/25 12:05:30 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[285] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 12:05:30 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 45.4 KB, free 340.2 MB)
18/06/25 12:05:30 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 16.9 KB, free 340.2 MB)
18/06/25 12:05:30 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53973 (size: 16.9 KB, free: 340.4 MB)
18/06/25 12:05:30 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[285] at count at NativeMethodAccessorImpl.java:0)
18/06/25 12:05:30 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
18/06/25 12:05:30 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53973 in memory (size: 4.0 KB, free: 340.4 MB)
18/06/25 12:05:30 INFO ContextCleaner: Cleaned accumulator 3774
18/06/25 12:05:31 WARN TaskSetManager: Stage 68 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:31 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 12:05:31 INFO Executor: Running task 0.0 in stage 68.0 (TID 71)
18/06/25 12:05:31 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:31 INFO Executor: Finished task 0.0 in stage 68.0 (TID 71). 2839 bytes result sent to driver
18/06/25 12:05:31 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 71) in 633 ms on localhost (executor driver) (1/1)
18/06/25 12:05:31 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
18/06/25 12:05:31 INFO DAGScheduler: ShuffleMapStage 68 (count at NativeMethodAccessorImpl.java:0) finished in 0.634 s
18/06/25 12:05:31 INFO DAGScheduler: looking for newly runnable stages
18/06/25 12:05:31 INFO DAGScheduler: running: Set()
18/06/25 12:05:31 INFO DAGScheduler: waiting: Set(ResultStage 69)
18/06/25 12:05:31 INFO DAGScheduler: failed: Set()
18/06/25 12:05:31 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[288] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 12:05:31 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.0 KB, free 340.2 MB)
18/06/25 12:05:31 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.2 MB)
18/06/25 12:05:31 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53973 (size: 3.7 KB, free: 340.4 MB)
18/06/25 12:05:31 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[288] at count at NativeMethodAccessorImpl.java:0)
18/06/25 12:05:31 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
18/06/25 12:05:31 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 72, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 12:05:31 INFO Executor: Running task 0.0 in stage 69.0 (TID 72)
18/06/25 12:05:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 12:05:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 12:05:31 INFO Executor: Finished task 0.0 in stage 69.0 (TID 72). 2042 bytes result sent to driver
18/06/25 12:05:31 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 72) in 5 ms on localhost (executor driver) (1/1)
18/06/25 12:05:31 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
18/06/25 12:05:31 INFO DAGScheduler: ResultStage 69 (count at NativeMethodAccessorImpl.java:0) finished in 0.005 s
18/06/25 12:05:31 INFO DAGScheduler: Job 47 finished: count at NativeMethodAccessorImpl.java:0, took 0.647897 s
18/06/25 12:05:31 INFO CodeGenerator: Code generated in 16.941312 ms
18/06/25 12:05:31 INFO SparkContext: Starting job: collect at utils.scala:36
18/06/25 12:05:31 INFO DAGScheduler: Got job 48 (collect at utils.scala:36) with 1 output partitions
18/06/25 12:05:31 INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:36)
18/06/25 12:05:31 INFO DAGScheduler: Parents of final stage: List()
18/06/25 12:05:31 INFO DAGScheduler: Missing parents: List()
18/06/25 12:05:31 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[293] at map at utils.scala:33), which has no missing parents
18/06/25 12:05:31 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 76.1 KB, free 340.1 MB)
18/06/25 12:05:31 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 26.9 KB, free 340.1 MB)
18/06/25 12:05:31 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53973 (size: 26.9 KB, free: 340.4 MB)
18/06/25 12:05:31 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:996
18/06/25 12:05:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[293] at map at utils.scala:33)
18/06/25 12:05:31 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3558
18/06/25 12:05:31 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53973 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 12:05:31 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53973 in memory (size: 16.9 KB, free: 340.4 MB)
18/06/25 12:05:31 INFO ContextCleaner: Cleaned shuffle 21
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3791
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3790
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3789
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3788
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3787
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3786
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3785
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3784
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3783
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3782
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3781
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3780
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3779
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3778
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3777
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3776
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3775
18/06/25 12:05:31 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:53973 in memory (size: 26.9 KB, free: 340.4 MB)
18/06/25 12:05:31 INFO ContextCleaner: Cleaned shuffle 20
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3677
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3676
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3675
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3674
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3673
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3672
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3671
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3670
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3669
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3668
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3667
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3666
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3665
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3664
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3663
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3662
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3661
18/06/25 12:05:31 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53973 in memory (size: 17.0 KB, free: 340.4 MB)
18/06/25 12:05:31 INFO ContextCleaner: Cleaned shuffle 19
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3563
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3562
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3561
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3560
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3559
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3557
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3556
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3555
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3554
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3553
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3552
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3551
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3550
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3549
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3548
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3547
18/06/25 12:05:31 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:53973 in memory (size: 23.1 KB, free: 340.4 MB)
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3394
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3393
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3392
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3391
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3390
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3389
18/06/25 12:05:31 INFO ContextCleaner: Cleaned accumulator 3388
18/06/25 12:05:31 WARN TaskSetManager: Stage 70 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 12:05:31 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365305 bytes)
18/06/25 12:05:31 INFO Executor: Running task 0.0 in stage 70.0 (TID 73)
18/06/25 12:05:32 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 12:05:32 INFO Executor: Finished task 0.0 in stage 70.0 (TID 73). 808491 bytes result sent to driver
18/06/25 12:05:32 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 73) in 1386 ms on localhost (executor driver) (1/1)
18/06/25 12:05:32 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
18/06/25 12:05:32 INFO DAGScheduler: ResultStage 70 (collect at utils.scala:36) finished in 1.386 s
18/06/25 12:05:32 INFO DAGScheduler: Job 48 finished: collect at utils.scala:36, took 1.391699 s
18/06/25 12:07:36 INFO SparkContext: Invoking stop() from shutdown hook
18/06/25 12:07:36 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/06/25 12:07:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/06/25 12:07:36 INFO MemoryStore: MemoryStore cleared
18/06/25 12:07:36 INFO BlockManager: BlockManager stopped
18/06/25 12:07:36 INFO BlockManagerMaster: BlockManagerMaster stopped
18/06/25 12:07:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/06/25 12:07:36 INFO SparkContext: Successfully stopped SparkContext
18/06/25 12:07:36 INFO ShutdownHookManager: Shutdown hook called
18/06/25 12:07:36 INFO ShutdownHookManager: Deleting directory /private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/spark-12cec62f-cd1f-413a-af35-091a2a9cdd74
18/06/25 13:14:56 INFO SparkContext: Running Spark version 2.1.0
18/06/25 13:14:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/06/25 13:14:57 INFO SecurityManager: Changing view acls to: JBRickert
18/06/25 13:14:57 INFO SecurityManager: Changing modify acls to: JBRickert
18/06/25 13:14:57 INFO SecurityManager: Changing view acls groups to: 
18/06/25 13:14:57 INFO SecurityManager: Changing modify acls groups to: 
18/06/25 13:14:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(JBRickert); groups with view permissions: Set(); users  with modify permissions: Set(JBRickert); groups with modify permissions: Set()
18/06/25 13:14:57 INFO Utils: Successfully started service 'sparkDriver' on port 54715.
18/06/25 13:14:57 INFO SparkEnv: Registering MapOutputTracker
18/06/25 13:14:57 INFO SparkEnv: Registering BlockManagerMaster
18/06/25 13:14:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/06/25 13:14:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/06/25 13:14:57 INFO DiskBlockManager: Created local directory at /private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/blockmgr-b9d02b7b-38d8-40b1-a8f1-29fc9d41ea7e
18/06/25 13:14:57 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/06/25 13:14:57 INFO SparkEnv: Registering OutputCommitCoordinator
18/06/25 13:14:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/06/25 13:14:57 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/06/25 13:14:57 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:54715/jars/sparklyr-2.1-2.11.jar with timestamp 1529957697973
18/06/25 13:14:58 INFO Executor: Starting executor ID driver on host localhost
18/06/25 13:14:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54716.
18/06/25 13:14:58 INFO NettyBlockTransferService: Server created on 127.0.0.1:54716
18/06/25 13:14:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/06/25 13:14:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54716, None)
18/06/25 13:14:58 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54716 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54716, None)
18/06/25 13:14:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54716, None)
18/06/25 13:14:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54716, None)
18/06/25 13:14:58 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/06/25 13:14:58 INFO SharedState: Warehouse path is 'file:/Users/JBRickert/Documents/RStudio_Projects/useR_2018/spark-warehouse'.
18/06/25 13:14:58 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/06/25 13:14:59 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/06/25 13:14:59 INFO ObjectStore: ObjectStore, initialize called
18/06/25 13:14:59 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/06/25 13:14:59 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/06/25 13:15:01 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/06/25 13:15:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 13:15:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 13:15:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 13:15:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 13:15:03 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/06/25 13:15:03 INFO ObjectStore: Initialized ObjectStore
18/06/25 13:15:03 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/06/25 13:15:03 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/06/25 13:15:03 INFO HiveMetaStore: Added admin role in metastore
18/06/25 13:15:03 INFO HiveMetaStore: Added public role in metastore
18/06/25 13:15:04 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/06/25 13:15:04 INFO HiveMetaStore: 0: get_all_databases
18/06/25 13:15:04 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_all_databases	
18/06/25 13:15:04 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/06/25 13:15:04 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/06/25 13:15:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/06/25 13:15:04 INFO SessionState: Created local directory: /var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/1b5d9374-206d-445b-8af7-0ea2685bfdab_resources
18/06/25 13:15:04 INFO SessionState: Created HDFS directory: /tmp/hive/JBRickert/1b5d9374-206d-445b-8af7-0ea2685bfdab
18/06/25 13:15:04 INFO SessionState: Created local directory: /var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/JBRickert/1b5d9374-206d-445b-8af7-0ea2685bfdab
18/06/25 13:15:04 INFO SessionState: Created HDFS directory: /tmp/hive/JBRickert/1b5d9374-206d-445b-8af7-0ea2685bfdab/_tmp_space.db
18/06/25 13:15:04 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/JBRickert/Documents/RStudio_Projects/useR_2018/spark-warehouse
18/06/25 13:15:04 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:04 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:04 INFO HiveMetaStore: 0: get_database: global_temp
18/06/25 13:15:04 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/06/25 13:15:04 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/06/25 13:15:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 13:15:06 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:06 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:06 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:06 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 13:15:06 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 13:15:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 13:15:06 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:06 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:06 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:06 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 13:15:06 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 13:15:07 INFO CodeGenerator: Code generated in 334.723451 ms
18/06/25 13:15:07 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 13:15:07 INFO DAGScheduler: Got job 0 (collect at utils.scala:43) with 1 output partitions
18/06/25 13:15:07 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:43)
18/06/25 13:15:07 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:15:07 INFO DAGScheduler: Missing parents: List()
18/06/25 13:15:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:40), which has no missing parents
18/06/25 13:15:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
18/06/25 13:15:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
18/06/25 13:15:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54716 (size: 4.6 KB, free: 366.3 MB)
18/06/25 13:15:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:40)
18/06/25 13:15:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/06/25 13:15:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
18/06/25 13:15:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/06/25 13:15:07 INFO Executor: Fetching spark://127.0.0.1:54715/jars/sparklyr-2.1-2.11.jar with timestamp 1529957697973
18/06/25 13:15:07 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54715 after 19 ms (0 ms spent in bootstraps)
18/06/25 13:15:07 INFO Utils: Fetching spark://127.0.0.1:54715/jars/sparklyr-2.1-2.11.jar to /private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/spark-180f5696-5647-4b44-89bb-004e0de6a739/userFiles-45f27844-04e0-46ed-89cf-a2dbe62bf185/fetchFileTemp7850338805271883941.tmp
18/06/25 13:15:07 INFO Executor: Adding file:/private/var/folders/w0/skxpg0h51jg72m5b01y_8n_c0000gn/T/spark-180f5696-5647-4b44-89bb-004e0de6a739/userFiles-45f27844-04e0-46ed-89cf-a2dbe62bf185/sparklyr-2.1-2.11.jar to class loader
18/06/25 13:15:07 INFO CodeGenerator: Code generated in 16.750621 ms
18/06/25 13:15:07 INFO CodeGenerator: Code generated in 16.253065 ms
18/06/25 13:15:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1391 bytes result sent to driver
18/06/25 13:15:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 391 ms on localhost (executor driver) (1/1)
18/06/25 13:15:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/06/25 13:15:07 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:43) finished in 0.411 s
18/06/25 13:15:07 INFO DAGScheduler: Job 0 finished: collect at utils.scala:43, took 0.558619 s
18/06/25 13:15:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:07 INFO SparkSqlParser: Parsing command: iris
18/06/25 13:15:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:07 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
18/06/25 13:15:07 INFO SparkSqlParser: Parsing command: `iris`
18/06/25 13:15:08 INFO CodeGenerator: Code generated in 17.566292 ms
18/06/25 13:15:08 INFO CodeGenerator: Code generated in 14.090949 ms
18/06/25 13:15:08 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 13:15:08 INFO DAGScheduler: Registering RDD 15 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:08 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 13:15:08 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/06/25 13:15:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/06/25 13:15:08 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 366.3 MB)
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 366.3 MB)
18/06/25 13:15:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54716 (size: 8.4 KB, free: 366.3 MB)
18/06/25 13:15:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/06/25 13:15:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 10001 bytes)
18/06/25 13:15:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/06/25 13:15:08 INFO CodeGenerator: Code generated in 14.006934 ms
18/06/25 13:15:08 INFO CodeGenerator: Code generated in 56.047463 ms
18/06/25 13:15:08 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 5.6 KB, free 366.3 MB)
18/06/25 13:15:08 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:54716 (size: 5.6 KB, free: 366.3 MB)
18/06/25 13:15:08 INFO CodeGenerator: Code generated in 5.781022 ms
18/06/25 13:15:08 INFO CodeGenerator: Code generated in 21.614919 ms
18/06/25 13:15:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2747 bytes result sent to driver
18/06/25 13:15:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 267 ms on localhost (executor driver) (1/1)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/06/25 13:15:08 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.268 s
18/06/25 13:15:08 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:15:08 INFO DAGScheduler: running: Set()
18/06/25 13:15:08 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/06/25 13:15:08 INFO DAGScheduler: failed: Set()
18/06/25 13:15:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/06/25 13:15:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54716 (size: 3.7 KB, free: 366.3 MB)
18/06/25 13:15:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/06/25 13:15:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
18/06/25 13:15:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/06/25 13:15:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:15:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
18/06/25 13:15:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
18/06/25 13:15:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 36 ms on localhost (executor driver) (1/1)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/06/25 13:15:08 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.037 s
18/06/25 13:15:08 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.358641 s
18/06/25 13:15:08 INFO CodeGenerator: Code generated in 6.422947 ms
18/06/25 13:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:08 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
18/06/25 13:15:08 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 13:15:08 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
18/06/25 13:15:08 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
18/06/25 13:15:08 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
18/06/25 13:15:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/06/25 13:15:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/06/25 13:15:08 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 366.2 MB)
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.4 KB, free 366.2 MB)
18/06/25 13:15:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54716 (size: 8.4 KB, free: 366.3 MB)
18/06/25 13:15:08 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at utils.scala:196)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/06/25 13:15:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 9993 bytes)
18/06/25 13:15:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/06/25 13:15:08 INFO BlockManager: Found block rdd_12_0 locally
18/06/25 13:15:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2098 bytes result sent to driver
18/06/25 13:15:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 18 ms on localhost (executor driver) (1/1)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/06/25 13:15:08 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.018 s
18/06/25 13:15:08 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:15:08 INFO DAGScheduler: running: Set()
18/06/25 13:15:08 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/06/25 13:15:08 INFO DAGScheduler: failed: Set()
18/06/25 13:15:08 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/06/25 13:15:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54716 (size: 3.7 KB, free: 366.3 MB)
18/06/25 13:15:08 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[25] at collect at utils.scala:196)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/06/25 13:15:08 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
18/06/25 13:15:08 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/06/25 13:15:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:15:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 13:15:08 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
18/06/25 13:15:08 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/06/25 13:15:08 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.007 s
18/06/25 13:15:08 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.045920 s
18/06/25 13:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz20`
WHERE (0 = 1)
18/06/25 13:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 13:15:08 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:08 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:08 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:08 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 13:15:08 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 13:15:08 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 13:15:08 INFO DAGScheduler: Got job 3 (collect at utils.scala:43) with 1 output partitions
18/06/25 13:15:08 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:43)
18/06/25 13:15:08 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:15:08 INFO DAGScheduler: Missing parents: List()
18/06/25 13:15:08 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[31] at map at utils.scala:40), which has no missing parents
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 366.2 MB)
18/06/25 13:15:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.2 MB)
18/06/25 13:15:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54716 (size: 4.6 KB, free: 366.3 MB)
18/06/25 13:15:08 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[31] at map at utils.scala:40)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/06/25 13:15:08 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
18/06/25 13:15:08 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/06/25 13:15:08 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1238 bytes result sent to driver
18/06/25 13:15:08 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
18/06/25 13:15:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/06/25 13:15:08 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:43) finished in 0.011 s
18/06/25 13:15:08 INFO DAGScheduler: Job 3 finished: collect at utils.scala:43, took 0.020837 s
18/06/25 13:15:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:10 INFO SparkSqlParser: Parsing command: flights
18/06/25 13:15:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:10 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
18/06/25 13:15:10 INFO SparkSqlParser: Parsing command: `flights`
18/06/25 13:15:10 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 13:15:10 INFO DAGScheduler: Registering RDD 40 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:10 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 13:15:10 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
18/06/25 13:15:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
18/06/25 13:15:10 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 13:15:10 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 30.7 KB, free 366.2 MB)
18/06/25 13:15:10 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.7 KB, free 366.2 MB)
18/06/25 13:15:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54716 (size: 11.7 KB, free: 366.3 MB)
18/06/25 13:15:10 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:10 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 52
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 53
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 54
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 55
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 56
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 57
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 58
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 59
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 60
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 61
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 62
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 63
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 64
18/06/25 13:15:11 INFO ContextCleaner: Cleaned shuffle 0
18/06/25 13:15:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:54716 in memory (size: 8.4 KB, free: 366.3 MB)
18/06/25 13:15:11 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:54716 in memory (size: 3.7 KB, free: 366.3 MB)
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 161
18/06/25 13:15:11 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:54716 in memory (size: 8.4 KB, free: 366.3 MB)
18/06/25 13:15:11 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54716 in memory (size: 3.7 KB, free: 366.3 MB)
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 270
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 271
18/06/25 13:15:11 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:54716 in memory (size: 4.6 KB, free: 366.3 MB)
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 322
18/06/25 13:15:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:54716 in memory (size: 4.6 KB, free: 366.3 MB)
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 1
18/06/25 13:15:11 INFO ContextCleaner: Cleaned accumulator 0
18/06/25 13:15:11 WARN TaskSetManager: Stage 6 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:15:11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365330 bytes)
18/06/25 13:15:11 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/06/25 13:15:12 INFO CodeGenerator: Code generated in 22.013385 ms
18/06/25 13:15:12 INFO CodeGenerator: Code generated in 108.959919 ms
18/06/25 13:15:15 INFO MemoryStore: Block rdd_37_0 stored as values in memory (estimated size 22.5 MB, free 343.8 MB)
18/06/25 13:15:15 INFO BlockManagerInfo: Added rdd_37_0 in memory on 127.0.0.1:54716 (size: 22.5 MB, free: 343.8 MB)
18/06/25 13:15:15 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2733 bytes result sent to driver
18/06/25 13:15:15 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4847 ms on localhost (executor driver) (1/1)
18/06/25 13:15:15 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/06/25 13:15:15 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 4.847 s
18/06/25 13:15:15 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:15:15 INFO DAGScheduler: running: Set()
18/06/25 13:15:15 INFO DAGScheduler: waiting: Set(ResultStage 7)
18/06/25 13:15:15 INFO DAGScheduler: failed: Set()
18/06/25 13:15:15 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[43] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 13:15:15 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 343.8 MB)
18/06/25 13:15:15 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 343.7 MB)
18/06/25 13:15:15 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54716 (size: 3.7 KB, free: 343.8 MB)
18/06/25 13:15:15 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[43] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:15 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/06/25 13:15:15 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, ANY, 5953 bytes)
18/06/25 13:15:15 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
18/06/25 13:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 13:15:15 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2042 bytes result sent to driver
18/06/25 13:15:15 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (executor driver) (1/1)
18/06/25 13:15:15 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/06/25 13:15:15 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.009 s
18/06/25 13:15:15 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 4.883681 s
18/06/25 13:15:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:15 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
18/06/25 13:15:15 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 13:15:15 INFO DAGScheduler: Registering RDD 47 (collect at utils.scala:196)
18/06/25 13:15:15 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
18/06/25 13:15:15 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
18/06/25 13:15:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
18/06/25 13:15:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
18/06/25 13:15:15 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
18/06/25 13:15:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 30.7 KB, free 343.7 MB)
18/06/25 13:15:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.8 KB, free 343.7 MB)
18/06/25 13:15:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54716 (size: 11.8 KB, free: 343.8 MB)
18/06/25 13:15:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[47] at collect at utils.scala:196)
18/06/25 13:15:15 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/06/25 13:15:15 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54716 in memory (size: 3.7 KB, free: 343.8 MB)
18/06/25 13:15:15 INFO ContextCleaner: Cleaned accumulator 431
18/06/25 13:15:16 WARN TaskSetManager: Stage 8 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:15:16 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365323 bytes)
18/06/25 13:15:16 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
18/06/25 13:15:16 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:15:16 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2185 bytes result sent to driver
18/06/25 13:15:16 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 384 ms on localhost (executor driver) (1/1)
18/06/25 13:15:16 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/06/25 13:15:16 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.385 s
18/06/25 13:15:16 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:15:16 INFO DAGScheduler: running: Set()
18/06/25 13:15:16 INFO DAGScheduler: waiting: Set(ResultStage 9)
18/06/25 13:15:16 INFO DAGScheduler: failed: Set()
18/06/25 13:15:16 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[50] at collect at utils.scala:196), which has no missing parents
18/06/25 13:15:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 343.7 MB)
18/06/25 13:15:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 343.7 MB)
18/06/25 13:15:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54716 (size: 3.7 KB, free: 343.8 MB)
18/06/25 13:15:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[50] at collect at utils.scala:196)
18/06/25 13:15:16 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/06/25 13:15:16 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 5946 bytes)
18/06/25 13:15:16 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
18/06/25 13:15:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:15:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 13:15:16 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2042 bytes result sent to driver
18/06/25 13:15:16 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 10 ms on localhost (executor driver) (1/1)
18/06/25 13:15:16 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/06/25 13:15:16 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.011 s
18/06/25 13:15:16 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.414844 s
18/06/25 13:15:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz21`
WHERE (0 = 1)
18/06/25 13:15:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 13:15:16 INFO CodeGenerator: Code generated in 10.041219 ms
18/06/25 13:15:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 13:15:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 13:15:16 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 13:15:16 INFO SparkContext: Starting job: collect at utils.scala:43
18/06/25 13:15:16 INFO DAGScheduler: Got job 6 (collect at utils.scala:43) with 1 output partitions
18/06/25 13:15:16 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:43)
18/06/25 13:15:16 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:15:16 INFO DAGScheduler: Missing parents: List()
18/06/25 13:15:16 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[58] at map at utils.scala:40), which has no missing parents
18/06/25 13:15:16 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.7 KB, free 343.7 MB)
18/06/25 13:15:16 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KB, free 343.7 MB)
18/06/25 13:15:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54716 (size: 4.6 KB, free: 343.8 MB)
18/06/25 13:15:16 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[58] at map at utils.scala:40)
18/06/25 13:15:16 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/06/25 13:15:16 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
18/06/25 13:15:16 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
18/06/25 13:15:16 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1248 bytes result sent to driver
18/06/25 13:15:16 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 8 ms on localhost (executor driver) (1/1)
18/06/25 13:15:16 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/06/25 13:15:16 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:43) finished in 0.008 s
18/06/25 13:15:16 INFO DAGScheduler: Job 6 finished: collect at utils.scala:43, took 0.015439 s
18/06/25 13:15:16 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:54716 in memory (size: 11.8 KB, free: 343.8 MB)
18/06/25 13:15:17 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:54716 in memory (size: 3.7 KB, free: 343.8 MB)
18/06/25 13:15:17 INFO ContextCleaner: Cleaned accumulator 540
18/06/25 13:15:17 INFO ContextCleaner: Cleaned accumulator 541
18/06/25 13:15:17 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:54716 in memory (size: 4.6 KB, free: 343.8 MB)
18/06/25 13:15:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:17 INFO SparkSqlParser: Parsing command: batting
18/06/25 13:15:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:17 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
18/06/25 13:15:17 INFO SparkSqlParser: Parsing command: `batting`
18/06/25 13:15:17 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/06/25 13:15:17 INFO DAGScheduler: Registering RDD 67 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:17 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 13:15:17 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/06/25 13:15:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/06/25 13:15:17 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[67] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 13:15:17 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 31.9 KB, free 343.7 MB)
18/06/25 13:15:17 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.7 KB, free 343.7 MB)
18/06/25 13:15:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54716 (size: 11.7 KB, free: 343.8 MB)
18/06/25 13:15:17 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[67] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:17 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
18/06/25 13:15:17 WARN TaskSetManager: Stage 11 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 13:15:17 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814099 bytes)
18/06/25 13:15:17 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
18/06/25 13:15:17 INFO CodeGenerator: Code generated in 16.999421 ms
18/06/25 13:15:17 INFO CodeGenerator: Code generated in 90.29552 ms
18/06/25 13:15:17 INFO ContextCleaner: Cleaned accumulator 592
18/06/25 13:15:18 INFO MemoryStore: Block rdd_64_0 stored as values in memory (estimated size 3.3 MB, free 340.4 MB)
18/06/25 13:15:18 INFO BlockManagerInfo: Added rdd_64_0 in memory on 127.0.0.1:54716 (size: 3.3 MB, free: 340.5 MB)
18/06/25 13:15:18 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2733 bytes result sent to driver
18/06/25 13:15:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 1714 ms on localhost (executor driver) (1/1)
18/06/25 13:15:18 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/06/25 13:15:18 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 1.714 s
18/06/25 13:15:18 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:15:18 INFO DAGScheduler: running: Set()
18/06/25 13:15:18 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/06/25 13:15:18 INFO DAGScheduler: failed: Set()
18/06/25 13:15:18 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[70] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 13:15:18 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
18/06/25 13:15:18 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
18/06/25 13:15:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54716 (size: 3.7 KB, free: 340.4 MB)
18/06/25 13:15:18 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[70] at sql at NativeMethodAccessorImpl.java:0)
18/06/25 13:15:18 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/06/25 13:15:18 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, ANY, 5954 bytes)
18/06/25 13:15:18 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
18/06/25 13:15:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:15:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 13:15:18 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2042 bytes result sent to driver
18/06/25 13:15:18 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 10 ms on localhost (executor driver) (1/1)
18/06/25 13:15:18 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/06/25 13:15:18 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.010 s
18/06/25 13:15:18 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 1.738803 s
18/06/25 13:15:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:18 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
18/06/25 13:15:18 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 13:15:18 INFO DAGScheduler: Registering RDD 74 (collect at utils.scala:196)
18/06/25 13:15:18 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
18/06/25 13:15:18 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
18/06/25 13:15:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/06/25 13:15:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/06/25 13:15:18 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[74] at collect at utils.scala:196), which has no missing parents
18/06/25 13:15:18 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.9 KB, free 340.4 MB)
18/06/25 13:15:18 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 11.7 KB, free 340.3 MB)
18/06/25 13:15:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54716 (size: 11.7 KB, free: 340.4 MB)
18/06/25 13:15:18 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[74] at collect at utils.scala:196)
18/06/25 13:15:18 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/06/25 13:15:18 WARN TaskSetManager: Stage 13 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
18/06/25 13:15:18 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814091 bytes)
18/06/25 13:15:18 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
18/06/25 13:15:19 INFO BlockManager: Found block rdd_64_0 locally
18/06/25 13:15:19 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2098 bytes result sent to driver
18/06/25 13:15:19 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 92 ms on localhost (executor driver) (1/1)
18/06/25 13:15:19 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/06/25 13:15:19 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.095 s
18/06/25 13:15:19 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:15:19 INFO DAGScheduler: running: Set()
18/06/25 13:15:19 INFO DAGScheduler: waiting: Set(ResultStage 14)
18/06/25 13:15:19 INFO DAGScheduler: failed: Set()
18/06/25 13:15:19 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[77] at collect at utils.scala:196), which has no missing parents
18/06/25 13:15:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 340.3 MB)
18/06/25 13:15:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.3 MB)
18/06/25 13:15:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54716 (size: 3.7 KB, free: 340.4 MB)
18/06/25 13:15:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
18/06/25 13:15:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[77] at collect at utils.scala:196)
18/06/25 13:15:19 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
18/06/25 13:15:19 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 5946 bytes)
18/06/25 13:15:19 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
18/06/25 13:15:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:15:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 13:15:19 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2042 bytes result sent to driver
18/06/25 13:15:19 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 16 ms on localhost (executor driver) (1/1)
18/06/25 13:15:19 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/06/25 13:15:19 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.025 s
18/06/25 13:15:19 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.139806 s
18/06/25 13:15:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz22`
WHERE (0 = 1)
18/06/25 13:15:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:15:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/06/25 13:15:19 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:19 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:19 INFO HiveMetaStore: 0: get_database: default
18/06/25 13:15:19 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_database: default	
18/06/25 13:15:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/06/25 13:15:19 INFO audit: ugi=JBRickert	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/06/25 13:16:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (NOT(((`arr_delay`) IS NULL)))
18/06/25 13:16:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa14cd0cda
18/06/25 13:16:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa14cd0cda` AS `zzz23`
WHERE (0 = 1)
18/06/25 13:16:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa2206c6e1
18/06/25 13:16:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa2206c6e1` AS `zzz24`
WHERE (0 = 1)
18/06/25 13:16:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa14cd0cda`
18/06/25 13:16:24 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:54716 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 593
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 594
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 595
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 596
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 597
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 598
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 599
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 600
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 601
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 602
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 603
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 604
18/06/25 13:16:24 INFO ContextCleaner: Cleaned shuffle 4
18/06/25 13:16:24 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:54716 in memory (size: 11.7 KB, free: 340.4 MB)
18/06/25 13:16:24 INFO CodeGenerator: Code generated in 31.471148 ms
18/06/25 13:16:24 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:54716 in memory (size: 3.7 KB, free: 340.5 MB)
18/06/25 13:16:24 INFO ContextCleaner: Cleaned accumulator 701
18/06/25 13:16:24 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:54716 in memory (size: 11.7 KB, free: 340.5 MB)
18/06/25 13:16:24 INFO SparkContext: Starting job: countByValue at StringIndexer.scala:92
18/06/25 13:16:24 INFO DAGScheduler: Registering RDD 87 (countByValue at StringIndexer.scala:92)
18/06/25 13:16:24 INFO DAGScheduler: Got job 9 (countByValue at StringIndexer.scala:92) with 1 output partitions
18/06/25 13:16:24 INFO DAGScheduler: Final stage: ResultStage 16 (countByValue at StringIndexer.scala:92)
18/06/25 13:16:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
18/06/25 13:16:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
18/06/25 13:16:24 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[87] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 13:16:24 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 43.2 KB, free 340.4 MB)
18/06/25 13:16:24 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 16.0 KB, free 340.4 MB)
18/06/25 13:16:24 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54716 (size: 16.0 KB, free: 340.4 MB)
18/06/25 13:16:24 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[87] at countByValue at StringIndexer.scala:92)
18/06/25 13:16:24 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/06/25 13:16:24 WARN TaskSetManager: Stage 15 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:24 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365299 bytes)
18/06/25 13:16:24 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
18/06/25 13:16:24 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:24 INFO CodeGenerator: Code generated in 24.561504 ms
18/06/25 13:16:24 INFO CodeGenerator: Code generated in 39.891959 ms
18/06/25 13:16:25 INFO CodeGenerator: Code generated in 9.548302 ms
18/06/25 13:16:25 INFO CodeGenerator: Code generated in 8.311277 ms
18/06/25 13:16:26 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2567 bytes result sent to driver
18/06/25 13:16:26 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 1567 ms on localhost (executor driver) (1/1)
18/06/25 13:16:26 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/06/25 13:16:26 INFO DAGScheduler: ShuffleMapStage 15 (countByValue at StringIndexer.scala:92) finished in 1.568 s
18/06/25 13:16:26 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:16:26 INFO DAGScheduler: running: Set()
18/06/25 13:16:26 INFO DAGScheduler: waiting: Set(ResultStage 16)
18/06/25 13:16:26 INFO DAGScheduler: failed: Set()
18/06/25 13:16:26 INFO DAGScheduler: Submitting ResultStage 16 (ShuffledRDD[88] at countByValue at StringIndexer.scala:92), which has no missing parents
18/06/25 13:16:26 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 3.2 KB, free 340.4 MB)
18/06/25 13:16:26 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1970.0 B, free 340.4 MB)
18/06/25 13:16:26 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54716 (size: 1970.0 B, free: 340.4 MB)
18/06/25 13:16:26 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (ShuffledRDD[88] at countByValue at StringIndexer.scala:92)
18/06/25 13:16:26 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/06/25 13:16:26 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/06/25 13:16:26 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
18/06/25 13:16:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:16:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 13:16:26 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2244 bytes result sent to driver
18/06/25 13:16:26 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 22 ms on localhost (executor driver) (1/1)
18/06/25 13:16:26 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/06/25 13:16:26 INFO DAGScheduler: ResultStage 16 (countByValue at StringIndexer.scala:92) finished in 0.023 s
18/06/25 13:16:26 INFO DAGScheduler: Job 9 finished: countByValue at StringIndexer.scala:92, took 1.721840 s
18/06/25 13:16:26 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:54716 in memory (size: 1970.0 B, free: 340.4 MB)
18/06/25 13:16:26 INFO CodeGenerator: Code generated in 49.387556 ms
18/06/25 13:16:26 INFO SparkContext: Starting job: first at LinearRegression.scala:198
18/06/25 13:16:26 INFO DAGScheduler: Got job 10 (first at LinearRegression.scala:198) with 1 output partitions
18/06/25 13:16:26 INFO DAGScheduler: Final stage: ResultStage 17 (first at LinearRegression.scala:198)
18/06/25 13:16:26 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:16:26 INFO DAGScheduler: Missing parents: List()
18/06/25 13:16:26 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[91] at first at LinearRegression.scala:198), which has no missing parents
18/06/25 13:16:26 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 60.9 KB, free 340.3 MB)
18/06/25 13:16:26 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 22.0 KB, free 340.3 MB)
18/06/25 13:16:26 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54716 (size: 22.0 KB, free: 340.4 MB)
18/06/25 13:16:26 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[91] at first at LinearRegression.scala:198)
18/06/25 13:16:26 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/06/25 13:16:26 WARN TaskSetManager: Stage 17 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:26 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 13:16:26 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
18/06/25 13:16:27 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:27 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:54716 in memory (size: 16.0 KB, free: 340.4 MB)
18/06/25 13:16:27 INFO ContextCleaner: Cleaned shuffle 6
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 816
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 815
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 814
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 813
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 812
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 811
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 810
18/06/25 13:16:27 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54716 in memory (size: 11.7 KB, free: 340.5 MB)
18/06/25 13:16:27 INFO ContextCleaner: Cleaned shuffle 2
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 334
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 333
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 332
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 331
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 330
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 329
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 328
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 327
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 326
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 325
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 324
18/06/25 13:16:27 INFO ContextCleaner: Cleaned accumulator 323
18/06/25 13:16:27 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2282 bytes result sent to driver
18/06/25 13:16:27 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 1200 ms on localhost (executor driver) (1/1)
18/06/25 13:16:27 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/06/25 13:16:27 INFO DAGScheduler: ResultStage 17 (first at LinearRegression.scala:198) finished in 1.202 s
18/06/25 13:16:27 INFO DAGScheduler: Job 10 finished: first at LinearRegression.scala:198, took 1.209960 s
18/06/25 13:16:27 INFO CodeGenerator: Code generated in 8.955573 ms
18/06/25 13:16:28 INFO CodeGenerator: Code generated in 37.770052 ms
18/06/25 13:16:28 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
18/06/25 13:16:28 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
18/06/25 13:16:28 INFO DAGScheduler: Got job 11 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
18/06/25 13:16:28 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 13:16:28 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:16:28 INFO DAGScheduler: Missing parents: List()
18/06/25 13:16:28 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[97] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
18/06/25 13:16:28 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 63.8 KB, free 340.3 MB)
18/06/25 13:16:28 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.3 KB, free 340.3 MB)
18/06/25 13:16:28 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54716 (size: 23.3 KB, free: 340.4 MB)
18/06/25 13:16:28 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[97] at treeAggregate at WeightedLeastSquares.scala:100)
18/06/25 13:16:28 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
18/06/25 13:16:28 WARN TaskSetManager: Stage 18 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:28 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365311 bytes)
18/06/25 13:16:28 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
18/06/25 13:16:28 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:28 INFO CodeGenerator: Code generated in 5.084237 ms
18/06/25 13:16:30 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:54716 in memory (size: 22.0 KB, free: 340.5 MB)
18/06/25 13:16:30 INFO ContextCleaner: Cleaned accumulator 919
18/06/25 13:16:30 INFO ContextCleaner: Cleaned accumulator 918
18/06/25 13:16:30 INFO ContextCleaner: Cleaned accumulator 917
18/06/25 13:16:30 INFO ContextCleaner: Cleaned accumulator 916
18/06/25 13:16:30 INFO ContextCleaner: Cleaned accumulator 915
18/06/25 13:16:30 INFO ContextCleaner: Cleaned accumulator 914
18/06/25 13:16:30 INFO ContextCleaner: Cleaned accumulator 913
18/06/25 13:16:30 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 4172 bytes result sent to driver
18/06/25 13:16:30 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 2145 ms on localhost (executor driver) (1/1)
18/06/25 13:16:30 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/06/25 13:16:30 INFO DAGScheduler: ResultStage 18 (treeAggregate at WeightedLeastSquares.scala:100) finished in 2.146 s
18/06/25 13:16:30 INFO DAGScheduler: Job 11 finished: treeAggregate at WeightedLeastSquares.scala:100, took 2.153038 s
18/06/25 13:16:30 INFO WeightedLeastSquares: Number of instances: 210338.
18/06/25 13:16:30 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/06/25 13:16:30 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/06/25 13:16:30 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
18/06/25 13:16:30 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
18/06/25 13:16:30 INFO CodeGenerator: Code generated in 26.762179 ms
18/06/25 13:16:30 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
18/06/25 13:16:30 INFO DAGScheduler: Got job 12 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
18/06/25 13:16:30 INFO DAGScheduler: Final stage: ResultStage 19 (aggregate at RegressionMetrics.scala:57)
18/06/25 13:16:30 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:16:30 INFO DAGScheduler: Missing parents: List()
18/06/25 13:16:30 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[103] at map at RegressionMetrics.scala:55), which has no missing parents
18/06/25 13:16:30 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 62.6 KB, free 340.3 MB)
18/06/25 13:16:30 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 23.4 KB, free 340.3 MB)
18/06/25 13:16:30 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:54716 (size: 23.4 KB, free: 340.4 MB)
18/06/25 13:16:30 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[103] at map at RegressionMetrics.scala:55)
18/06/25 13:16:30 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
18/06/25 13:16:30 WARN TaskSetManager: Stage 19 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:30 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365307 bytes)
18/06/25 13:16:30 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
18/06/25 13:16:30 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:30 INFO CodeGenerator: Code generated in 5.764472 ms
18/06/25 13:16:31 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2604 bytes result sent to driver
18/06/25 13:16:31 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 1268 ms on localhost (executor driver) (1/1)
18/06/25 13:16:31 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/06/25 13:16:31 INFO DAGScheduler: ResultStage 19 (aggregate at RegressionMetrics.scala:57) finished in 1.268 s
18/06/25 13:16:31 INFO DAGScheduler: Job 12 finished: aggregate at RegressionMetrics.scala:57, took 1.276819 s
18/06/25 13:16:31 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
18/06/25 13:16:31 INFO DAGScheduler: Got job 13 (sum at RegressionMetrics.scala:71) with 1 output partitions
18/06/25 13:16:31 INFO DAGScheduler: Final stage: ResultStage 20 (sum at RegressionMetrics.scala:71)
18/06/25 13:16:31 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:16:31 INFO DAGScheduler: Missing parents: List()
18/06/25 13:16:31 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[104] at map at RegressionMetrics.scala:69), which has no missing parents
18/06/25 13:16:31 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 62.1 KB, free 340.2 MB)
18/06/25 13:16:31 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 23.2 KB, free 340.2 MB)
18/06/25 13:16:31 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:54716 (size: 23.2 KB, free: 340.4 MB)
18/06/25 13:16:31 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[104] at map at RegressionMetrics.scala:69)
18/06/25 13:16:31 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
18/06/25 13:16:31 WARN TaskSetManager: Stage 20 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:31 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365301 bytes)
18/06/25 13:16:31 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
18/06/25 13:16:32 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:54716 in memory (size: 23.4 KB, free: 340.4 MB)
18/06/25 13:16:32 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:54716 in memory (size: 23.3 KB, free: 340.5 MB)
18/06/25 13:16:32 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:33 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2121 bytes result sent to driver
18/06/25 13:16:33 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 1278 ms on localhost (executor driver) (1/1)
18/06/25 13:16:33 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/06/25 13:16:33 INFO DAGScheduler: ResultStage 20 (sum at RegressionMetrics.scala:71) finished in 1.280 s
18/06/25 13:16:33 INFO DAGScheduler: Job 13 finished: sum at RegressionMetrics.scala:71, took 1.289943 s
18/06/25 13:16:33 INFO CodeGenerator: Code generated in 15.974315 ms
18/06/25 13:16:33 INFO SparkContext: Starting job: count at LinearRegression.scala:683
18/06/25 13:16:33 INFO DAGScheduler: Registering RDD 107 (count at LinearRegression.scala:683)
18/06/25 13:16:33 INFO DAGScheduler: Got job 14 (count at LinearRegression.scala:683) with 1 output partitions
18/06/25 13:16:33 INFO DAGScheduler: Final stage: ResultStage 22 (count at LinearRegression.scala:683)
18/06/25 13:16:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
18/06/25 13:16:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
18/06/25 13:16:33 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[107] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 13:16:33 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 45.4 KB, free 340.3 MB)
18/06/25 13:16:33 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 16.9 KB, free 340.3 MB)
18/06/25 13:16:33 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:54716 (size: 16.9 KB, free: 340.4 MB)
18/06/25 13:16:33 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[107] at count at LinearRegression.scala:683)
18/06/25 13:16:33 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
18/06/25 13:16:33 INFO ContextCleaner: Cleaned accumulator 1126
18/06/25 13:16:33 WARN TaskSetManager: Stage 21 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:33 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 13:16:33 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
18/06/25 13:16:33 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:33 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:54716 in memory (size: 23.2 KB, free: 340.5 MB)
18/06/25 13:16:34 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 2839 bytes result sent to driver
18/06/25 13:16:34 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 1101 ms on localhost (executor driver) (1/1)
18/06/25 13:16:34 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/06/25 13:16:34 INFO DAGScheduler: ShuffleMapStage 21 (count at LinearRegression.scala:683) finished in 1.101 s
18/06/25 13:16:34 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:16:34 INFO DAGScheduler: running: Set()
18/06/25 13:16:34 INFO DAGScheduler: waiting: Set(ResultStage 22)
18/06/25 13:16:34 INFO DAGScheduler: failed: Set()
18/06/25 13:16:34 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[110] at count at LinearRegression.scala:683), which has no missing parents
18/06/25 13:16:34 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
18/06/25 13:16:34 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
18/06/25 13:16:34 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:54716 (size: 3.7 KB, free: 340.5 MB)
18/06/25 13:16:34 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[110] at count at LinearRegression.scala:683)
18/06/25 13:16:34 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
18/06/25 13:16:34 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 13:16:34 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
18/06/25 13:16:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:16:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 13:16:34 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 2042 bytes result sent to driver
18/06/25 13:16:34 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 4 ms on localhost (executor driver) (1/1)
18/06/25 13:16:34 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/06/25 13:16:34 INFO DAGScheduler: ResultStage 22 (count at LinearRegression.scala:683) finished in 0.005 s
18/06/25 13:16:34 INFO DAGScheduler: Job 14 finished: count at LinearRegression.scala:683, took 1.119121 s
18/06/25 13:16:34 INFO CodeGenerator: Code generated in 15.762725 ms
18/06/25 13:16:34 INFO CodeGenerator: Code generated in 29.978161 ms
18/06/25 13:16:34 INFO SparkContext: Starting job: first at LinearRegression.scala:707
18/06/25 13:16:34 INFO DAGScheduler: Registering RDD 113 (first at LinearRegression.scala:707)
18/06/25 13:16:34 INFO DAGScheduler: Got job 15 (first at LinearRegression.scala:707) with 1 output partitions
18/06/25 13:16:34 INFO DAGScheduler: Final stage: ResultStage 24 (first at LinearRegression.scala:707)
18/06/25 13:16:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
18/06/25 13:16:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
18/06/25 13:16:34 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[113] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 13:16:34 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 69.6 KB, free 340.3 MB)
18/06/25 13:16:34 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 26.9 KB, free 340.3 MB)
18/06/25 13:16:34 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:54716 (size: 26.9 KB, free: 340.4 MB)
18/06/25 13:16:34 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[113] at first at LinearRegression.scala:707)
18/06/25 13:16:34 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
18/06/25 13:16:34 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:54716 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 13:16:34 INFO ContextCleaner: Cleaned accumulator 1240
18/06/25 13:16:34 WARN TaskSetManager: Stage 23 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:34 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365238 bytes)
18/06/25 13:16:34 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
18/06/25 13:16:34 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1127
18/06/25 13:16:35 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:54716 in memory (size: 16.9 KB, free: 340.4 MB)
18/06/25 13:16:35 INFO ContextCleaner: Cleaned shuffle 7
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1143
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1142
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1141
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1140
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1139
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1138
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1137
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1136
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1135
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1134
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1133
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1132
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1131
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1130
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1129
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 1128
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 974
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 973
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 972
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 971
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 970
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 969
18/06/25 13:16:35 INFO ContextCleaner: Cleaned accumulator 968
18/06/25 13:16:36 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2839 bytes result sent to driver
18/06/25 13:16:36 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 1549 ms on localhost (executor driver) (1/1)
18/06/25 13:16:36 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/06/25 13:16:36 INFO DAGScheduler: ShuffleMapStage 23 (first at LinearRegression.scala:707) finished in 1.549 s
18/06/25 13:16:36 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:16:36 INFO DAGScheduler: running: Set()
18/06/25 13:16:36 INFO DAGScheduler: waiting: Set(ResultStage 24)
18/06/25 13:16:36 INFO DAGScheduler: failed: Set()
18/06/25 13:16:36 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[116] at first at LinearRegression.scala:707), which has no missing parents
18/06/25 13:16:36 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.9 KB, free 340.4 MB)
18/06/25 13:16:36 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 4.0 KB, free 340.4 MB)
18/06/25 13:16:36 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:54716 (size: 4.0 KB, free: 340.4 MB)
18/06/25 13:16:36 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[116] at first at LinearRegression.scala:707)
18/06/25 13:16:36 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
18/06/25 13:16:36 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/06/25 13:16:36 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
18/06/25 13:16:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:16:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/06/25 13:16:36 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2114 bytes result sent to driver
18/06/25 13:16:36 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
18/06/25 13:16:36 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/06/25 13:16:36 INFO DAGScheduler: ResultStage 24 (first at LinearRegression.scala:707) finished in 0.007 s
18/06/25 13:16:36 INFO DAGScheduler: Job 15 finished: first at LinearRegression.scala:707, took 1.567071 s
18/06/25 13:16:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa276047c3
18/06/25 13:16:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa276047c3` AS `zzz25`
WHERE (0 = 1)
18/06/25 13:16:36 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:54716 in memory (size: 4.0 KB, free: 340.4 MB)
18/06/25 13:16:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa22076767
18/06/25 13:16:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa22076767` AS `zzz26`
WHERE (0 = 1)
18/06/25 13:16:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa14cd0cda`
18/06/25 13:16:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa1415aca5
18/06/25 13:16:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa1415aca5` AS `zzz27`
WHERE (0 = 1)
18/06/25 13:16:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa1415aca5`
18/06/25 13:16:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:16:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa22076767`
18/06/25 13:16:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
18/06/25 13:16:49 INFO DAGScheduler: Registering RDD 122 (count at NativeMethodAccessorImpl.java:0)
18/06/25 13:16:49 INFO DAGScheduler: Got job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/06/25 13:16:49 INFO DAGScheduler: Final stage: ResultStage 26 (count at NativeMethodAccessorImpl.java:0)
18/06/25 13:16:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
18/06/25 13:16:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
18/06/25 13:16:49 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[122] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 13:16:49 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 45.4 KB, free 340.3 MB)
18/06/25 13:16:49 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 17.0 KB, free 340.3 MB)
18/06/25 13:16:49 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:54716 (size: 17.0 KB, free: 340.4 MB)
18/06/25 13:16:49 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[122] at count at NativeMethodAccessorImpl.java:0)
18/06/25 13:16:49 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
18/06/25 13:16:49 INFO ContextCleaner: Cleaned accumulator 1354
18/06/25 13:16:49 WARN TaskSetManager: Stage 25 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:49 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365324 bytes)
18/06/25 13:16:49 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
18/06/25 13:16:49 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:50 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2839 bytes result sent to driver
18/06/25 13:16:50 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 788 ms on localhost (executor driver) (1/1)
18/06/25 13:16:50 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/06/25 13:16:50 INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0.792 s
18/06/25 13:16:50 INFO DAGScheduler: looking for newly runnable stages
18/06/25 13:16:50 INFO DAGScheduler: running: Set()
18/06/25 13:16:50 INFO DAGScheduler: waiting: Set(ResultStage 26)
18/06/25 13:16:50 INFO DAGScheduler: failed: Set()
18/06/25 13:16:50 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[125] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
18/06/25 13:16:50 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 340.3 MB)
18/06/25 13:16:50 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.3 MB)
18/06/25 13:16:50 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:54716 (size: 3.7 KB, free: 340.4 MB)
18/06/25 13:16:50 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[125] at count at NativeMethodAccessorImpl.java:0)
18/06/25 13:16:50 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
18/06/25 13:16:50 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/06/25 13:16:50 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
18/06/25 13:16:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/06/25 13:16:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/06/25 13:16:50 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2042 bytes result sent to driver
18/06/25 13:16:50 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 5 ms on localhost (executor driver) (1/1)
18/06/25 13:16:50 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/06/25 13:16:50 INFO DAGScheduler: ResultStage 26 (count at NativeMethodAccessorImpl.java:0) finished in 0.006 s
18/06/25 13:16:50 INFO DAGScheduler: Job 16 finished: count at NativeMethodAccessorImpl.java:0, took 0.813123 s
18/06/25 13:16:50 INFO CodeGenerator: Code generated in 38.06543 ms
18/06/25 13:16:50 INFO SparkContext: Starting job: collect at utils.scala:36
18/06/25 13:16:50 INFO DAGScheduler: Got job 17 (collect at utils.scala:36) with 1 output partitions
18/06/25 13:16:50 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:36)
18/06/25 13:16:50 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:16:50 INFO DAGScheduler: Missing parents: List()
18/06/25 13:16:50 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[130] at map at utils.scala:33), which has no missing parents
18/06/25 13:16:50 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 76.1 KB, free 340.2 MB)
18/06/25 13:16:50 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 26.9 KB, free 340.2 MB)
18/06/25 13:16:50 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:54716 (size: 26.9 KB, free: 340.4 MB)
18/06/25 13:16:50 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
18/06/25 13:16:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[130] at map at utils.scala:33)
18/06/25 13:16:50 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
18/06/25 13:16:50 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:54716 in memory (size: 3.7 KB, free: 340.4 MB)
18/06/25 13:16:50 WARN TaskSetManager: Stage 27 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:16:50 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365305 bytes)
18/06/25 13:16:50 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
18/06/25 13:16:50 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:16:50 INFO CodeGenerator: Code generated in 6.101257 ms
18/06/25 13:16:51 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 803450 bytes result sent to driver
18/06/25 13:16:51 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 1227 ms on localhost (executor driver) (1/1)
18/06/25 13:16:51 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/06/25 13:16:51 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:36) finished in 1.227 s
18/06/25 13:16:51 INFO DAGScheduler: Job 17 finished: collect at utils.scala:36, took 1.237780 s
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa2206c6e1`
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa1bb3ef99
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa1bb3ef99` AS `zzz28`
WHERE (0 = 1)
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa1bb3ef99`
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_8dfa42373404
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_8dfa42373404` AS `zzz29`
WHERE (0 = 1)
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, `prediction`
FROM `sparklyr_tmp_8dfa42373404`
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, `prediction`
FROM `sparklyr_tmp_8dfa42373404`
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, `prediction`
FROM `sparklyr_tmp_8dfa42373404`
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, `prediction`
FROM `sparklyr_tmp_8dfa42373404`
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, `prediction`
FROM `sparklyr_tmp_8dfa42373404`
18/06/25 13:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/06/25 13:17:32 INFO SparkSqlParser: Parsing command: SELECT `year`, `month`, `day`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `origin`, `dest`, `air_time`, `distance`, `hour`, `minute`, `time_hour`, `prediction`
FROM `sparklyr_tmp_8dfa42373404`
LIMIT 1000
18/06/25 13:17:32 INFO CodeGenerator: Code generated in 26.431191 ms
18/06/25 13:17:32 INFO SparkContext: Starting job: collect at utils.scala:196
18/06/25 13:17:32 INFO DAGScheduler: Got job 18 (collect at utils.scala:196) with 1 output partitions
18/06/25 13:17:32 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:196)
18/06/25 13:17:32 INFO DAGScheduler: Parents of final stage: List()
18/06/25 13:17:32 INFO DAGScheduler: Missing parents: List()
18/06/25 13:17:32 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[135] at collect at utils.scala:196), which has no missing parents
18/06/25 13:17:32 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 66.0 KB, free 340.2 MB)
18/06/25 13:17:32 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 24.7 KB, free 340.1 MB)
18/06/25 13:17:32 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:54716 (size: 24.7 KB, free: 340.4 MB)
18/06/25 13:17:32 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
18/06/25 13:17:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[135] at collect at utils.scala:196)
18/06/25 13:17:32 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
18/06/25 13:17:32 WARN TaskSetManager: Stage 28 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
18/06/25 13:17:32 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365249 bytes)
18/06/25 13:17:32 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
18/06/25 13:17:32 INFO BlockManager: Found block rdd_37_0 locally
18/06/25 13:17:33 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 70855 bytes result sent to driver
18/06/25 13:17:33 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 795 ms on localhost (executor driver) (1/1)
18/06/25 13:17:33 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/06/25 13:17:33 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:196) finished in 0.795 s
18/06/25 13:17:33 INFO DAGScheduler: Job 18 finished: collect at utils.scala:196, took 0.802162 s
18/06/25 13:17:33 INFO CodeGenerator: Code generated in 12.025175 ms
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1246
18/06/25 13:44:58 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:54716 in memory (size: 24.7 KB, free: 340.4 MB)
18/06/25 13:44:58 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:54716 in memory (size: 26.9 KB, free: 340.4 MB)
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1475
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1474
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1473
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1472
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1471
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1470
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1469
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1468
18/06/25 13:44:58 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:54716 in memory (size: 17.0 KB, free: 340.4 MB)
18/06/25 13:44:58 INFO ContextCleaner: Cleaned shuffle 9
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1371
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1370
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1369
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1368
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1367
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1366
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1365
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1364
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1363
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1362
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1361
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1360
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1359
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1358
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1357
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1356
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1355
18/06/25 13:44:58 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:54716 in memory (size: 26.9 KB, free: 340.5 MB)
18/06/25 13:44:58 INFO ContextCleaner: Cleaned shuffle 8
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1257
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1256
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1255
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1254
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1253
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1252
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1251
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1250
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1249
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1248
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1247
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1245
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1244
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1243
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1242
18/06/25 13:44:58 INFO ContextCleaner: Cleaned accumulator 1241
